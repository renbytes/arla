{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ARLA: The Agent Simulation Framework","text":""},{"location":"#build-the-future-of-agent-based-modeling","title":"Build the Future of Agent-Based Modeling","text":"<p>ARLA combines cutting-edge cognitive architectures with high-performance simulation to create believable, intelligent agents that learn, adapt, and emerge complex behaviors.</p> <p>Get Started View Documentation</p>"},{"location":"#why-arla","title":"Why ARLA?","text":"<ul> <li> <p> High-Performance Core</p> <p>Built on asynchronous Python with Entity-Component-System architecture. Scale to thousands of agents with concurrent execution and optimized memory management.</p> <p> Architecture Overview</p> </li> <li> <p> Cognitively-Rich Agents</p> <p>Move beyond simple rules. Agents with memory, emotions, social awareness, and goal-driven behavior powered by Large Language Models.</p> <p> Cognitive Systems</p> </li> <li> <p> Modular &amp; Extensible</p> <p>Clean separation of data and logic through ECS. Add new behaviors, cognitive models, and environmental rules without touching the core engine.</p> <p> Developer Guide</p> </li> <li> <p> Research-Ready</p> <p>Built-in experiment management, MLflow integration, and comprehensive logging. Perfect for ablation studies and reproducible research.</p> <p> Running Experiments</p> </li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<ul> <li> <p>1. Install</p> <pre><code>git clone https://github.com/renbytes/arla.git\ncd arla\nmake setup &amp;&amp; make up\n</code></pre> </li> <li> <p>2. Run</p> <pre><code>make run-example\n</code></pre> </li> <li> <p>3. Explore</p> <p>Open MLflow UI to view results and experiment tracking.</p> </li> </ul>"},{"location":"#use-cases","title":"Use Cases","text":"<ul> <li> <p> Social Dynamics</p> <p>Study how societies form, cooperate, and conflict. Model everything from small groups to large populations.</p> </li> <li> <p> Economic Emergence</p> <p>Watch markets, trade, and currency systems emerge naturally from agent interactions and resource scarcity.</p> </li> <li> <p> Learning &amp; Adaptation</p> <p>Research how agents learn from experience, form memories, and adapt their strategies over time.</p> </li> <li> <p> Moral Reasoning</p> <p>Explore how ethical systems develop through social feedback and cultural transmission.</p> </li> </ul>"},{"location":"#built-for-researchers","title":"Built for Researchers","text":"AcademicIndustryEducation <p>Perfect for computational social science, AI research, and complex systems studies. Built-in support for:</p> <ul> <li>Reproducible experiments with configuration management</li> <li>Statistical analysis with automated data collection</li> <li>Publication-ready visualizations and metrics</li> </ul> <p>Prototype and test multi-agent systems for real-world applications:</p> <ul> <li>Market simulation and economic modeling</li> <li>Social network analysis and recommendation systems</li> <li>Human-AI interaction studies</li> </ul> <p>Teach complex systems, AI, and social dynamics with engaging simulations:</p> <ul> <li>Pre-built scenarios for classroom use</li> <li>Visual debugging and real-time monitoring</li> <li>Comprehensive documentation and tutorials</li> </ul>"},{"location":"#community-support","title":"Community &amp; Support","text":"<ul> <li> <p> Open Source</p> <p>MIT licensed with active development. Contribute features, report bugs, or extend the platform.</p> <p> Contributing Guide</p> </li> <li> <p> Documentation</p> <p>Comprehensive guides, tutorials, and API reference. From first simulation to advanced cognitive architectures.</p> <p> Browse Docs</p> </li> <li> <p> Research Blog</p> <p>Latest developments, research findings, and community showcases. Stay updated with the ARLA ecosystem.</p> <p> Read Blog</p> </li> </ul> <p>Ready to build intelligent agents?</p> <p>Start Tutorial Install ARLA</p>"},{"location":"api/agent-core/","title":"API Reference: agent-core","text":"<p>The <code>agent-core</code> library provides foundational, world-agnostic classes and interfaces that form the backbone of all ARLA simulations. These abstractions ensure consistency and enable modular development across different simulation environments.</p> <p>Package Overview</p> <p><code>agent-core</code> defines the contracts and base implementations that all ARLA simulations must follow. Think of it as the \"constitution\" for the ARLA ecosystem, establishing the fundamental patterns that enable modularity and extensibility.</p>"},{"location":"api/agent-core/#core-ecs-classes","title":"Core ECS Classes","text":"<p>The Entity-Component-System pattern forms the architectural foundation of ARLA. These classes provide the essential building blocks for simulation state management and agent behavior.</p>"},{"location":"api/agent-core/#simulationstate","title":"SimulationState","text":"<p>The central hub for all simulation data, managing entities and their components with efficient queries and updates.</p> <p>Core Capabilities:</p> <ul> <li>Entity Management: Create, destroy, and query entities efficiently</li> <li>Component Storage: Type-safe component attachment and retrieval</li> <li>Batch Operations: Optimized queries for entities with specific component combinations</li> <li>State Persistence: Serialization support for checkpointing and analysis</li> </ul>"},{"location":"api/agent-core/#agent_core.core.ecs.abstractions.AbstractSimulationState","title":"<code>agent_core.core.ecs.abstractions.AbstractSimulationState</code>","text":"<p>               Bases: <code>ABC</code></p> <p>The abstract interface for the simulation's state container. This contract ensures that any system can interact with the state in a predictable way without knowing the concrete implementation.</p>"},{"location":"api/agent-core/#agent_core.core.ecs.abstractions.AbstractSimulationState.event_bus","title":"<code>event_bus</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Provides access to the simulation's event bus.</p>"},{"location":"api/agent-core/#agent_core.core.ecs.abstractions.AbstractSimulationState.get_component","title":"<code>get_component(entity_id, component_type)</code>  <code>abstractmethod</code>","text":"<p>Retrieves a component of a specific type for a given entity.</p>"},{"location":"api/agent-core/#agent_core.core.ecs.abstractions.AbstractSimulationState.get_entities_with_components","title":"<code>get_entities_with_components(component_types)</code>  <code>abstractmethod</code>","text":"<p>Retrieves all entities that have a specific set of components.</p>"},{"location":"api/agent-core/#component-base-class","title":"Component Base Class","text":"<p>Pure data containers that define entity properties and state.</p> <p>Design Principles:</p> <ul> <li>Components should contain only data, no business logic</li> <li>Implement <code>to_dict()</code> for serialization and persistence</li> <li>Include <code>validate()</code> for data integrity checking</li> <li>Use type hints for all attributes</li> </ul> <p>Example Component:</p> <pre><code>class HealthComponent(Component):\n    \"\"\"Manages agent health and damage tracking.\"\"\"\n\n    def __init__(self, max_health: int = 100):\n        self.max_health = max_health\n        self.current_health = max_health\n        self.last_damage_tick = 0\n        self.damage_history: List[int] = []\n\n    @property\n    def health_percentage(self) -&gt; float:\n        \"\"\"Current health as percentage of maximum.\"\"\"\n        return self.current_health / self.max_health\n\n    @property\n    def is_critical(self) -&gt; bool:\n        \"\"\"True if health is below 25% of maximum.\"\"\"\n        return self.health_percentage &lt; 0.25\n\n    def to_dict(self) -&gt; Dict[str, Any]:\n        return {\n            \"max_health\": self.max_health,\n            \"current_health\": self.current_health,\n            \"last_damage_tick\": self.last_damage_tick,\n            \"damage_history\": self.damage_history\n        }\n\n    def validate(self, entity_id: str) -&gt; Tuple[bool, List[str]]:\n        errors = []\n        if self.current_health &lt; 0:\n            errors.append(\"Health cannot be negative\")\n        if self.max_health &lt;= 0:\n            errors.append(\"Max health must be positive\")\n        return len(errors) == 0, errors\n</code></pre>"},{"location":"api/agent-core/#agent_core.core.ecs.component.Component","title":"<code>agent_core.core.ecs.component.Component</code>","text":"<p>               Bases: <code>CognitiveComponent</code></p> <p>Base class for all components with validation interface.</p>"},{"location":"api/agent-core/#agent_core.core.ecs.component.Component.auto_fix","title":"<code>auto_fix(entity_id, config)</code>","text":"<p>Attempts to automatically fix validation errors.</p>"},{"location":"api/agent-core/#agent_core.core.ecs.component.Component.to_dict","title":"<code>to_dict()</code>  <code>abstractmethod</code>","text":"<p>Converts the component's data to a dictionary for serialization/logging.</p>"},{"location":"api/agent-core/#agent_core.core.ecs.component.Component.validate","title":"<code>validate(entity_id)</code>  <code>abstractmethod</code>","text":"<p>Validates component state and returns (is_valid, error_list).</p>"},{"location":"api/agent-core/#action-interfaces","title":"Action Interfaces","text":"<p>Actions define the behaviors available to agents. The action system enables dynamic behavior generation and supports machine learning integration.</p>"},{"location":"api/agent-core/#actioninterface","title":"ActionInterface","text":"<p>The contract that all agent actions must implement, ensuring consistent integration with the simulation engine.</p> <p>Action Lifecycle:</p> <pre><code>graph LR\n    A[Discovery] --&gt; B[Parameter Generation]\n    B --&gt; C[Action Selection]\n    C --&gt; D[Execution]\n    D --&gt; E[System Processing]\n    E --&gt; F[Outcome Calculation]</code></pre> <ol> <li>Discovery: <code>@action_registry.register</code> makes actions available</li> <li>Parameter Generation: <code>generate_possible_params()</code> creates action variants</li> <li>Selection: Decision systems choose from available actions</li> <li>Execution: <code>execute()</code> returns outcome, systems handle state changes</li> <li>Learning: <code>get_feature_vector()</code> enables ML model training</li> </ol> <p>Implementation Guidelines:</p> <ul> <li>Keep <code>execute()</code> lightweight - delegate actual work to Systems</li> <li>Generate parameters based on current world state</li> <li>Return meaningful ActionOutcome messages for debugging</li> <li>Design feature vectors for your learning algorithms</li> </ul>"},{"location":"api/agent-core/#agent_core.agents.actions.action_interface.ActionInterface","title":"<code>agent_core.agents.actions.action_interface.ActionInterface</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract Base Class for all actions. Any new action created for the simulation must inherit from this class and implement its abstract methods and properties.</p>"},{"location":"api/agent-core/#agent_core.agents.actions.action_interface.ActionInterface.action_id","title":"<code>action_id</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>A unique string identifier for the action, e.g., 'move', 'extract_resources'.</p>"},{"location":"api/agent-core/#agent_core.agents.actions.action_interface.ActionInterface.name","title":"<code>name</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>A human-readable name for the action, e.g., 'Move'.</p>"},{"location":"api/agent-core/#agent_core.agents.actions.action_interface.ActionInterface.execute","title":"<code>execute(entity_id, simulation_state, params, current_tick)</code>  <code>abstractmethod</code>","text":"<p>Executes the action's logic and modifies the simulation state.</p>"},{"location":"api/agent-core/#agent_core.agents.actions.action_interface.ActionInterface.generate_possible_params","title":"<code>generate_possible_params(entity_id, simulation_state, current_tick)</code>  <code>abstractmethod</code>","text":"<p>Generates all possible valid parameter combinations for this action for a given entity.</p>"},{"location":"api/agent-core/#agent_core.agents.actions.action_interface.ActionInterface.get_base_cost","title":"<code>get_base_cost(simulation_state)</code>  <code>abstractmethod</code>","text":"<p>The base time budget cost to perform the action.</p>"},{"location":"api/agent-core/#agent_core.agents.actions.action_interface.ActionInterface.get_feature_vector","title":"<code>get_feature_vector(entity_id, simulation_state, params)</code>  <code>abstractmethod</code>","text":"<p>Generates the feature vector for this specific action variant.</p>"},{"location":"api/agent-core/#provider-interfaces","title":"Provider Interfaces","text":"<p>Provider interfaces enable world-agnostic systems to access world-specific data through dependency injection, maintaining the separation between engine and simulation logic.</p>"},{"location":"api/agent-core/#core-provider-pattern","title":"Core Provider Pattern","text":"<p>The provider pattern bridges the gap between world-agnostic cognitive systems and world-specific data:</p> <pre><code>class VitalityMetricsProvider(VitalityMetricsProviderInterface):\n    \"\"\"Bridges health/energy systems with cognitive architecture.\"\"\"\n\n    def get_normalized_vitality_metrics(\n        self, \n        entity_id: str, \n        components: Dict[Type[Component], Component], \n        config: Dict[str, Any]\n    ) -&gt; Dict[str, float]:\n        health_comp = components.get(HealthComponent)\n        energy_comp = components.get(EnergyComponent)\n\n        if not health_comp or not energy_comp:\n            return {\"health_norm\": 0.5, \"energy_norm\": 0.5, \"fatigue_norm\": 0.5}\n\n        return {\n            \"health_norm\": health_comp.current / health_comp.max_health,\n            \"energy_norm\": energy_comp.current / energy_comp.max_energy,\n            \"fatigue_norm\": 1.0 - (energy_comp.current / energy_comp.max_energy)\n        }\n</code></pre> <p>Available Provider Interfaces:</p> <ul> <li> <p>VitalityMetricsProvider</p> <p>Provides normalized health and energy data for cognitive systems.</p> </li> <li> <p>NarrativeContextProvider</p> <p>Supplies contextual information for LLM-based reflection and planning.</p> </li> <li> <p>StateEncoderProvider</p> <p>Encodes simulation state into feature vectors for machine learning.</p> </li> <li> <p>MemoryAccessProvider</p> <p>Manages filtered access to agent memories and experiences.</p> </li> </ul>"},{"location":"api/agent-core/#system-base-classes","title":"System Base Classes","text":"<p>Foundation classes for implementing simulation logic and cognitive systems.</p>"},{"location":"api/agent-core/#system-base-class","title":"System Base Class","text":"<p>The parent class for all simulation systems, providing event bus access and lifecycle management.</p> <p>System Development Pattern:</p> <pre><code>class ExampleSystem(System):\n    \"\"\"Example system demonstrating best practices.\"\"\"\n\n    def __init__(self, simulation_state, config, cognitive_scaffold):\n        super().__init__(simulation_state, config, cognitive_scaffold)\n\n        # Subscribe to relevant events\n        if self.event_bus:\n            self.event_bus.subscribe(\"target_event\", self.handle_event)\n            self.event_bus.subscribe(\"tick_completed\", self.on_tick_complete)\n\n    def handle_event(self, event_data: Dict[str, Any]) -&gt; None:\n        \"\"\"Process specific events with proper error handling.\"\"\"\n        try:\n            entity_id = event_data.get(\"entity_id\")\n            if not entity_id:\n                return\n\n            # Process event logic here\n            self._process_event_logic(entity_id, event_data)\n\n        except Exception as e:\n            print(f\"Error handling event in {self.__class__.__name__}: {e}\")\n\n    async def update(self, current_tick: int) -&gt; None:\n        \"\"\"Main system update loop called each simulation tick.\"\"\"\n        # Periodic processing logic here\n        entities = self.simulation_state.get_entities_with_components([\n            RequiredComponent\n        ])\n\n        for entity_id, components in entities.items():\n            await self._process_entity(entity_id, components, current_tick)\n\n    def _process_entity(self, entity_id: str, components: Dict, tick: int):\n        \"\"\"Process individual entity - separate method for testing.\"\"\"\n        pass\n</code></pre>"},{"location":"api/agent-core/#agent_engine.simulation.system.System","title":"<code>agent_engine.simulation.system.System</code>","text":"<p>               Bases: <code>CognitiveSystem</code>, <code>SystemProtocol</code></p> <p>Abstract base class for all systems in the engine. It now directly inherits the asynchronous contract from CognitiveSystem.</p>"},{"location":"api/agent-core/#agent_engine.simulation.system.System.update","title":"<code>update(current_tick)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Processes the system's logic for the current simulation tick. The system is responsible for fetching the entities it needs to operate on from self.simulation_state, typically using self.REQUIRED_COMPONENTS.</p>"},{"location":"api/agent-core/#configuration-management","title":"Configuration Management","text":"<p>ARLA uses Pydantic for type-safe, validated configuration management across all simulations.</p>"},{"location":"api/agent-core/#configuration-schema-pattern","title":"Configuration Schema Pattern","text":"<pre><code>from pydantic import BaseModel, Field\nfrom typing import Optional, List\n\nclass AgentConfig(BaseModel):\n    \"\"\"Configuration for agent behavior and properties.\"\"\"\n    max_health: int = Field(default=100, gt=0, description=\"Maximum health points\")\n    learning_rate: float = Field(default=0.01, gt=0, le=1, description=\"Learning rate for Q-learning\")\n    memory_capacity: int = Field(default=1000, gt=0, description=\"Size of agent memory buffer\")\n\nclass EnvironmentConfig(BaseModel):\n    \"\"\"Configuration for world environment settings.\"\"\"\n    grid_size: tuple[int, int] = Field(default=(50, 50), description=\"World dimensions\")\n    resource_spawn_rate: float = Field(default=0.02, ge=0, le=1, description=\"Resource spawn probability per tick\")\n\nclass SimulationConfig(BaseModel):\n    \"\"\"Top-level simulation configuration.\"\"\"\n    agent: AgentConfig = Field(default_factory=AgentConfig)\n    environment: EnvironmentConfig = Field(default_factory=EnvironmentConfig)\n    max_ticks: int = Field(default=1000, gt=0, description=\"Maximum simulation duration\")\n    random_seed: Optional[int] = Field(default=42, description=\"Random seed for reproducibility\")\n    debug_mode: bool = Field(default=False, description=\"Enable debug logging\")\n</code></pre> <p>Configuration Benefits:</p> <ul> <li>Type Safety: Catch configuration errors at startup</li> <li>Validation: Automatic constraint checking with clear error messages</li> <li>Documentation: Self-documenting configuration schemas</li> <li>IDE Support: Autocompletion and type checking during development</li> </ul>"},{"location":"api/agent-core/#migration-guide","title":"Migration Guide","text":""},{"location":"api/agent-core/#from-dictionary-based-configuration","title":"From Dictionary-Based Configuration","text":"<p>Before: <pre><code># Fragile dictionary access with no validation\nhealth = config.get(\"agent\", {}).get(\"health\", {}).get(\"max\", 100)\nlearning_rate = config.get(\"learning\", {}).get(\"rate\", 0.01)\n</code></pre></p> <p>After: <pre><code># Type-safe access with IDE support\nhealth = config.agent.max_health\nlearning_rate = config.agent.learning_rate\n</code></pre></p>"},{"location":"api/agent-core/#component-design-best-practices","title":"Component Design Best Practices","text":"<p>Avoid Logic in Components: <pre><code>class BadComponent(Component):\n    def update_health(self, damage):  # Logic belongs in Systems!\n        self.health -= damage\n        if self.health &lt;= 0:\n            self.trigger_death()  # Side effects in components are bad\n</code></pre></p> <p>Prefer Pure Data: <pre><code>class GoodComponent(Component):\n    def __init__(self, max_health: int = 100):\n        self.max_health = max_health\n        self.current_health = max_health  # Just data storage\n        self.damage_taken = 0\n\n    # Properties for computed values are acceptable\n    @property\n    def is_alive(self) -&gt; bool:\n        return self.current_health &gt; 0\n</code></pre></p>"},{"location":"api/agent-core/#performance-considerations","title":"Performance Considerations","text":""},{"location":"api/agent-core/#component-queries","title":"Component Queries","text":"<ul> <li>Use <code>get_entities_with_components()</code> for bulk operations</li> <li>Cache component references when processing multiple entities</li> <li>Prefer specific component queries over entity iteration</li> </ul> <pre><code># Efficient bulk processing\nentities = simulation_state.get_entities_with_components([\n    HealthComponent, PositionComponent\n])\n\nfor entity_id, components in entities.items():\n    health_comp = components[HealthComponent]\n    pos_comp = components[PositionComponent]\n    # Process with cached references\n</code></pre>"},{"location":"api/agent-core/#memory-management","title":"Memory Management","text":"<ul> <li>Components are lightweight - favor composition over inheritance</li> <li>Use <code>__slots__</code> for frequently instantiated components</li> <li>Clean up references in component destructors</li> </ul> <pre><code>class OptimizedComponent(Component):\n    __slots__ = ['x', 'y', 'timestamp']  # Reduces memory overhead\n\n    def __init__(self, x: int, y: int):\n        self.x = x\n        self.y = y\n        self.timestamp = time.time()\n</code></pre>"},{"location":"api/agent-core/#event-bus-usage","title":"Event Bus Usage","text":"<ul> <li>Subscribe to specific events, not broad categories</li> <li>Unsubscribe systems that are no longer needed</li> <li>Use event data efficiently to avoid serialization overhead</li> </ul> <pre><code># Efficient event handling\ndef __init__(self, simulation_state, config, cognitive_scaffold):\n    super().__init__(simulation_state, config, cognitive_scaffold)\n\n    # Subscribe to specific, relevant events only\n    if self.event_bus:\n        self.event_bus.subscribe(\"agent_death\", self.handle_death)\n        self.event_bus.subscribe(\"resource_depleted\", self.handle_depletion)\n        # Avoid subscribing to \"all_events\" or overly broad categories\n</code></pre>"},{"location":"api/agent-engine/","title":"API Reference: agent-engine","text":"<p>The <code>agent-engine</code> library contains the core cognitive systems and simulation orchestration components that bring ARLA agents to life. These classes implement sophisticated behavioral models while remaining world-agnostic through the provider interface system.</p> <p>Cognitive Architecture</p> <p>The agent-engine implements a modular cognitive architecture inspired by theories from psychology and cognitive science, including memory consolidation, emotional appraisal, identity formation, and causal reasoning.</p>"},{"location":"api/agent-engine/#core-simulation-engine","title":"Core Simulation Engine","text":"<p>The simulation engine orchestrates the entire agent lifecycle, from initialization to shutdown, managing concurrent system execution and state persistence.</p>"},{"location":"api/agent-engine/#simulationmanager","title":"SimulationManager","text":"<p>The primary orchestrator that coordinates all simulation systems and manages the simulation lifecycle.</p> <p>Key Responsibilities:</p> <ul> <li>System Registration: Register and initialize all cognitive and world systems</li> <li>Lifecycle Management: Handle simulation startup, execution, and shutdown</li> <li>State Coordination: Manage state persistence and checkpoint creation</li> <li>Error Recovery: Handle system failures gracefully with rollback capabilities</li> </ul>"},{"location":"api/agent-engine/#agent_engine.simulation.engine.SimulationManager","title":"<code>agent_engine.simulation.engine.SimulationManager</code>","text":"<p>This manager is responsible for stepping through time, processing entity decisions, and updating all registered systems.</p>"},{"location":"api/agent-engine/#agent_engine.simulation.engine.SimulationManager.load_state","title":"<code>load_state(filepath)</code>","text":"<p>Loads the entire simulation state from a checkpoint file.</p>"},{"location":"api/agent-engine/#agent_engine.simulation.engine.SimulationManager.register_system","title":"<code>register_system(system_class, **kwargs)</code>","text":"<p>A convenience method to register a system with the SystemManager.</p>"},{"location":"api/agent-engine/#agent_engine.simulation.engine.SimulationManager.run","title":"<code>run(start_step=0, end_step=None)</code>  <code>async</code>","text":"<p>Executes the main ECS simulation loop asynchronously.</p>"},{"location":"api/agent-engine/#agent_engine.simulation.engine.SimulationManager.save_state","title":"<code>save_state(tick)</code>","text":"<p>Saves the current simulation state to a file.</p>"},{"location":"api/agent-engine/#systemmanager","title":"SystemManager","text":"<p>Manages the concurrent execution of multiple systems with dependency resolution and performance monitoring.</p> <p>Execution Strategies:</p> <ul> <li>Asynchronous: Concurrent system execution for maximum performance</li> <li>Serial: Deterministic execution for debugging and reproducibility</li> <li>Hybrid: Mixed execution with critical systems running synchronously</li> </ul>"},{"location":"api/agent-engine/#agent_engine.simulation.system.SystemManager","title":"<code>agent_engine.simulation.system.SystemManager</code>","text":"<p>Manages the registration, initialization, and execution of all systems using a specified runner (e.g., AsyncSystemRunner).</p>"},{"location":"api/agent-engine/#agent_engine.simulation.system.SystemManager.get_system","title":"<code>get_system(system_type)</code>","text":"<p>Retrieves a system instance of the given type. NOTE: This should be used sparingly, primarily for debugging or post-simulation analysis. Prefer using the EventBus for inter-system communication.</p>"},{"location":"api/agent-engine/#agent_engine.simulation.system.SystemManager.register_system","title":"<code>register_system(system_class, **kwargs)</code>","text":"<p>Instantiates and registers a system, passing extra keyword arguments to its constructor. This is crucial for dependency injection.</p>"},{"location":"api/agent-engine/#agent_engine.simulation.system.SystemManager.update_all","title":"<code>update_all(current_tick)</code>  <code>async</code>","text":"<p>Executes the update method for all registered systems using the runner.</p>"},{"location":"api/agent-engine/#cognitive-systems","title":"Cognitive Systems","text":"<p>These systems implement the core intelligence of ARLA agents, from basic decision-making to complex social reasoning.</p>"},{"location":"api/agent-engine/#reflectionsystem","title":"ReflectionSystem","text":"<p>Implements metacognitive capabilities, enabling agents to analyze their experiences and form narrative memories.</p> <p>Reflection Process:</p> <pre><code>graph TD\n    A[Experience Buffer] --&gt; B[Pattern Recognition]\n    B --&gt; C[LLM Analysis]\n    C --&gt; D[Memory Consolidation]\n    D --&gt; E[Insight Generation]\n    E --&gt; F[Goal Updates]</code></pre> <p>Core Functions:</p> <ul> <li>Experience Analysis: Process recent actions and outcomes for patterns</li> <li>Memory Consolidation: Convert experiences into lasting narrative memories</li> <li>Insight Generation: Extract learnings and update agent beliefs</li> <li>Goal Adaptation: Modify agent objectives based on reflection insights</li> </ul>"},{"location":"api/agent-engine/#agent_engine.systems.reflection_system.ReflectionSystem","title":"<code>agent_engine.systems.reflection_system.ReflectionSystem</code>","text":"<p>               Bases: <code>System</code></p> <p>Relies on an injected NarrativeContextProviderInterface for world-specific narrative generation, improving decoupling.</p>"},{"location":"api/agent-engine/#agent_engine.systems.reflection_system.ReflectionSystem.on_action_executed_for_chunking","title":"<code>on_action_executed_for_chunking(event_data)</code>","text":"<p>Buffers events for each agent to be chunked into episodes later.</p>"},{"location":"api/agent-engine/#agent_engine.systems.reflection_system.ReflectionSystem.on_reflection_requested","title":"<code>on_reflection_requested(event_data)</code>","text":"<p>Handles an explicit request for reflection from another system.</p>"},{"location":"api/agent-engine/#agent_engine.systems.reflection_system.ReflectionSystem.update","title":"<code>update(current_tick)</code>  <code>async</code>","text":"<p>Periodically triggers the reflection process for active agents.</p>"},{"location":"api/agent-engine/#agent_engine.systems.reflection_system.ReflectionSystem.update_for_entity","title":"<code>update_for_entity(entity_id, current_tick, is_final_reflection)</code>  <code>async</code>","text":"<p>Allows forcing a reflection cycle for a specific entity.</p>"},{"location":"api/agent-engine/#qlearningsystem","title":"QLearningSystem","text":"<p>Implements utility-based decision-making with neural network function approximation and experience replay.</p> <p>Learning Architecture:</p> <ul> <li>State Encoding: Convert world state to feature vectors via providers</li> <li>Action Valuation: Estimate expected utility for all available actions</li> <li>Policy Updates: Update neural network weights based on prediction errors</li> <li>Exploration Strategy: Balance exploitation with exploration using \u03b5-greedy</li> </ul> <p>Integration Features:</p> <ul> <li>Causal Rewards: Incorporates causally-adjusted rewards from CausalGraphSystem</li> <li>Emotional Modulation: Learning rates affected by emotional state</li> <li>Value Alignment: Rewards shaped by agent's personal value system</li> </ul>"},{"location":"api/agent-engine/#agent_engine.systems.q_learning_system.QLearningSystem","title":"<code>agent_engine.systems.q_learning_system.QLearningSystem</code>","text":"<p>               Bases: <code>System</code></p> <p>Manages the Q-learning process for all agents, now enhanced with causal inference.</p>"},{"location":"api/agent-engine/#agent_engine.systems.q_learning_system.QLearningSystem.on_action_executed","title":"<code>on_action_executed(event_data)</code>","text":"<p>Event handler that triggers the Q-learning update step.</p>"},{"location":"api/agent-engine/#agent_engine.systems.q_learning_system.QLearningSystem.update","title":"<code>update(current_tick)</code>  <code>async</code>","text":"<p>Caches the current state features for each active learning agent.</p>"},{"location":"api/agent-engine/#identitysystem","title":"IdentitySystem","text":"<p>Manages multi-dimensional agent identity across social, competence, moral, relational, and agency domains.</p> <p>Identity Domains:</p> <ul> <li> <p>Social Identity</p> <p>Group membership, reputation, and social standing within the community.</p> </li> <li> <p>Competence Identity</p> <p>Skills, abilities, and perceived effectiveness in various tasks.</p> </li> <li> <p>Moral Identity</p> <p>Ethical principles, values, and moral standing.</p> </li> <li> <p>Relational Identity</p> <p>Relationships with other agents and social connections.</p> </li> <li> <p>Agency Identity</p> <p>Sense of autonomy, control, and self-efficacy.</p> </li> </ul> <p>Identity Dynamics:</p> <ul> <li>Experience Integration: Update identity based on action outcomes</li> <li>Social Feedback: Incorporate reactions from other agents</li> <li>Consistency Maintenance: Resolve conflicts between identity domains</li> <li>Adaptive Flexibility: Balance stability with growth and change</li> </ul>"},{"location":"api/agent-engine/#agent_engine.systems.identity_system.IdentitySystem","title":"<code>agent_engine.systems.identity_system.IdentitySystem</code>","text":"<p>               Bases: <code>System</code></p> <p>Updates an agent's multi-domain identity based on narrative reflections. This system is event-driven, world-agnostic, and implements the identity update model.</p>"},{"location":"api/agent-engine/#agent_engine.systems.identity_system.IdentitySystem.on_reflection_completed","title":"<code>on_reflection_completed(event_data)</code>","text":"<p>Event handler that orchestrates the full identity update cycle upon receiving a completed reflection. It receives a generic context object and passes it down the chain.</p>"},{"location":"api/agent-engine/#agent_engine.systems.identity_system.IdentitySystem.update","title":"<code>update(current_tick)</code>  <code>async</code>","text":"<p>This system is purely event-driven.</p>"},{"location":"api/agent-engine/#goalsystem","title":"GoalSystem","text":"<p>Implements dynamic goal generation, prioritization, and achievement tracking.</p> <p>Goal Lifecycle:</p> <pre><code>graph LR\n    A[Goal Generation] --&gt; B[Prioritization]\n    B --&gt; C[Plan Formation]\n    C --&gt; D[Execution]\n    D --&gt; E[Progress Tracking]\n    E --&gt; F[Achievement/Adaptation]</code></pre> <p>Goal Types:</p> <ul> <li>Survival Goals: Basic needs like health, energy, and safety</li> <li>Social Goals: Relationship building, reputation, and cooperation</li> <li>Achievement Goals: Skill development, resource accumulation, and mastery</li> <li>Exploratory Goals: Curiosity-driven exploration and learning</li> </ul>"},{"location":"api/agent-engine/#agent_engine.systems.goal_system.GoalSystem","title":"<code>agent_engine.systems.goal_system.GoalSystem</code>","text":"<p>               Bases: <code>System</code></p> <p>Manages an agent's goal creation, selection, and refinement based on its experiences and reflections. This system is world-agnostic.</p>"},{"location":"api/agent-engine/#agent_engine.systems.goal_system.GoalSystem.on_update_goals_event","title":"<code>on_update_goals_event(event_data)</code>","text":"<p>Triggered after a reflection, this orchestrates the goal update cycle.</p>"},{"location":"api/agent-engine/#agent_engine.systems.goal_system.GoalSystem.update","title":"<code>update(current_tick)</code>  <code>async</code>","text":"<p>This system is purely event-driven and has no per-tick logic.</p>"},{"location":"api/agent-engine/#advanced-cognitive-features","title":"Advanced Cognitive Features","text":""},{"location":"api/agent-engine/#emotional-dynamics","title":"Emotional Dynamics","text":"<p>The AffectSystem implements sophisticated emotional modeling based on appraisal theory:</p> <pre><code># Example of emotional appraisal calculation\ndef calculate_emotion(self, event, agent_goals, agent_values):\n    \"\"\"\n    Emotion emerges from the intersection of:\n    - Goal relevance (does this matter to me?)\n    - Outcome controllability (can I influence this?)\n    - Value alignment (does this match my values?)\n    - Social context (how do others see this?)\n    \"\"\"\n\n    appraisal_scores = {\n        'goal_relevance': self._assess_goal_relevance(event, agent_goals),\n        'controllability': self._assess_controllability(event),\n        'value_alignment': self._assess_value_alignment(event, agent_values),\n        'social_approval': self._assess_social_context(event)\n    }\n\n    # Emotions emerge from specific appraisal patterns\n    if appraisal_scores['goal_relevance'] &gt; 0.7 and appraisal_scores['controllability'] &lt; 0.3:\n        return 'frustration'\n    elif appraisal_scores['value_alignment'] &gt; 0.8 and appraisal_scores['social_approval'] &gt; 0.6:\n        return 'pride'\n    # ... additional emotion patterns\n</code></pre>"},{"location":"api/agent-engine/#causal-reasoning","title":"Causal Reasoning","text":"<p>The CausalGraphSystem builds formal causal models using the DoWhy library:</p> <pre><code># Example of causal effect estimation\ndef estimate_action_effect(self, agent_id: str, action: str) -&gt; float:\n    \"\"\"\n    Estimate the causal effect of an action using do-calculus.\n\n    This answers: \"What would happen if the agent were forced\n    to take this action, controlling for confounding factors?\"\n    \"\"\"\n\n    causal_model = self._get_agent_causal_model(agent_id)\n    if not causal_model:\n        return 0.0  # Fall back to observational data\n\n    # Perform causal intervention\n    causal_effect = causal_model.estimate_effect(\n        treatment_value=action,\n        outcome='reward',\n        method='iv'  # Instrumental variables\n    )\n\n    return causal_effect.value\n</code></pre>"},{"location":"api/agent-engine/#memory-architecture","title":"Memory Architecture","text":"<p>Agents maintain multiple memory systems with different retention and access patterns:</p> <pre><code>class MemoryComponent(Component):\n    \"\"\"Multi-layered memory architecture.\"\"\"\n\n    def __init__(self):\n        # Working memory for immediate context\n        self.working_memory: List[Experience] = []\n\n        # Episodic memory for specific experiences\n        self.episodic_memory: List[Episode] = []\n\n        # Semantic memory for general knowledge\n        self.semantic_memory: Dict[str, ConceptNode] = {}\n\n        # Emotional memories with stronger retention\n        self.emotional_memories: List[EmotionalEpisode] = []\n\n        # Social memories about other agents\n        self.social_memory: Dict[str, AgentSchema] = {}\n</code></pre>"},{"location":"api/agent-engine/#system-integration-patterns","title":"System Integration Patterns","text":""},{"location":"api/agent-engine/#event-driven-communication","title":"Event-Driven Communication","text":"<p>Systems communicate exclusively through the event bus, enabling loose coupling:</p> <pre><code>class CognitivePipeline:\n    \"\"\"Example of how cognitive systems coordinate.\"\"\"\n\n    def __init__(self, event_bus):\n        self.event_bus = event_bus\n\n        # Systems subscribe to relevant events\n        self.event_bus.subscribe(\"action_executed\", self.affect_system.process_outcome)\n        self.event_bus.subscribe(\"action_executed\", self.q_learning_system.update_policy)\n        self.event_bus.subscribe(\"reflection_completed\", self.goal_system.update_goals)\n        self.event_bus.subscribe(\"identity_changed\", self.social_system.update_reputation)\n\n    async def process_agent_tick(self, agent_id: str, tick: int):\n        \"\"\"Coordinate cognitive processing for one agent.\"\"\"\n\n        # 1. Decision making\n        self.event_bus.publish(\"decision_requested\", {\n            \"agent_id\": agent_id,\n            \"tick\": tick\n        })\n\n        # 2. Action execution happens in world systems\n        # 3. Outcome processing happens automatically via subscriptions\n        # 4. Reflection triggered periodically\n\n        if tick % 50 == 0:  # Reflect every 50 ticks\n            self.event_bus.publish(\"reflection_triggered\", {\n                \"agent_id\": agent_id,\n                \"tick\": tick\n            })\n</code></pre>"},{"location":"api/agent-engine/#provider-integration","title":"Provider Integration","text":"<p>Cognitive systems access world data through provider interfaces:</p> <pre><code>class ReflectionSystem(System):\n    \"\"\"Example of provider usage in cognitive systems.\"\"\"\n\n    def __init__(self, simulation_state, config, cognitive_scaffold):\n        super().__init__(simulation_state, config, cognitive_scaffold)\n\n        # Providers injected at runtime\n        self.vitality_provider = None\n        self.narrative_provider = None\n        self.state_encoder = None\n\n    def set_providers(self, providers: Dict[str, Any]):\n        \"\"\"Dependency injection of world-specific providers.\"\"\"\n        self.vitality_provider = providers.get('vitality')\n        self.narrative_provider = providers.get('narrative')\n        self.state_encoder = providers.get('state_encoder')\n\n    async def generate_reflection(self, agent_id: str) -&gt; str:\n        \"\"\"Generate reflection using injected providers.\"\"\"\n\n        # Get agent components\n        components = self.simulation_state.get_entity_components(agent_id)\n\n        # Use providers to extract world-specific context\n        vitality = self.vitality_provider.get_normalized_vitality_metrics(\n            agent_id, components, self.config\n        )\n\n        narrative_context = self.narrative_provider.get_narrative_context(\n            agent_id, components, self.config\n        )\n\n        # Generate reflection prompt with LLM\n        reflection = await self.cognitive_scaffold.generate_reflection(\n            vitality_metrics=vitality,\n            narrative_context=narrative_context,\n            recent_experiences=self._get_recent_experiences(agent_id)\n        )\n\n        return reflection\n</code></pre>"},{"location":"api/agent-engine/#performance-and-scalability","title":"Performance and Scalability","text":""},{"location":"api/agent-engine/#concurrent-system-execution","title":"Concurrent System Execution","text":"<p>The agent-engine supports multiple execution strategies optimized for different scenarios:</p> <pre><code># High-performance async execution\nrunner = AsyncSystemRunner(systems, event_bus)\nawait runner.execute_tick(current_tick)\n\n# Deterministic serial execution for debugging\nrunner = SerialSystemRunner(systems, event_bus)\nawait runner.execute_tick(current_tick)\n\n# Hybrid execution with system priorities\nrunner = HybridSystemRunner(systems, event_bus, priorities={\n    'ActionSystem': 'sync',      # Critical path\n    'ReflectionSystem': 'async', # Can run concurrently\n    'LoggingSystem': 'background' # Low priority\n})\nawait runner.execute_tick(current_tick)\n</code></pre>"},{"location":"api/agent-engine/#memory-and-state-management","title":"Memory and State Management","text":"<ul> <li>Component Pooling: Reuse component instances to reduce allocation overhead</li> <li>Lazy Loading: Load memories and complex state only when needed</li> <li>State Compression: Compress historical data using efficient encoding</li> <li>Garbage Collection: Automatically clean up old memories and unused state</li> </ul>"},{"location":"api/agent-engine/#llm-integration-optimization","title":"LLM Integration Optimization","text":"<pre><code>class CognitiveScaffold:\n    \"\"\"Optimized LLM integration with caching and batching.\"\"\"\n\n    def __init__(self):\n        self.prompt_cache = LRUCache(maxsize=1000)\n        self.batch_queue = []\n        self.response_futures = {}\n\n    async def generate_reflection(self, **context):\n        \"\"\"Generate reflection with caching and batching.\"\"\"\n\n        # Check cache first\n        cache_key = self._hash_context(context)\n        if cache_key in self.prompt_cache:\n            return self.prompt_cache[cache_key]\n\n        # Add to batch queue\n        request_id = uuid.uuid4()\n        self.batch_queue.append({\n            'id': request_id,\n            'type': 'reflection',\n            'context': context\n        })\n\n        # Process batch when full or after timeout\n        if len(self.batch_queue) &gt;= 10:\n            await self._process_batch()\n\n        # Return future for async completion\n        future = asyncio.Future()\n        self.response_futures[request_id] = future\n        return await future\n</code></pre>"},{"location":"api/agent-engine/#testing-and-debugging","title":"Testing and Debugging","text":""},{"location":"api/agent-engine/#cognitive-system-testing","title":"Cognitive System Testing","text":"<pre><code>import pytest\nfrom unittest.mock import Mock, AsyncMock\n\nclass TestReflectionSystem:\n    \"\"\"Example test patterns for cognitive systems.\"\"\"\n\n    @pytest.fixture\n    def reflection_system(self):\n        mock_state = Mock()\n        mock_config = Mock()\n        mock_scaffold = AsyncMock()\n\n        system = ReflectionSystem(mock_state, mock_config, mock_scaffold)\n\n        # Inject mock providers\n        system.set_providers({\n            'vitality': Mock(),\n            'narrative': Mock(),\n            'state_encoder': Mock()\n        })\n\n        return system\n\n    async def test_reflection_generation(self, reflection_system):\n        \"\"\"Test reflection generation with mocked dependencies.\"\"\"\n\n        # Setup mock responses\n        reflection_system.vitality_provider.get_normalized_vitality_metrics.return_value = {\n            'health_norm': 0.8,\n            'energy_norm': 0.6\n        }\n\n        reflection_system.narrative_provider.get_narrative_context.return_value = {\n            'recent_events': ['Won a battle', 'Found treasure'],\n            'social_context': 'Respected by peers'\n        }\n\n        # Test reflection generation\n        reflection = await reflection_system.generate_reflection(\"test_agent\")\n\n        assert reflection is not None\n        assert isinstance(reflection, str)\n</code></pre>"},{"location":"api/agent-engine/#system-integration-testing","title":"System Integration Testing","text":"<pre><code>async def test_cognitive_pipeline_integration():\n    \"\"\"Test full cognitive pipeline with multiple systems.\"\"\"\n\n    # Setup simulation environment\n    manager = SimulationManager(test_config)\n    manager.register_system(ActionSystem)\n    manager.register_system(ReflectionSystem)\n    manager.register_system(GoalSystem)\n    manager.register_system(QLearningSystem)\n\n    # Create test agent with required components\n    agent_id = \"test_agent\"\n    manager.simulation_state.add_component(agent_id, MemoryComponent())\n    manager.simulation_state.add_component(agent_id, IdentityComponent())\n    manager.simulation_state.add_component(agent_id, GoalComponent())\n\n    # Run simulation for several ticks\n    for tick in range(10):\n        await manager.run_tick(tick)\n\n    # Verify cognitive state updates\n    memory_comp = manager.simulation_state.get_component(agent_id, MemoryComponent)\n    assert len(memory_comp.episodic_memory) &gt; 0\n\n    goal_comp = manager.simulation_state.get_component(agent_id, GoalComponent)\n    assert len(goal_comp.active_goals) &gt; 0\n</code></pre> <p>The agent-engine provides a sophisticated yet modular cognitive architecture that can be adapted for a wide range of simulation scenarios while maintaining high performance and extensibility.</p>"},{"location":"architecture/","title":"ARLA Architecture","text":"<p>The ARLA framework is engineered for modularity and extensibility, enabling the construction of sophisticated agent-based simulations with cognitively rich behaviors. At its core, the architecture leverages the Entity Component System (ECS) pattern to enforce strict separation between data and logic, fostering rapid experimentation and research.</p> <p>Design Philosophy</p> <p>ARLA's architecture prioritizes modularity, performance, and research reproducibility. Every design decision supports the ability to isolate, test, and modify individual cognitive components without affecting the broader system.</p>"},{"location":"architecture/#core-architectural-principles","title":"Core Architectural Principles","text":""},{"location":"architecture/#data-oriented-design","title":"Data-Oriented Design","text":"<p>At the heart of ARLA is the ECS pattern, which provides clear separation of concerns:</p> <ul> <li> <p>Entities</p> <p>Unique identifiers representing agents or environmental objects. Think of them as database primary keys.</p> </li> <li> <p>Components</p> <p>Pure data structures containing an agent's state (memory, health, position). No logic allowed.</p> </li> <li> <p>Systems</p> <p>All operational logic that processes entities with specific component combinations.</p> </li> </ul> <p>This separation makes simulation state transparent, easy to debug, and simple to serialize for analysis.</p>"},{"location":"architecture/#asynchronous-concurrency","title":"Asynchronous Concurrency","text":"<p>All systems are designed to be non-blocking and execute concurrently via an asynchronous scheduler. This architecture is critical for performance, especially when integrating I/O-bound operations like Large Language Model calls.</p> <p>Benefits:</p> <ul> <li>Scalability: Handle thousands of agents with concurrent system execution</li> <li>Responsiveness: Non-blocking LLM calls don't freeze the simulation</li> <li>Flexibility: Switch between async and deterministic execution modes</li> </ul>"},{"location":"architecture/#decoupled-communication","title":"Decoupled Communication","text":"<p>Systems operate in isolation and communicate indirectly through a central Event Bus. This event-driven approach ensures new functionality can be added without modifying existing systems.</p> <pre><code>graph TD\n    A[System A] --&gt; B[Event Bus]\n    C[System B] --&gt; B\n    D[System C] --&gt; B\n    B --&gt; E[System D]\n    B --&gt; F[System E]\n    B --&gt; G[System F]</code></pre> <p>Event Flow Example: * ActionSystem publishes \"action_executed\" events * ReflectionSystem, QLearningSystem, and IdentitySystem all subscribe * Each processes the event independently without knowing about the others</p>"},{"location":"architecture/#world-agnostic-engine","title":"World-Agnostic Engine","text":"<p>The agent-engine is fundamentally agnostic to the rules of any specific simulation. World-specific logic\u2014such as physics, valid actions, or environmental interactions\u2014is injected through clearly defined provider interfaces.</p> <p>Architecture Benefits:</p> <ul> <li>Reusability: Same cognitive engine works across different simulation worlds</li> <li>Testability: Mock providers enable isolated testing of cognitive systems</li> <li>Modularity: Swap world implementations without changing agent logic</li> </ul>"},{"location":"architecture/#high-level-architecture","title":"High-Level Architecture","text":"<p>The diagram below illustrates the data flow and control between ARLA's primary architectural layers:</p> <pre><code>graph TB\n    subgraph \"Simulation Layer (e.g., soul_sim)\"\n        A[World-Specific Systems &amp; Components]\n        B[Action Implementations]\n        C[Provider Implementations]\n        D[Scenario Configuration]\n    end\n\n    subgraph \"Core Engine (agent-engine)\"\n        E[Simulation Manager] --&gt; F{Main Loop}\n        F --&gt; G[System Manager]\n        G --&gt; H[Event Bus]\n        G --&gt; I[Async System Runner]\n        I --&gt; J[Cognitive Systems]\n        J --&gt; K[Reflection System]\n        J --&gt; L[Q-Learning System]\n        J --&gt; M[Identity System]\n        J --&gt; N[Goal System]\n        H &lt;--&gt; J\n    end\n\n    subgraph \"Core Abstractions (agent-core)\"\n        O[Simulation State] --&gt; P[Entities &amp; Components]\n        Q[Action Interfaces]\n        R[Provider Interfaces]\n        S[System Base Classes]\n    end\n\n    subgraph \"Infrastructure\"\n        T[Database Layer]\n        U[MLflow Tracking]\n        V[Configuration Management]\n    end\n\n    A --&gt; O\n    B --&gt; Q\n    C --&gt; R\n    D --&gt; V\n    J --&gt; O\n    E --&gt; T\n    E --&gt; U\n\n    style E fill:#e1f5fe,stroke:#01579b,stroke-width:2px\n    style O fill:#f3e5f5,stroke:#4a148c,stroke-width:2px\n    style H fill:#fff3e0,stroke:#e65100,stroke-width:2px</code></pre> <p>Layer Responsibilities:</p> <ul> <li>Simulation Layer: World-specific implementations and configurations</li> <li>Core Engine: Cognitive architecture and simulation orchestration</li> <li>Core Abstractions: Framework contracts and base implementations</li> <li>Infrastructure: Data persistence, experiment tracking, and configuration</li> </ul>"},{"location":"architecture/#cognitive-architecture-components","title":"Cognitive Architecture Components","text":"<p>ARLA implements a comprehensive cognitive architecture inspired by theories from psychology and cognitive science.</p>"},{"location":"architecture/#memory-systems","title":"Memory Systems","text":"<p>Agents maintain multiple memory types with different characteristics:</p> <pre><code>graph LR\n    A[Working Memory] --&gt; B[Episodic Memory]\n    B --&gt; C[Semantic Memory]\n    D[Emotional Memory] --&gt; B\n    E[Social Memory] --&gt; B\n\n    subgraph \"Retention Characteristics\"\n        F[Short-term: 5-10 experiences]\n        G[Medium-term: 100s of episodes]\n        H[Long-term: Consolidated knowledge]\n        I[Enhanced: Emotionally significant]\n        J[Relationship: Agent interactions]\n    end\n\n    A -.-&gt; F\n    B -.-&gt; G\n    C -.-&gt; H\n    D -.-&gt; I\n    E -.-&gt; J</code></pre>"},{"location":"architecture/#decision-making-pipeline","title":"Decision-Making Pipeline","text":"<p>The cognitive decision-making process follows a sophisticated multi-stage pipeline:</p> <pre><code>graph TD\n    A[Perception] --&gt; B[Working Memory Update]\n    B --&gt; C[Goal Activation]\n    C --&gt; D[Action Generation]\n    D --&gt; E[Utility Estimation]\n    E --&gt; F[Action Selection]\n    F --&gt; G[Execution]\n    G --&gt; H[Outcome Evaluation]\n    H --&gt; I[Learning Update]\n    I --&gt; J[Memory Consolidation]\n\n    subgraph \"Cognitive Modulation\"\n        K[Emotional State]\n        L[Identity Consistency]\n        M[Social Context]\n    end\n\n    K --&gt; E\n    L --&gt; F\n    M --&gt; D</code></pre>"},{"location":"architecture/#emotional-dynamics","title":"Emotional Dynamics","text":"<p>Emotions emerge from appraisal patterns based on established psychological theory:</p> <ul> <li> <p>Goal Relevance</p> <p>How much does this event matter to the agent's current objectives?</p> </li> <li> <p>Controllability</p> <p>Can the agent influence the outcome of this situation?</p> </li> <li> <p>Value Alignment</p> <p>Does this event align with the agent's core values and beliefs?</p> </li> <li> <p>Social Approval</p> <p>How do other agents perceive this event and the agent's role in it?</p> </li> </ul> <p>Emotion-Cognition Integration:</p> <ul> <li>Attention: Emotional salience affects what agents notice and remember</li> <li>Learning: Emotional states modulate learning rates and generalization</li> <li>Decision-Making: Current mood influences risk-taking and cooperation</li> <li>Memory: Emotional experiences receive enhanced consolidation</li> </ul>"},{"location":"architecture/#system-integration-patterns","title":"System Integration Patterns","text":""},{"location":"architecture/#provider-pattern-implementation","title":"Provider Pattern Implementation","text":"<p>The provider pattern enables world-agnostic cognitive systems to access world-specific data:</p> <pre><code># World-agnostic cognitive system\nclass ReflectionSystem(System):\n    def __init__(self, simulation_state, config, cognitive_scaffold):\n        super().__init__(simulation_state, config, cognitive_scaffold)\n        self.vitality_provider = None  # Injected at runtime\n\n    def reflect_on_experience(self, agent_id: str) -&gt; str:\n        # Use provider to get world-specific context\n        vitality_data = self.vitality_provider.get_normalized_vitality_metrics(\n            agent_id, components, config\n        )\n        # Generate reflection using world-agnostic logic + world-specific data\n        return self._generate_reflection(vitality_data)\n\n# World-specific provider implementation\nclass FantasyWorldVitalityProvider(VitalityMetricsProviderInterface):\n    def get_normalized_vitality_metrics(self, entity_id, components, config):\n        health = components.get(HealthComponent)\n        mana = components.get(ManaComponent)\n        stamina = components.get(StaminaComponent)\n\n        return {\n            \"physical_health\": health.current / health.maximum,\n            \"magical_energy\": mana.current / mana.maximum,\n            \"physical_endurance\": stamina.current / stamina.maximum\n        }\n</code></pre>"},{"location":"architecture/#event-driven-state-management","title":"Event-Driven State Management","text":"<p>All state changes flow through the event bus, creating an auditable trail:</p> <pre><code>sequenceDiagram\n    participant Agent\n    participant ActionSystem\n    participant WorldSystem\n    participant CognitiveSystem\n    participant EventBus\n\n    Agent-&gt;&gt;ActionSystem: Choose Action\n    ActionSystem-&gt;&gt;EventBus: Publish \"action_chosen\"\n    EventBus-&gt;&gt;WorldSystem: Notify action execution\n    WorldSystem-&gt;&gt;EventBus: Publish \"action_outcome\"\n    EventBus-&gt;&gt;CognitiveSystem: Update learning\n    EventBus-&gt;&gt;ActionSystem: Calculate final reward\n    ActionSystem-&gt;&gt;EventBus: Publish \"action_completed\"</code></pre>"},{"location":"architecture/#concurrent-system-execution","title":"Concurrent System Execution","text":"<p>Systems execute concurrently while maintaining data consistency:</p> <pre><code>async def execute_simulation_tick(self, tick: int):\n    \"\"\"Execute one simulation tick with concurrent systems.\"\"\"\n\n    # Phase 1: Perception and decision-making (can run concurrently)\n    decision_tasks = [\n        self.perception_system.update(tick),\n        self.goal_system.update(tick),\n        self.decision_system.update(tick)\n    ]\n    await asyncio.gather(*decision_tasks)\n\n    # Phase 2: Action execution (sequential for determinism)\n    await self.action_system.update(tick)\n\n    # Phase 3: World updates (can run concurrently)\n    world_tasks = [\n        self.movement_system.update(tick),\n        self.combat_system.update(tick),\n        self.environment_system.update(tick)\n    ]\n    await asyncio.gather(*world_tasks)\n\n    # Phase 4: Learning and reflection (can run concurrently)\n    learning_tasks = [\n        self.q_learning_system.update(tick),\n        self.reflection_system.update(tick),\n        self.identity_system.update(tick)\n    ]\n    await asyncio.gather(*learning_tasks)\n</code></pre>"},{"location":"architecture/#performance-considerations","title":"Performance Considerations","text":""},{"location":"architecture/#scalability-architecture","title":"Scalability Architecture","text":"<p>ARLA is designed to scale from single-agent studies to large population simulations:</p> <p>Agent Scaling: - 1-100 agents: Single-threaded execution with full cognitive features - 100-1,000 agents: Concurrent system execution with selective cognitive features - 1,000+ agents: Distributed execution with cognitive feature batching</p> <p>Memory Management: - Component pooling to reduce allocation overhead - Lazy loading of memory and historical data - Automatic garbage collection of old experiences</p>"},{"location":"architecture/#llm-integration-optimization","title":"LLM Integration Optimization","text":"<p>Large Language Model calls are the primary performance bottleneck, addressed through:</p> <p>Caching Strategies: - Prompt caching for repeated reflection patterns - Response caching for similar contexts - Semantic similarity matching for near-duplicates</p> <p>Batching Mechanisms: - Batch multiple agent reflections into single API calls - Priority queuing for time-sensitive operations - Background processing for non-critical reflections</p> <p>Cost Management: - Token usage monitoring and budget enforcement - Adaptive reflection frequency based on available budget - Fallback to rule-based reasoning when LLM unavailable</p>"},{"location":"architecture/#research-applications","title":"Research Applications","text":""},{"location":"architecture/#ablation-studies","title":"Ablation Studies","text":"<p>ARLA's modular architecture enables precise ablation studies:</p> <pre><code># Study the effect of identity on cooperation\nconfigs = [\n    {\"systems\": [\"ActionSystem\", \"QLearningSystem\", \"IdentitySystem\"]},\n    {\"systems\": [\"ActionSystem\", \"QLearningSystem\"]},  # No identity\n]\n\n# Study the effect of emotion on decision-making\nconfigs = [\n    {\"affect_system\": {\"enabled\": True}},\n    {\"affect_system\": {\"enabled\": False}},  # No emotions\n]\n\n# Study the effect of causal reasoning on learning\nconfigs = [\n    {\"q_learning\": {\"use_causal_rewards\": True}},\n    {\"q_learning\": {\"use_causal_rewards\": False}},  # Raw rewards only\n]\n</code></pre>"},{"location":"architecture/#emergent-behavior-studies","title":"Emergent Behavior Studies","text":"<p>The architecture supports studying emergence at multiple levels:</p> <ul> <li>Individual: How do cognitive components interact to produce behavior?</li> <li>Dyadic: How do pairs of agents develop relationships and cooperation?</li> <li>Group: How do social norms and hierarchies emerge in populations?</li> <li>Population: How do cultural patterns and institutions develop over time?</li> </ul>"},{"location":"architecture/#reproducibility-features","title":"Reproducibility Features","text":"<p>Research reproducibility is built into the architecture:</p> <ul> <li>Deterministic Execution: Exact reproduction with identical random seeds</li> <li>Configuration Versioning: Git-tracked configuration with validation</li> <li>State Snapshots: Complete simulation state capture at any point</li> <li>Experiment Tracking: Automatic logging of hyperparameters and results</li> </ul>"},{"location":"architecture/#extension-points","title":"Extension Points","text":""},{"location":"architecture/#adding-new-cognitive-systems","title":"Adding New Cognitive Systems","text":"<p>Create custom cognitive capabilities by extending the System base class:</p> <pre><code>class CreativitySystem(System):\n    \"\"\"Custom system for modeling creative problem-solving.\"\"\"\n\n    def __init__(self, simulation_state, config, cognitive_scaffold):\n        super().__init__(simulation_state, config, cognitive_scaffold)\n\n        if self.event_bus:\n            self.event_bus.subscribe(\"problem_encountered\", self.generate_creative_solution)\n\n    async def generate_creative_solution(self, event_data):\n        # Custom creative reasoning logic\n        pass\n</code></pre>"},{"location":"architecture/#creating-new-provider-interfaces","title":"Creating New Provider Interfaces","text":"<p>Define domain-specific data access patterns:</p> <pre><code>class CreativityContextProviderInterface(ABC):\n    \"\"\"Interface for providing creativity-relevant context.\"\"\"\n\n    @abstractmethod\n    def get_creative_resources(self, entity_id: str, components: Dict, config: Dict) -&gt; Dict[str, Any]:\n        \"\"\"Return available creative resources and constraints.\"\"\"\n        pass\n\n    @abstractmethod\n    def get_inspiration_sources(self, entity_id: str, components: Dict, config: Dict) -&gt; List[str]:\n        \"\"\"Return potential sources of creative inspiration.\"\"\"\n        pass\n</code></pre>"},{"location":"architecture/#world-integration","title":"World Integration","text":"<p>Integrate ARLA with existing simulation environments:</p> <pre><code>class ExternalWorldAdapter:\n    \"\"\"Adapter pattern for integrating external simulation engines.\"\"\"\n\n    def __init__(self, external_sim, arla_simulation_state):\n        self.external_sim = external_sim\n        self.arla_state = arla_simulation_state\n\n    async def sync_states(self):\n        \"\"\"Synchronize state between ARLA and external simulation.\"\"\"\n\n        # Extract state from external simulation\n        external_entities = self.external_sim.get_all_entities()\n\n        # Update ARLA components\n        for entity_id, external_state in external_entities.items():\n            self._update_arla_components(entity_id, external_state)\n\n    def _update_arla_components(self, entity_id: str, external_state: dict):\n        \"\"\"Convert external state to ARLA components.\"\"\"\n\n        # Convert position\n        if \"position\" in external_state:\n            pos_comp = PositionComponent(\n                x=external_state[\"position\"][\"x\"],\n                y=external_state[\"position\"][\"y\"]\n            )\n            self.arla_state.add_component(entity_id, pos_comp)\n\n        # Convert health\n        if \"health\" in external_state:\n            health_comp = HealthComponent(\n                current_health=external_state[\"health\"][\"current\"],\n                max_health=external_state[\"health\"][\"maximum\"]\n            )\n            self.arla_state.add_component(entity_id, health_comp)\n</code></pre> <p>ARLA's architecture provides a robust foundation for agent-based modeling research while maintaining the flexibility needed for diverse simulation scenarios and experimental designs.</p>"},{"location":"blog/","title":"ARLA Development Blog","text":"<p>Welcome to the ARLA dev blog! This is the place to find the latest news, announcements, and in-depth articles about the ARLA framework.</p>"},{"location":"blog/2025/08/21/from-schelling-to-psyche-a-technical-look-at-validating-arla/","title":"From Schelling to Psyche: A Technical Look at Validating ARLA","text":"<p>Welcome back to the ARLA Development Blog! In our first post, we introduced our vision for a modular framework for building cognitively rich agents. Today, we're diving into the code to show how we're building and validating this platform, starting with a classic: the Schelling Segregation Model.</p> <p>This isn't just an academic exercise. It's a critical, two-phase process to build a robust foundation for groundbreaking research. First, we implement a simple version to serve as a \"smoke test.\" In later posts, we will use that stable baseline to conduct sophisticated ablative studies on complex cognitive features.</p>"},{"location":"blog/2025/08/21/from-schelling-to-psyche-a-technical-look-at-validating-arla/#phase-1-the-baseline-a-rule-based-schelling-model","title":"Phase 1: The Baseline - A Rule-Based Schelling Model","text":"<p>Before we can trust our advanced cognitive systems, we must verify that the basic mechanics of the engine\u2014state management, action execution, and system updates\u2014are working correctly. The Schelling model is perfect for this because its outcome is well-understood.</p> <p>Our baseline implementation is purely rule-based and relies on three key world-specific components.</p> <p><code>PositionComponent</code>: Stores the agent's <code>(x, y)</code> coordinates.</p> <p><code>GroupComponent</code>: Assigns the agent's type (e.g., group <code>1</code> or <code>2</code>).</p> <p><code>SatisfactionComponent</code>: A simple data container that holds the agent's satisfaction threshold and its current state.</p> simulations/schelling_sim/components.py<pre><code>class SatisfactionComponent(Component):\n    \"\"\"Stores an agent's satisfaction state and threshold.\"\"\"\n\n    def __init__(self, satisfaction_threshold: float) -&gt; None:\n        self.satisfaction_threshold = satisfaction_threshold\n        self.is_satisfied: bool = False\n\n    # ... to_dict() and validate() methods ...\n</code></pre> <p>With these components in place, the logic is driven by two simple, world-specific systems:</p> <p><code>SatisfactionSystem</code>: On every tick, this system iterates through all agents. It checks an agent's neighbors and updates the <code>is_satisfied</code> flag in its <code>SatisfactionComponent</code> based on whether the ratio of same-type neighbors meets its threshold.</p> simulations/schelling_sim/systems.py<pre><code># Inside SatisfactionSystem.update()\nfor _, components in all_agents.items():\n    # ... get components ...\n    neighbors = env.get_neighbors_of_position(pos_comp.position)\n    if len(neighbors) == 0:\n        satisfaction_comp.is_satisfied = True\n        continue\n\n    same_type_neighbors = 0\n    for neighbor_id in neighbors.values():\n        # ... count same-type neighbors ...\n\n    satisfaction_ratio = same_type_neighbors / len(neighbors)\n    satisfaction_comp.is_satisfied = satisfaction_ratio &gt;= satisfaction_comp.satisfaction_threshold\n</code></pre> <p><code>MovementSystem</code>: This system subscribes to the <code>execute_move_to_empty_cell_action</code> event. When triggered, it handles the logic of updating the agent's <code>PositionComponent</code> and moving the agent within the <code>SchellingGridEnvironment</code>.</p> <p>This setup establishes our control group. The behavior is simple, deterministic, and verifiable.</p> <p>And as expected, we see that the agents start with a low <code>satisfaction_rate</code> and explore until they meet an equilibrium at around 100% satisfaction. We also see the segregation_index starting near <code>1.0</code>\u2014a randomly mixed population\u2014and dropping to around <code>0.5</code> as the agents move and the population becomes more segregated.</p> <p></p>"},{"location":"blog/2025/08/21/from-schelling-to-psyche-a-technical-look-at-validating-arla/#phase-2-the-frontier-of-cognitive-ablation","title":"Phase 2: The Frontier of Cognitive Ablation","text":"<p>With a validated baseline, we can now use the Schelling model as a laboratory for cognitive science. ARLA's architecture allows us to layer on advanced, world-agnostic cognitive systems from agent-engine and precisely measure their effects. This is the core of ablative analysis.</p>"},{"location":"blog/2025/08/21/from-schelling-to-psyche-a-technical-look-at-validating-arla/#experiment-1-adding-subjective-rewards","title":"Experiment 1: Adding Subjective Rewards","text":"<p>Instead of a fixed reward for moving, what if the reward was subjective, influenced by the agent's emotional state? We can test this by enabling the <code>AffectSystem</code> and modifying our world's <code>RewardCalculator</code>.</p> <p>The <code>ActionSystem</code> uses a dependency-injected <code>RewardCalculator</code> to determine the final reward for any action. We can create a custom calculator that accesses the agent's <code>EmotionComponent</code> and modifies the reward based on its emotional valence.</p> <pre><code># A hypothetical RewardCalculator for an advanced study\n\nclass EmotionModulatedRewardCalculator(RewardCalculatorInterface):\n    def calculate_final_reward(self, base_reward, ..., entity_components):\n        emotion_comp = entity_components.get(EmotionComponent)\n\n        # If the agent is feeling positive (high valence), it gets a bigger reward\n        # for taking an action that aligns with its goals.\n        if emotion_comp and emotion_comp.valence &gt; 0.5:\n            final_reward = base_reward * (1 + emotion_comp.valence)\n        else:\n            final_reward = base_reward\n\n        # ... return final_reward and breakdown ...\n</code></pre> <p>By running the simulation with and without this emotional modulation, we can quantitatively measure how an agent's internal affective state influences the emergent segregation pattern.</p>"},{"location":"blog/2025/08/21/from-schelling-to-psyche-a-technical-look-at-validating-arla/#experiment-2-causal-reasoning-vs-simple-rules","title":"Experiment 2: Causal Reasoning vs. Simple Rules","text":"<p>In the baseline model, agents are unhappy simply because of the ratio of their neighbors. But what if the true cause of unhappiness in a dense simulation is the lack of open space?</p> <p>By enabling the <code>CausalGraphSystem</code>, agents can build a formal causal model from their experiences. The <code>QLearningSystem</code> can then use this model to get a more robust learning signal that moves beyond simple correlation.</p> <pre><code># In the QLearningSystem...\n\n# Instead of just using the observed reward from the environment...\nfinal_learning_reward = action_outcome.reward\n\n# The system can query the agent's own causal model to find the \"true\" effect\n# of its action, controlling for confounding factors.\ncausal_reward_estimate = self.causal_graph_system.estimate_causal_effect(\n    agent_id=entity_id, treatment_value=action_plan.action_type.action_id\n)\n\n# It then blends the two to create a more robust learning signal\nif causal_reward_estimate is not None:\n    final_learning_reward = 0.5 * action_outcome.reward + 0.5 * causal_reward_estimate\n</code></pre> <p>This allows us to test a fascinating hypothesis: Can agents with a causal reasoning module learn to overcome their innate biases and discover a more optimal, less-segregated settlement pattern?</p>"},{"location":"blog/2025/08/21/from-schelling-to-psyche-a-technical-look-at-validating-arla/#your-turn-to-experiment","title":"Your Turn to Experiment","text":"<p>This two-phase approach\u2014validate with classics, then innovate with cognitive layers\u2014is central to ARLA's design. The Schelling simulation, now part of the codebase, is the first of many such testbeds.</p> <p>We encourage you to dive into the code yourself. The full implementation can be found in the <code>simulations/schelling_sim/</code> directory. Clone the repository, run the experiment, and start tinkering. What happens if you change the satisfaction threshold? What other cognitive systems could influence this classic model?</p> <p>This is just the beginning, and we can't wait to see what you build.</p>"},{"location":"blog/2025/08/23/can-ai-tell-why-probing-causal-reasoning-in-arla/","title":"Can AI Tell \"Why?\": Probing Causal Reasoning in ARLA","text":"<p>Welcome back to the ARLA Development Blog! In our last post, we used the classic Schelling Model as a \"smoke test\" to validate our engine's core mechanics. With that foundation in place, we can now ask deeper questions. Can we build agents that move beyond simple pattern matching to understand true cause and effect?</p> <p>To find out, we designed the Berry Toxicity Experiment. The intuition is simple. Imagine you're playing a video game and you learn that blue potions give you health. You'd drink every one you see. But what if the game suddenly changes the rules halfway through? Now, blue potions are poisonous, but only when you're standing near water. A simple bot might keep drinking them and fail, but a truly intelligent player would notice the new pattern and figure out the new, more complex rule. That's exactly what we're testing here: can our AI agents be the smart player?</p> <p>This is a challenging A/B test where survival depends on an agent's ability to learn these complex, contextual rules and adapt to a sudden environmental change.</p>"},{"location":"blog/2025/08/23/can-ai-tell-why-probing-causal-reasoning-in-arla/#phase-1-the-baseline-a-blind-heuristic-forager","title":"Phase 1: The Baseline - A \"Blind\" Heuristic Forager","text":"<p>Our control group is the Baseline-Heuristic-Agent. Its strategy is simple and hardcoded: find the closest visible berry and move towards it. However, the environment has a trick up its sleeve:</p> <p>The Test: At step 1000, blue berries, which were previously safe, become toxic\u2014but only when they are near water.</p> <p>The baseline agent's logic is straightforward, relying on direct access to the environment's state to find its target.</p> <pre><code>class BerryDecisionSelector(DecisionSelectorInterface):\n    \"\"\"A simple heuristic policy for the baseline agent.\"\"\"\n    def select(self, sim_state, entity_id, possible_actions):\n        # ...\n        # This agent has \"perfect vision\" into the environment\n        for berry_pos in env.berry_locations.keys():\n            # Find the closest berry and move towards it\n            # ...\n</code></pre> <p>As expected, this simple agent performs well until the rules change. The MLflow results for the baseline agent show a predictable and catastrophic failure to adapt.</p> <p>At step 1000, the <code>average_agent_health</code> plummets, leading to a sharp drop in <code>active_agents</code>. The <code>causal_understanding_score</code> flatlines near zero, proving the agent failed to learn the new rule.</p> <p></p>"},{"location":"blog/2025/08/23/can-ai-tell-why-probing-causal-reasoning-in-arla/#phase-2-the-causal-agent-learning-to-see","title":"Phase 2: The Causal Agent - Learning to See","text":"<p>Our experimental group is the Causal-QLearning-Agent. It uses a sophisticated Q-learning model to make decisions. Crucially, we gave this agent \"senses\" by equipping it with a <code>PerceptionComponent</code> and a more advanced state encoder.</p> <p>Instead of being blind, its \"brain\" now receives a rich feature vector describing its surroundings.</p> <pre><code>class BerryStateEncoder(StateEncoderInterface):\n    def encode_state(self, sim_state, entity_id, config):\n        \"\"\"\n        Creates a feature vector including agent vitals and sensory data.\n        \"\"\"\n        # ... (agent's own x, y, and health)\n        agent_state_vector = [agent_x, agent_y, health]\n\n        # NEW: Sensory data about the nearest visible berries\n        perception_vector = []\n        for berry_type in [\"red\", \"blue\", \"yellow\"]:\n            # ... find nearest berry of this type ...\n            if berry_data:\n                # Add normalized distance and angle to the feature vector\n                dist = berry_data[\"distance\"] / vision_range\n                angle = math.atan2(dy, dx) / math.pi\n                perception_vector.extend([dist, angle])\n            else:\n                # Use default values if no berry is seen\n                perception_vector.extend([1.0, 0.0])\n\n        return np.array(agent_state_vector + perception_vector)\n</code></pre> <p>At step 1000, the <code>average_agent_health</code> falls then recovers and is not enough to kill off as many agents <code>active_agents</code>. The <code>causal_understanding_score</code> spikes then remains higher-roughly 2X higher than our baseline agents-proving the agent failed to learn the new rule.</p> <p></p>"},{"location":"blog/2025/08/23/can-ai-tell-why-probing-causal-reasoning-in-arla/#the-ab-test-a-clear-winner","title":"The A/B Test: A Clear Winner","text":"<p>The results are conclusive.</p> <pre><code>--- A/B Test Statistical Analysis ---\n\n\ud83d\udccb Group Averages (Final Health):\n  - Causal Agent: 95.82\n  - Baseline Agent: 90.25\n\n\ud83d\udd2c T-Test Results:\n  - T-Statistic: 3.1675\n  - P-Value: 0.0344\n\n\ud83d\udca1 Conclusion:\n  The p-value (0.0344) is less than our significance level (0.05).\n  \u2705 We can conclude that there is a **statistically significant** difference\n     in the average final health between the two agent types.\n</code></pre> <p>This isn't just a fluke; the data proves that the Causal Agent's ability to learn and adapt provides a real, measurable survival advantage. The visual evidence from the MLflow graphs supports this statistical conclusion perfectly.</p> <p>Successful Adaptation: The <code>causal_understanding_score</code> for the Causal Agent spikes to nearly 1.0, proving it successfully learned the new, complex rule about blue berries and water.</p> <p>Damage Mitigation: The <code>average_agent_health</code> shows only a minor dip before recovering, as the agent quickly stops eating the toxic berries.</p> <p>Dramatically Higher Survival: Most importantly, the <code>active_agents</code> graph shows minimal or zero population loss. The Causal Agent learned to survive where the baseline agent perished.</p>"},{"location":"blog/2025/08/23/can-ai-tell-why-probing-causal-reasoning-in-arla/#your-turn-to-experiment","title":"Your Turn to Experiment","text":"<p>This experiment highlights a core principle of AI: a sophisticated brain is useless without the right sensory information. By engineering a better state representation, we enabled our learning agent to understand its world and thrive.</p> <p>The full implementation is available in the simulations/berry_sim/ directory. We encourage you to run the experiment yourself and try to improve on our results. Can you design an even better state representation? What other cognitive systems could help the agent learn faster or more reliably?</p> <pre><code># Run the full A/B test yourself!\nmake run FILE=simulations/berry_sim/experiments/causal_ab_test.yml WORKERS=8\n</code></pre> <p>You can check the ongoing metrics at http://localhost:5001/</p> <p>And when the simulation is complete, you can run the A/B test like so: <pre><code>docker compose exec app poetry run python simulations/berry_sim/analysis/analyze_ab_test.py\n</code></pre></p> <p>This successful validation opens the door to even more complex research. Now that we have agents who can understand their world, our next post will explore whether they can learn to communicate with each other about it.</p>"},{"location":"blog/2025/08/18/welcome-to-the-arla-development-blog/","title":"Welcome to the ARLA Development Blog!","text":"<p>Welcome to the official development blog for the ARLA Framework! We are incredibly excited to launch this project and share it with the community of researchers, developers, and enthusiasts in the field of agent-based modeling and artificial life.</p>"},{"location":"blog/2025/08/18/welcome-to-the-arla-development-blog/#our-vision-for-arla","title":"Our Vision for ARLA","text":"<p>Our goal with ARLA is to provide a powerful, flexible, and high-performance framework for building simulations with cognitively rich agents. We believe that by combining the proven Entity Component System (ECS) pattern with modern, asynchronous Python, we can enable a new generation of complex, emergent simulations that were previously out of reach.</p>"},{"location":"blog/2025/08/18/welcome-to-the-arla-development-blog/#what-to-expect-here","title":"What to Expect Here","text":"<p>This blog will be our primary channel for communicating with the ARLA community. Here's what you can look forward to:</p> <ul> <li>Development Updates: Get the latest news on new features, performance improvements, and bug fixes.</li> <li>In-Depth Tutorials: We'll post deep dives into advanced topics, like creating custom cognitive models or integrating new machine learning libraries.</li> <li>Community Spotlights: We want to showcase the amazing simulations and research that you create with ARLA.</li> <li>Release Announcements: Be the first to know when new versions of the ARLA framework are released.</li> </ul>"},{"location":"blog/2025/08/18/welcome-to-the-arla-development-blog/#get-involved","title":"Get Involved!","text":"<p>ARLA is an open-source project, and we welcome contributions from everyone. Whether you're interested in fixing a bug, adding a new feature, or improving the documentation, we encourage you to check out our Contributor's Guide and get involved.</p> <p>We can't wait to see what you'll build.</p> <p>\u2014 The ARLA Team</p>"},{"location":"cognition/causal_reasoning/","title":"Formal Causal Reasoning in the ARLA Framework","text":"<p>This document outlines the formal causal reasoning engine implemented in the ARLA framework, which replaces the previous correlation-based CausalGraphSystem.</p>"},{"location":"cognition/causal_reasoning/#1-the-why-moving-beyond-correlation","title":"1. The \"Why\": Moving Beyond Correlation","text":"<p>The original CausalGraphSystem was effective at identifying which events or states were correlated with positive or negative outcomes. However, correlation is not causation. An agent might learn that being near a \"Danger\" sign is associated with a negative reward, but it couldn't distinguish between two possibilities:</p> <ol> <li>The sign itself is harmless, but it happens to be located near a cliff that causes the negative reward (confounding).</li> <li>The sign is a trap that directly causes the negative reward.</li> </ol> <p>To build more intelligent and robust agents, we need a system that can understand true cause-and-effect relationships. This allows an agent to learn the real consequences of its actions, leading to better decision-making.</p>"},{"location":"cognition/causal_reasoning/#2-the-how-integration-with-dowhy","title":"2. The \"How\": Integration with DoWhy","text":"<p>We have integrated the <code>dowhy</code> library, a powerful tool for causal inference, to build and analyze formal causal models for each agent.</p>"},{"location":"cognition/causal_reasoning/#data-collection","title":"Data Collection","text":"<ul> <li>The <code>ActionSystem</code> now attaches a unique <code>event_id</code> to every action's outcome.</li> <li>The <code>CausalGraphSystem</code> listens for <code>action_executed</code> events. For each event, it logs a structured record <code>(event_id, pre-action_state, action, outcome)</code> to a list within the agent's <code>MemoryComponent</code>.</li> </ul>"},{"location":"cognition/causal_reasoning/#causal-model-construction","title":"Causal Model Construction","text":"<ul> <li>Periodically (e.g., every 50 ticks), the <code>CausalGraphSystem</code> takes the collected data from an agent's <code>MemoryComponent</code> and constructs a <code>dowhy.CausalModel</code>.</li> <li>This model is built using a predefined causal graph, which represents our domain knowledge about how variables in the simulation are related. For example, we assume that an agent's state influences its choice of action, and that both the state and the action can influence the outcome.</li> <li>The constructed <code>CausalModel</code> is then stored back in the agent's <code>MemoryComponent</code>.</li> </ul>"},{"location":"cognition/causal_reasoning/#estimating-causal-effects-do-calculus","title":"Estimating Causal Effects (Do-Calculus)","text":"<ul> <li>The <code>CausalGraphSystem</code> exposes a new method: <code>estimate_causal_effect(agent_id, treatment_value)</code>.</li> <li>This method uses the agent's stored <code>CausalModel</code> to perform a causal intervention based on Judea Pearl's do-calculus. It answers the question: \"What would the average effect on the outcome be if the agent were forced to take this action, regardless of the state it was in?\"</li> <li>This is different from simply averaging the observed rewards for that action, as it controls for confounding variables (e.g., \"Did the agent succeed because it chose to fight, or because it only chose to fight when it was already in a strong state?\").</li> </ul>"},{"location":"cognition/causal_reasoning/#formal-counterfactual-reasoning","title":"Formal Counterfactual Reasoning","text":"<ul> <li>The <code>generate_counterfactual</code> function now uses the agent's <code>CausalModel</code> to ask \"what if?\" questions about specific past events.</li> <li>Using the <code>event_id</code>, it finds the exact state of the world during a past action and uses the model's <code>whatif()</code> method to predict what the outcome would have been had the agent taken a different action.</li> </ul>"},{"location":"cognition/causal_reasoning/#3-the-what-how-to-use-the-causal-engine","title":"3. The \"What\": How to Use the Causal Engine","text":"<p>The new causal reasoning capabilities are consumed by other systems to improve the agent's intelligence.</p>"},{"location":"cognition/causal_reasoning/#for-learning-systems-qlearningsystem","title":"For Learning Systems (QLearningSystem)","text":"<ul> <li>The <code>QLearningSystem</code> now calls <code>estimate_causal_effect</code> after an action is performed.</li> <li>It then blends the raw, observed reward with the causally-estimated reward. This creates a more robust learning signal that is less susceptible to spurious correlations. The agent learns based on what its actions truly cause.</li> </ul>"},{"location":"cognition/causal_reasoning/#for-reflection-systems-counterfactualpy","title":"For Reflection Systems (counterfactual.py)","text":"<ul> <li>To generate a counterfactual, a system can now call <code>generate_counterfactual</code> and pass in a specific past episode and an alternative action to consider.</li> <li>The function will return a <code>CounterfactualEpisode</code> object containing a mathematically grounded prediction, which can be used to generate new insights, goals, or beliefs for the agent.</li> </ul>"},{"location":"cognition/causal_reasoning/#for-model-validation","title":"For Model Validation","text":"<ul> <li>The <code>CausalModelValidator</code> class in <code>validation.py</code> can be used to test the robustness of an agent's learned causal model.</li> <li>It runs several refutation tests (e.g., adding a random common cause, using a placebo treatment) and produces a confidence score.</li> <li>This score is stored in the <code>ValidationComponent</code> and can be used by the agent to understand how much it should trust its own causal beliefs.</li> </ul>"},{"location":"contributing/setup/","title":"Installation &amp; Setup","text":"<p>Get ARLA running on your local machine in minutes. Our Docker-based setup ensures consistency across all platforms while providing a complete development environment with cognitive systems, data persistence, and experiment tracking.</p> <p>What You'll Build</p> <p>By the end of this guide, you'll have a complete ARLA development environment with:</p> <ul> <li>Agent simulation engine with cognitive systems</li> <li>PostgreSQL database for experiment data and agent memories</li> <li>MLflow tracking server for experiment management and visualization</li> <li>Redis message broker for distributed computing and task queues</li> </ul>"},{"location":"contributing/setup/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have these tools installed on your development machine:</p> <ul> <li> <p> Git</p> <p>For cloning the repository and version control.</p> <p>Download Git</p> </li> <li> <p> Docker &amp; Docker Compose</p> <p>For running the containerized development environment.</p> <p>Download Docker</p> </li> <li> <p> OpenAI API Key</p> <p>Required for cognitive systems that use Large Language Models.</p> <p>Get API Key</p> </li> </ul>"},{"location":"contributing/setup/#quick-start","title":"Quick Start","text":""},{"location":"contributing/setup/#step-1-clone-the-repository","title":"Step 1: Clone the Repository","text":"<p>Get the latest version of ARLA from GitHub:</p> HTTPSSSHGitHub CLI <pre><code>git clone https://github.com/renbytes/arla.git\ncd arla\n</code></pre> <pre><code>git clone git@github.com:renbytes/arla.git\ncd arla\n</code></pre> <pre><code>gh repo clone renbytes/arla\ncd arla\n</code></pre>"},{"location":"contributing/setup/#step-2-configure-environment","title":"Step 2: Configure Environment","text":"<p>ARLA uses environment variables for sensitive configuration like API keys and database credentials.</p> <p>Create Configuration File:</p> <p>The <code>Makefile</code> includes a convenient setup command:</p> <pre><code>make setup\n</code></pre> <p>This copies <code>.env.example</code> to <code>.env</code> with sensible defaults.</p> <p>Add Your API Key:</p> <p>Open the newly created <code>.env</code> file and add your OpenAI API key:</p> .env<pre><code># --- OpenAI API Key (Required) ---\nOPENAI_API_KEY=sk-YourSecretKeyGoesHere\n\n# --- Database Configuration ---\nPOSTGRES_USER=admin\nPOSTGRES_PASSWORD=password\nPOSTGRES_DB=agent_sim_db\n\n# --- MLflow Configuration ---\nMLFLOW_TRACKING_URI=http://mlflow:5000\nMLFLOW_TRACKING_USERNAME=admin\nMLFLOW_TRACKING_PASSWORD=password\n\n# --- Redis Configuration ---\nREDIS_URL=redis://redis:6379/0\n</code></pre> <p>Security Note</p> <p>Never commit your <code>.env</code> file to version control. It's already included in <code>.gitignore</code>.</p>"},{"location":"contributing/setup/#step-3-build-and-start-services","title":"Step 3: Build and Start Services","text":"<p>Launch the complete ARLA environment with a single command:</p> <pre><code>make up\n</code></pre> <p>What Happens During Setup:</p> <ul> <li> <p>1. Image Building</p> <p>Docker builds custom images for the application and worker services, installing Python dependencies with Poetry.</p> </li> <li> <p>2. Service Startup</p> <p>Launches PostgreSQL database, Redis message broker, and MLflow tracking server with health checks.</p> </li> <li> <p>3. Dependency Caching</p> <p>Creates shared volumes to cache Python dependencies, making subsequent builds much faster.</p> </li> <li> <p>4. Database Migration</p> <p>Automatically creates database tables and applies any pending migrations.</p> </li> </ul> <p>First Run Performance</p> <p>The initial setup may take 5-10 minutes to download images and install dependencies. Subsequent runs are much faster thanks to Docker's caching.</p>"},{"location":"contributing/setup/#step-4-verify-installation","title":"Step 4: Verify Installation","text":"<p>Confirm everything is working correctly:</p> <p>Check Service Status:</p> <pre><code>docker compose ps\n</code></pre> <p>You should see all services running with <code>healthy</code> status:</p> <pre><code>NAME            STATUS                    PORTS\narla-app-1      Up (healthy)             \narla-worker-1   Up (healthy)             \narla-db-1       Up (healthy)             0.0.0.0:5432-&gt;5432/tcp\narla-redis-1    Up (healthy)             0.0.0.0:6379-&gt;6379/tcp\narla-mlflow-1   Up (healthy)             0.0.0.0:5001-&gt;5000/tcp\n</code></pre> <p>Run Example Simulation:</p> <p>Test the installation with a pre-configured simulation:</p> <pre><code>make run-example\n</code></pre> <p>Expected Output: <pre><code>\u2705 Database connection successful\n\ud83d\udcca MLflow tracking enabled\n\ud83e\udd16 Spawning 10 agents in 50x50 grid world\n\u26a1 Starting simulation with 1000 ticks...\n\ud83e\udde0 Cognitive systems initialized: Reflection, Q-Learning, Identity, Goals\n\ud83c\udfac Simulation running... (Tick 1/1000)\n</code></pre></p> <p>Access MLflow UI:</p> <p>Open your browser and navigate to http://localhost:5001 to view the experiment tracking interface.</p> <p>Installation Complete!</p> <p>You now have a complete ARLA development environment running locally. You're ready to start building simulations!</p>"},{"location":"contributing/setup/#development-workflow","title":"Development Workflow","text":""},{"location":"contributing/setup/#daily-development-commands","title":"Daily Development Commands","text":"<p>Once installed, use these commands for daily development:</p> <pre><code># Start services\nmake up\n\n# Run a quick test simulation\nmake run-example\n\n# Run the full test suite\nmake test\n\n# View logs from all services\nmake logs\n</code></pre>"},{"location":"contributing/style-guide/","title":"Contributor's Guide: Coding Standards &amp; Style","text":"<p>To maintain a high level of code quality and consistency across the ARLA project, we adhere to a set of coding standards and architectural patterns. All contributions should follow these guidelines.</p> <p>Our CI pipeline automatically checks for compliance, so following these rules will help ensure your pull requests are merged smoothly.</p>"},{"location":"contributing/style-guide/#1-formatting-linting-with-ruff","title":"1. Formatting &amp; Linting with Ruff","text":"<p>We use Ruff as an all-in-one tool for linting and code formatting. It's incredibly fast and helps us enforce a consistent style based on the PEP 8 standard.</p> <ul> <li>Formatting: Before committing your code, please run the formatter from the root of the project.</li> </ul> <pre><code>poetry run ruff format .\n</code></pre> <ul> <li>Linting: To check for potential errors or style violations, run the linter.</li> </ul> <pre><code>poetry run ruff check .\n</code></pre> <p>Our CI pipeline will fail if either of these checks does not pass, so it's a good practice to run them locally before pushing your changes.</p>"},{"location":"contributing/style-guide/#2-static-type-checking-with-mypy","title":"2. Static Type Checking with Mypy","text":"<p>We use Mypy to enforce static type checking. All new code should include type hints for function arguments, return values, and variables. This helps us catch bugs before they happen and makes the codebase easier to understand and maintain.</p> <p>You can run the type checker locally with the following command:</p> <pre><code>poetry run mypy .\n</code></pre>"},{"location":"contributing/style-guide/#3-architectural-principles","title":"3. Architectural Principles","text":"<ul> <li>Separation of Concerns: This is the most important principle in the ARLA framework.</li> <li>Components must only contain data (state). They should not have any logic.</li> <li>Systems must only contain logic. They should not have any local state beyond what's necessary for their operation.</li> <li> <p>Actions define what is possible but delegate the implementation of the logic to Systems via the Event Bus.</p> </li> <li> <p>Dependency Injection: Systems and other core classes receive their dependencies (like the <code>SimulationState</code> or configuration objects) through their constructors. Avoid using global objects or singletons.</p> </li> <li> <p>Event-Driven Communication: Systems must not call each other directly. All inter-system communication must happen through the Event Bus.</p> </li> </ul>"},{"location":"contributing/style-guide/#4-docstrings-and-comments","title":"4. Docstrings and Comments","text":"<ul> <li> <p>Docstrings: All public modules, classes, and functions should have a clear, concise docstring explaining their purpose, arguments, and what they return. We follow the Google Python Style Guide for docstrings.</p> </li> <li> <p>Comments: Use comments sparingly. Your code should be as self-documenting as possible through clear variable names and well-structured logic.</p> </li> </ul>"},{"location":"contributing/testing/","title":"Contributor's Guide: Running Tests","text":"<p>Testing is a critical part of the development process for the ARLA framework. We have a comprehensive test suite that includes unit, integration, and contract tests to ensure the reliability and correctness of the codebase.</p> <p>All contributors are expected to run the test suite locally before submitting a pull request. Furthermore, all new features or bug fixes should be accompanied by corresponding tests.</p>"},{"location":"contributing/testing/#1-running-the-full-test-suite","title":"1. Running the Full Test Suite","text":"<p>We've simplified the process of running tests with a single <code>Makefile</code> command. This command should be run from the root of the project.</p> <pre><code>make test\n</code></pre> <p>This command executes <code>pytest</code> inside the Docker container and does the following:</p> <ul> <li>Discovers and runs all tests in the <code>tests/</code> directory.</li> <li>Generates a code coverage report for the <code>agent-core</code> and <code>agent-engine</code> libraries.</li> <li>Fails the build if the total test coverage is below the configured threshold (currently 80%).</li> </ul>"},{"location":"contributing/testing/#2-continuous-integration-ci","title":"2. Continuous Integration (CI)","text":"<p>Our CI pipeline, powered by GitHub Actions, automatically runs the full test suite on every pull request and every push to the <code>main</code> branch.</p> <p>A pull request will not be merged if any of the tests are failing or if the code coverage drops below the required threshold. Running the tests locally before you push your changes is the best way to ensure a smooth review process.</p>"},{"location":"contributing/testing/#3-writing-new-tests","title":"3. Writing New Tests","text":"<p>When you add a new feature or fix a bug, you should also add one or more tests to validate your changes.</p> <ul> <li> <p>Test Location: Tests are organized in a parallel directory structure. For example, a test for a module located at <code>agent-engine/src/agent_engine/systems/reflection_system.py</code> should be placed at <code>tests/agent-engine/systems/test_reflection_system.py</code>.</p> </li> <li> <p>Framework: We use <code>pytest</code> as our testing framework. Please use <code>pytest</code>-style fixtures and assertion syntax.</p> </li> <li> <p>Mocking: We use <code>unittest.mock</code> for creating mock objects and patching dependencies to ensure tests are isolated.</p> </li> </ul> <p>Thank you for helping us maintain a high-quality and reliable codebase!</p>"},{"location":"developer/creating-actions/","title":"Creating Custom Actions","text":"<p>Actions are the building blocks of agent behavior in ARLA. They define what agents can do, from basic movement to complex social interactions. This guide walks through creating robust, extensible actions.</p> <p>Action Design Philosophy</p> <p>Actions should define what is possible, not how it's implemented. The actual state changes happen in Systems via the event bus, keeping actions lightweight and testable.</p>"},{"location":"developer/creating-actions/#action-architecture","title":"Action Architecture","text":""},{"location":"developer/creating-actions/#the-actioninterface-contract","title":"The ActionInterface Contract","text":"<p>Every action must implement the <code>ActionInterface</code>, ensuring consistent integration with the simulation engine:</p> <pre><code>class ActionInterface:\n    @property\n    def action_id(self) -&gt; str: ...        # Unique identifier\n    @property \n    def name(self) -&gt; str: ...             # Human-readable name\n\n    def get_base_cost(self, simulation_state) -&gt; float: ...\n    def generate_possible_params(self, entity_id, simulation_state, current_tick) -&gt; List[Dict]: ...\n    def execute(self, entity_id, simulation_state, params, current_tick) -&gt; ActionOutcome: ...\n    def get_feature_vector(self, entity_id, simulation_state, params) -&gt; List[float]: ...\n</code></pre>"},{"location":"developer/creating-actions/#action-lifecycle","title":"Action Lifecycle","text":"<pre><code>graph LR\n    A[Registration] --&gt; B[Parameter Generation]\n    B --&gt; C[Action Selection]\n    C --&gt; D[Execution]\n    D --&gt; E[System Processing]\n    E --&gt; F[Outcome Calculation]</code></pre> <ol> <li>Registration: <code>@action_registry.register</code> makes action discoverable</li> <li>Parameter Generation: Creates valid action variants for current world state</li> <li>Selection: AI/heuristic systems choose from available actions</li> <li>Execution: Returns ActionOutcome, publishes event for Systems</li> <li>System Processing: World-specific logic updates simulation state</li> <li>Outcome Calculation: Final rewards and consequences computed</li> </ol>"},{"location":"developer/creating-actions/#example-communication-action","title":"Example: Communication Action","text":"<p>Let's build a comprehensive communication system that demonstrates best practices:</p> Basic StructureParameter GenerationExecution &amp; Features actions/communicate_action.py<pre><code>from typing import Any, Dict, List, Optional\nfrom dataclasses import dataclass\n\nfrom agent_core.agents.actions.action_interface import ActionInterface\nfrom agent_core.agents.actions.action_registry import action_registry\nfrom agent_core.agents.actions.base_action import ActionOutcome\nfrom agent_core.core.ecs.abstractions import SimulationState\n\n@dataclass\nclass CommunicationParams:\n    \"\"\"Structured parameters for communication actions.\"\"\"\n    target_agent_id: str\n    message_type: str  # \"greeting\", \"trade_offer\", \"warning\", etc.\n    message_content: str\n    urgency: float = 0.5  # 0.0 = casual, 1.0 = urgent\n    requires_response: bool = False\n\n@action_registry.register\nclass CommunicateAction(ActionInterface):\n    \"\"\"Enables agents to send messages to nearby agents.\"\"\"\n\n    # Action costs by message type\n    MESSAGE_COSTS = {\n        \"greeting\": 0.5,\n        \"trade_offer\": 1.0,\n        \"warning\": 0.3,\n        \"insult\": 0.2,\n        \"compliment\": 0.4\n    }\n\n    @property\n    def action_id(self) -&gt; str:\n        return \"communicate\"\n\n    @property\n    def name(self) -&gt; str:\n        return \"Communicate\"\n</code></pre> <pre><code>def generate_possible_params(\n    self, \n    entity_id: str, \n    simulation_state: SimulationState, \n    current_tick: int\n) -&gt; List[Dict[str, Any]]:\n    \"\"\"Generate communication possibilities based on context.\"\"\"\n\n    # Get agent's position and social memory\n    pos_comp = simulation_state.get_component(entity_id, \"PositionComponent\")\n    social_comp = simulation_state.get_component(entity_id, \"SocialMemoryComponent\")\n\n    if not pos_comp:\n        return []\n\n    possible_actions = []\n\n    # Find nearby agents\n    nearby_agents = self._find_nearby_agents(\n        simulation_state, \n        pos_comp, \n        max_distance=5\n    )\n\n    for target_id, distance in nearby_agents:\n        if target_id == entity_id:\n            continue\n\n        # Generate context-appropriate messages\n        relationship = self._get_relationship_context(\n            social_comp, target_id\n        )\n\n        message_options = self._generate_message_options(\n            relationship, distance, current_tick\n        )\n\n        for msg_type, content in message_options:\n            params = CommunicationParams(\n                target_agent_id=target_id,\n                message_type=msg_type,\n                message_content=content,\n                urgency=self._calculate_urgency(relationship, msg_type),\n                requires_response=msg_type in [\"trade_offer\", \"question\"]\n            )\n\n            possible_actions.append(params.__dict__)\n\n    return possible_actions\n\ndef _find_nearby_agents(\n    self, \n    simulation_state: SimulationState, \n    pos_comp, \n    max_distance: int\n) -&gt; List[tuple[str, int]]:\n    \"\"\"Find agents within communication range.\"\"\"\n    nearby = []\n    my_pos = (pos_comp.x, pos_comp.y)\n\n    # Query all entities with position components\n    for entity_id, components in simulation_state.get_entities_with_components([\n        \"PositionComponent\"\n    ]).items():\n        other_pos_comp = components[\"PositionComponent\"]\n        other_pos = (other_pos_comp.x, other_pos_comp.y)\n\n        # Calculate Manhattan distance\n        distance = abs(my_pos[0] - other_pos[0]) + abs(my_pos[1] - other_pos[1])\n\n        if distance &lt;= max_distance:\n            nearby.append((entity_id, distance))\n\n    return nearby\n\ndef _generate_message_options(\n    self, \n    relationship: Dict[str, Any], \n    distance: int, \n    current_tick: int\n) -&gt; List[tuple[str, str]]:\n    \"\"\"Generate appropriate messages based on context.\"\"\"\n    options = []\n\n    # Always available: basic greeting\n    options.append((\"greeting\", \"Hello there!\"))\n\n    # Relationship-based messages\n    if relationship.get(\"trust\", 0.5) &gt; 0.7:\n        options.append((\"compliment\", \"You're doing great work!\"))\n        options.append((\"trade_offer\", \"Want to trade resources?\"))\n\n    if relationship.get(\"threat_level\", 0.0) &gt; 0.5:\n        options.append((\"warning\", \"Stay back!\"))\n\n    # Distance-based messages\n    if distance == 1:  # Adjacent\n        options.append((\"whisper\", \"Psst, over here...\"))\n\n    return options\n</code></pre> <pre><code>def execute(\n    self,\n    entity_id: str,\n    simulation_state: SimulationState,\n    params: Dict[str, Any],\n    current_tick: int,\n) -&gt; ActionOutcome:\n    \"\"\"Execute communication action.\"\"\"\n    target_id = params.get(\"target_agent_id\")\n    message_type = params.get(\"message_type\", \"greeting\")\n    content = params.get(\"message_content\", \"\")\n\n    # Validate target exists and is in range\n    if not self._validate_target(simulation_state, entity_id, target_id):\n        return ActionOutcome(\n            success=False,\n            message=f\"Cannot communicate with {target_id}: out of range or invalid\",\n            base_reward=-0.1\n        )\n\n    # Calculate success probability based on relationship\n    success_prob = self._calculate_success_probability(\n        simulation_state, entity_id, target_id, message_type\n    )\n\n    import random\n    success = random.random() &lt; success_prob\n\n    outcome_message = (\n        f\"Agent {entity_id} {message_type}s to {target_id}: '{content}'\"\n        if success else \n        f\"Agent {entity_id}'s {message_type} to {target_id} was ignored\"\n    )\n\n    return ActionOutcome(\n        success=success,\n        message=outcome_message,\n        base_reward=0.2 if success else -0.05\n    )\n\ndef get_base_cost(self, simulation_state: SimulationState) -&gt; float:\n    \"\"\"Dynamic cost based on recent communication frequency.\"\"\"\n    # Could implement fatigue system here\n    return 1.0\n\ndef get_feature_vector(\n    self,\n    entity_id: str,\n    simulation_state: SimulationState,\n    params: Dict[str, Any],\n) -&gt; List[float]:\n    \"\"\"Encode action for machine learning.\"\"\"\n\n    # One-hot encode message types\n    message_types = [\"greeting\", \"trade_offer\", \"warning\", \"insult\", \"compliment\"]\n    message_type = params.get(\"message_type\", \"greeting\")\n\n    type_encoding = [1.0 if msg_type == message_type else 0.0 \n                    for msg_type in message_types]\n\n    # Additional features\n    features = type_encoding + [\n        float(params.get(\"urgency\", 0.5)),           # Urgency level\n        1.0 if params.get(\"requires_response\") else 0.0,  # Expects response\n        self._get_relationship_strength(simulation_state, entity_id, \n                                      params.get(\"target_agent_id\", \"\"))\n    ]\n\n    return features\n\ndef _get_relationship_strength(\n    self, \n    simulation_state: SimulationState, \n    entity_id: str, \n    target_id: str\n) -&gt; float:\n    \"\"\"Get normalized relationship strength.\"\"\"\n    social_comp = simulation_state.get_component(entity_id, \"SocialMemoryComponent\")\n    if not social_comp or target_id not in social_comp.relationships:\n        return 0.5  # Neutral\n\n    relationship = social_comp.relationships[target_id]\n    return relationship.get(\"trust\", 0.5)\n</code></pre>"},{"location":"developer/creating-actions/#advanced-action-patterns","title":"Advanced Action Patterns","text":""},{"location":"developer/creating-actions/#multi-step-actions","title":"Multi-Step Actions","text":"<p>For actions that span multiple ticks:</p> <pre><code>@action_registry.register\nclass BuildAction(ActionInterface):\n    \"\"\"Action that takes multiple ticks to complete.\"\"\"\n\n    def generate_possible_params(self, entity_id, simulation_state, current_tick):\n        # Check if agent is already building\n        build_comp = simulation_state.get_component(entity_id, \"BuildingComponent\")\n        if build_comp and build_comp.is_building:\n            return [{\"action\": \"continue_building\"}]\n\n        # Generate new building options\n        return [\n            {\"action\": \"start_building\", \"structure_type\": \"shelter\"},\n            {\"action\": \"start_building\", \"structure_type\": \"workshop\"}\n        ]\n</code></pre>"},{"location":"developer/creating-actions/#conditional-actions","title":"Conditional Actions","text":"<p>Actions available only under specific conditions:</p> <pre><code>@action_registry.register\nclass TradeAction(ActionInterface):\n    \"\"\"Trading requires specific inventory items.\"\"\"\n\n    def generate_possible_params(self, entity_id, simulation_state, current_tick):\n        inventory = simulation_state.get_component(entity_id, \"InventoryComponent\")\n        if not inventory or len(inventory.items) == 0:\n            return []  # No items to trade\n\n        # Find potential trading partners\n        nearby_traders = self._find_traders_with_desired_items(\n            simulation_state, entity_id, inventory.wishlist\n        )\n\n        if not nearby_traders:\n            return []\n\n        # Generate trade offers\n        return self._generate_trade_offers(inventory, nearby_traders)\n</code></pre>"},{"location":"developer/creating-actions/#composite-actions","title":"Composite Actions","text":"<p>Actions that trigger multiple sub-actions:</p> <pre><code>@action_registry.register  \nclass AttackAction(ActionInterface):\n    \"\"\"Combat action with movement and damage components.\"\"\"\n\n    def execute(self, entity_id, simulation_state, params, current_tick):\n        # This will trigger multiple systems:\n        # 1. MovementSystem (if need to close distance)\n        # 2. CombatSystem (for damage calculation)\n        # 3. SocialSystem (for reputation effects)\n\n        return ActionOutcome(\n            success=True,\n            message=f\"Agent {entity_id} attacks {params['target']}\",\n            base_reward=0.0,  # Determined by combat outcome\n            metadata={\n                \"triggers_movement\": params.get(\"requires_movement\", False),\n                \"combat_type\": params.get(\"weapon_type\", \"melee\")\n            }\n        )\n</code></pre>"},{"location":"developer/creating-actions/#testing-actions","title":"Testing Actions","text":""},{"location":"developer/creating-actions/#unit-testing-pattern","title":"Unit Testing Pattern","text":"<pre><code>import pytest\nfrom unittest.mock import Mock, MagicMock\n\nclass TestCommunicateAction:\n    def setup_method(self):\n        self.action = CommunicateAction()\n        self.mock_simulation_state = Mock()\n\n    def test_generate_params_no_nearby_agents(self):\n        \"\"\"Test parameter generation with no nearby agents.\"\"\"\n        # Mock empty position component\n        self.mock_simulation_state.get_component.return_value = None\n\n        params = self.action.generate_possible_params(\n            \"agent_001\", self.mock_simulation_state, 100\n        )\n\n        assert params == []\n\n    def test_execute_valid_communication(self):\n        \"\"\"Test successful communication execution.\"\"\"\n        params = {\n            \"target_agent_id\": \"agent_002\",\n            \"message_type\": \"greeting\",\n            \"message_content\": \"Hello!\"\n        }\n\n        outcome = self.action.execute(\n            \"agent_001\", self.mock_simulation_state, params, 100\n        )\n\n        assert outcome.success\n        assert \"greeting\" in outcome.message\n        assert outcome.base_reward &gt; 0\n</code></pre>"},{"location":"developer/creating-actions/#integration-testing","title":"Integration Testing","text":"<pre><code>async def test_communication_system_integration():\n    \"\"\"Test full communication flow with actual systems.\"\"\"\n\n    # Set up simulation with communication system\n    manager = SimulationManager(test_config)\n    manager.register_system(CommunicationSystem)\n\n    # Create test agents\n    agent1 = manager.create_agent(\"test_agent_1\")\n    agent2 = manager.create_agent(\"test_agent_2\")\n\n    # Place agents near each other\n    pos1 = PositionComponent(x=5, y=5)\n    pos2 = PositionComponent(x=6, y=5)\n\n    manager.simulation_state.add_component(agent1, pos1)\n    manager.simulation_state.add_component(agent2, pos2)\n\n    # Force communication action\n    action = CommunicateAction()\n    params = action.generate_possible_params(agent1, manager.simulation_state, 1)\n\n    assert len(params) &gt; 0\n\n    # Execute and verify system processes it\n    outcome = action.execute(agent1, manager.simulation_state, params[0], 1)\n    assert outcome.success\n</code></pre>"},{"location":"developer/creating-actions/#performance-optimization","title":"Performance Optimization","text":""},{"location":"developer/creating-actions/#efficient-parameter-generation","title":"Efficient Parameter Generation","text":"<pre><code>def generate_possible_params(self, entity_id, simulation_state, current_tick):\n    # Cache expensive calculations\n    if not hasattr(self, '_nearby_cache') or current_tick % 10 == 0:\n        self._nearby_cache = self._build_proximity_cache(simulation_state)\n\n    # Use cached data for parameter generation\n    nearby_agents = self._nearby_cache.get(entity_id, [])\n    return self._generate_params_from_cache(entity_id, nearby_agents)\n</code></pre>"},{"location":"developer/creating-actions/#memory-efficient-features","title":"Memory-Efficient Features","text":"<pre><code>def get_feature_vector(self, entity_id, simulation_state, params):\n    # Use numpy for efficient numeric operations\n    import numpy as np\n\n    features = np.zeros(self.FEATURE_VECTOR_SIZE, dtype=np.float32)\n\n    # Sparse encoding for categorical features\n    message_type_idx = self.MESSAGE_TYPE_TO_INDEX.get(\n        params.get(\"message_type\"), 0\n    )\n    features[message_type_idx] = 1.0\n\n    return features.tolist()\n</code></pre>"},{"location":"developer/creating-actions/#common-pitfalls","title":"Common Pitfalls","text":""},{"location":"developer/creating-actions/#avoid-heavy-logic-in-actions","title":"Avoid Heavy Logic in Actions","text":"<p>Wrong: <pre><code>def execute(self, entity_id, simulation_state, params, current_tick):\n    # Don't do complex state modifications here!\n    target_health = simulation_state.get_component(params[\"target\"], \"HealthComponent\")\n    target_health.current_health -= params[\"damage\"]  # BAD!\n\n    return ActionOutcome(success=True, message=\"Attack executed\")\n</code></pre></p> <p>Right: <pre><code>def execute(self, entity_id, simulation_state, params, current_tick):\n    # Just return the outcome - let CombatSystem handle the logic\n    return ActionOutcome(\n        success=True,\n        message=f\"Agent {entity_id} attacks {params['target']}\",\n        base_reward=0.1\n    )\n</code></pre></p>"},{"location":"developer/creating-actions/#parameter-validation","title":"Parameter Validation","text":"<pre><code>def execute(self, entity_id, simulation_state, params, current_tick):\n    # Always validate parameters\n    required_params = [\"target_agent_id\", \"message_type\"]\n    for param in required_params:\n        if param not in params:\n            return ActionOutcome(\n                success=False,\n                message=f\"Missing required parameter: {param}\",\n                base_reward=-0.1\n            )\n\n    # Rest of execution logic...\n</code></pre>"},{"location":"developer/creating-actions/#feature-vector-consistency","title":"Feature Vector Consistency","text":"<pre><code>class CommunicateAction(ActionInterface):\n    # Define feature vector size as class constant\n    FEATURE_VECTOR_SIZE = 10\n\n    def get_feature_vector(self, entity_id, simulation_state, params):\n        features = [0.0] * self.FEATURE_VECTOR_SIZE\n        # Always return exactly FEATURE_VECTOR_SIZE elements\n        return features\n</code></pre> <p>Actions form the interface between agent decision-making and world simulation. By following these patterns, you'll create robust, testable actions that integrate seamlessly with ARLA's cognitive architecture.</p>"},{"location":"developer/creating-systems/","title":"Creating New Systems","text":"<p>Systems are the engines of logic in ARLA's ECS architecture. While Actions define what agents can do, Systems define how those actions (and other simulation rules) affect the world. This guide demonstrates building a complete communication system that showcases advanced patterns and best practices.</p> <p>System Design Philosophy</p> <p>Systems should contain logic, not data. They operate on entities with specific component combinations and communicate through events, not direct calls. This separation enables modularity, testability, and concurrent execution.</p>"},{"location":"developer/creating-systems/#system-architecture-overview","title":"System Architecture Overview","text":""},{"location":"developer/creating-systems/#the-role-of-systems","title":"The Role of Systems","text":"<p>Systems in ARLA follow a specific pattern designed for scalability and maintainability:</p> <ul> <li> <p>Single Responsibility</p> <p>Each system handles one specific domain (movement, combat, communication, etc.)</p> </li> <li> <p>Event-Driven</p> <p>Systems communicate through the event bus, never direct method calls</p> </li> <li> <p>Stateless</p> <p>Systems contain minimal local state, reading from and writing to Components</p> </li> <li> <p>Concurrent</p> <p>Systems can execute concurrently via async/await patterns</p> </li> </ul>"},{"location":"developer/creating-systems/#system-lifecycle","title":"System Lifecycle","text":"<pre><code>graph TD\n    A[System Registration] --&gt; B[Initialization]\n    B --&gt; C[Event Subscription]\n    C --&gt; D[Main Loop]\n    D --&gt; E[Event Processing]\n    E --&gt; D\n    D --&gt; F[Shutdown]\n\n    style D fill:#e3f2fd,stroke:#1976d2,stroke-width:2px\n    style E fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px</code></pre>"},{"location":"developer/creating-systems/#example-communication-system","title":"Example: Communication System","text":"<p>Let's build a comprehensive communication system that handles agent-to-agent messaging, relationship updates, and social dynamics.</p>"},{"location":"developer/creating-systems/#step-1-define-supporting-components","title":"Step 1: Define Supporting Components","text":"<p>First, create the components that store communication-related data:</p> Social ComponentsPosition Component components/social_components.py<pre><code>from typing import Dict, List, Optional, Any\nfrom dataclasses import dataclass\nfrom agent_core.core.ecs.component import Component\n\n@dataclass\nclass Message:\n    \"\"\"Represents a single communication event.\"\"\"\n    sender_id: str\n    content: str\n    message_type: str  # \"greeting\", \"trade_offer\", \"warning\", etc.\n    timestamp: int\n    urgency: float = 0.5\n    requires_response: bool = False\n\nclass CommunicationComponent(Component):\n    \"\"\"Stores agent's communication abilities and message queue.\"\"\"\n\n    def __init__(self, max_range: int = 5, language_skill: float = 1.0):\n        self.max_range = max_range\n        self.language_skill = language_skill\n        self.message_queue: List[Message] = []\n        self.sent_messages: List[Message] = []\n        self.communication_cooldown = 0\n\n    def add_incoming_message(self, message: Message) -&gt; None:\n        \"\"\"Add a message to the agent's inbox.\"\"\"\n        self.message_queue.append(message)\n\n    def get_unread_messages(self) -&gt; List[Message]:\n        \"\"\"Get all unread messages and mark as read.\"\"\"\n        messages = self.message_queue.copy()\n        self.message_queue.clear()\n        return messages\n\n    def to_dict(self) -&gt; Dict[str, Any]:\n        return {\n            \"max_range\": self.max_range,\n            \"language_skill\": self.language_skill,\n            \"message_queue\": [\n                {\n                    \"sender_id\": msg.sender_id,\n                    \"content\": msg.content,\n                    \"message_type\": msg.message_type,\n                    \"timestamp\": msg.timestamp,\n                    \"urgency\": msg.urgency,\n                    \"requires_response\": msg.requires_response\n                } for msg in self.message_queue\n            ],\n            \"communication_cooldown\": self.communication_cooldown\n        }\n\nclass SocialMemoryComponent(Component):\n    \"\"\"Stores agent's memories of other agents.\"\"\"\n\n    def __init__(self):\n        self.relationships: Dict[str, Dict[str, Any]] = {}\n        self.reputation_scores: Dict[str, float] = {}\n        self.interaction_history: List[Dict[str, Any]] = []\n\n    def update_relationship(self, other_agent_id: str, interaction_type: str, outcome: str):\n        \"\"\"Update relationship based on interaction.\"\"\"\n        if other_agent_id not in self.relationships:\n            self.relationships[other_agent_id] = {\n                \"trust\": 0.5,\n                \"familiarity\": 0.0,\n                \"last_interaction\": 0,\n                \"interaction_count\": 0\n            }\n\n        relationship = self.relationships[other_agent_id]\n        relationship[\"interaction_count\"] += 1\n        relationship[\"familiarity\"] = min(1.0, relationship[\"familiarity\"] + 0.1)\n\n        # Adjust trust based on interaction outcome\n        if outcome == \"positive\":\n            relationship[\"trust\"] = min(1.0, relationship[\"trust\"] + 0.1)\n        elif outcome == \"negative\":\n            relationship[\"trust\"] = max(0.0, relationship[\"trust\"] - 0.2)\n\n    def get_relationship_strength(self, other_agent_id: str) -&gt; float:\n        \"\"\"Get overall relationship strength with another agent.\"\"\"\n        if other_agent_id not in self.relationships:\n            return 0.5  # Neutral\n\n        rel = self.relationships[other_agent_id]\n        return (rel[\"trust\"] + rel[\"familiarity\"]) / 2\n\n    def to_dict(self) -&gt; Dict[str, Any]:\n        return {\n            \"relationships\": self.relationships,\n            \"reputation_scores\": self.reputation_scores,\n            \"interaction_history\": self.interaction_history\n        }\n</code></pre> components/position_component.py<pre><code>from typing import Tuple, Dict, Any, List\nfrom agent_core.core.ecs.component import Component\n\nclass PositionComponent(Component):\n    \"\"\"Stores spatial location for range-based communication.\"\"\"\n\n    def __init__(self, x: int = 0, y: int = 0):\n        self.x = x\n        self.y = y\n        self.movement_history: List[Tuple[int, int]] = [(x, y)]\n\n    @property\n    def position(self) -&gt; Tuple[int, int]:\n        return (self.x, self.y)\n\n    def distance_to(self, other_position: Tuple[int, int]) -&gt; int:\n        \"\"\"Calculate Manhattan distance to another position.\"\"\"\n        return abs(self.x - other_position[0]) + abs(self.y - other_position[1])\n\n    def move_to(self, new_x: int, new_y: int) -&gt; None:\n        \"\"\"Update position and track history.\"\"\"\n        self.movement_history.append((new_x, new_y))\n        if len(self.movement_history) &gt; 20:  # Keep last 20 positions\n            self.movement_history.pop(0)\n        self.x, self.y = new_x, new_y\n\n    def to_dict(self) -&gt; Dict[str, Any]:\n        return {\n            \"x\": self.x,\n            \"y\": self.y,\n            \"movement_history\": self.movement_history\n        }\n</code></pre>"},{"location":"developer/creating-systems/#step-2-implement-the-communication-system","title":"Step 2: Implement the Communication System","text":"<p>Now create the system that processes communication events:</p> Communication SystemSystem Registration systems/communication_system.py<pre><code>from typing import Any, Dict, List, Optional\nimport random\nfrom agent_engine.simulation.system import System\nfrom ..components.social_components import (\n    CommunicationComponent, SocialMemoryComponent, Message\n)\nfrom ..components.position_component import PositionComponent\n\nclass CommunicationSystem(System):\n    \"\"\"Handles agent-to-agent communication and social dynamics.\"\"\"\n\n    def __init__(self, simulation_state, config, cognitive_scaffold):\n        super().__init__(simulation_state, config, cognitive_scaffold)\n\n        # Subscribe to communication-related events\n        if self.event_bus:\n            self.event_bus.subscribe(\"execute_communicate_action\", self.on_communicate)\n            self.event_bus.subscribe(\"tick_started\", self.process_message_queue)\n            self.event_bus.subscribe(\"agent_moved\", self.update_communication_ranges)\n\n    def on_communicate(self, event_data: Dict[str, Any]) -&gt; None:\n        \"\"\"Handle communication action execution.\"\"\"\n        entity_id = event_data[\"entity_id\"]\n        action_plan = event_data[\"action_plan_component\"]\n        params = action_plan.params\n        current_tick = event_data.get(\"current_tick\", 0)\n\n        # Validate communication attempt\n        if not self._validate_communication(entity_id, params):\n            self._publish_failure(event_data, \"Invalid communication parameters\")\n            return\n\n        # Process the communication\n        success = self._process_communication(entity_id, params, current_tick)\n\n        if success:\n            self._publish_success(event_data, \"Communication sent successfully\")\n        else:\n            self._publish_failure(event_data, \"Communication failed\")\n\n    def _validate_communication(self, sender_id: str, params: Dict[str, Any]) -&gt; bool:\n        \"\"\"Validate that communication is possible.\"\"\"\n\n        # Check sender has communication component\n        comm_comp = self.simulation_state.get_component(sender_id, CommunicationComponent)\n        if not comm_comp:\n            return False\n\n        # Check cooldown\n        if comm_comp.communication_cooldown &gt; 0:\n            return False\n\n        # Check required parameters\n        required_params = [\"target_agent_id\", \"message_type\", \"message_content\"]\n        if not all(param in params for param in required_params):\n            return False\n\n        # Check target exists\n        target_id = params[\"target_agent_id\"]\n        target_comm_comp = self.simulation_state.get_component(target_id, CommunicationComponent)\n        if not target_comm_comp:\n            return False\n\n        # Check range if positions exist\n        sender_pos = self.simulation_state.get_component(sender_id, PositionComponent)\n        target_pos = self.simulation_state.get_component(target_id, PositionComponent)\n\n        if sender_pos and target_pos:\n            distance = sender_pos.distance_to(target_pos.position)\n            if distance &gt; comm_comp.max_range:\n                return False\n\n        return True\n\n    def _process_communication(self, sender_id: str, params: Dict[str, Any], current_tick: int) -&gt; bool:\n        \"\"\"Process the actual communication between agents.\"\"\"\n\n        target_id = params[\"target_agent_id\"]\n        message_type = params[\"message_type\"]\n        content = params[\"message_content\"]\n        urgency = params.get(\"urgency\", 0.5)\n        requires_response = params.get(\"requires_response\", False)\n\n        # Get components\n        sender_comm = self.simulation_state.get_component(sender_id, CommunicationComponent)\n        target_comm = self.simulation_state.get_component(target_id, CommunicationComponent)\n        sender_social = self.simulation_state.get_component(sender_id, SocialMemoryComponent)\n        target_social = self.simulation_state.get_component(target_id, SocialMemoryComponent)\n\n        # Create message\n        message = Message(\n            sender_id=sender_id,\n            content=content,\n            message_type=message_type,\n            timestamp=current_tick,\n            urgency=urgency,\n            requires_response=requires_response\n        )\n\n        # Calculate communication success probability\n        success_probability = self._calculate_success_probability(\n            sender_id, target_id, message_type\n        )\n\n        success = random.random() &lt; success_probability\n\n        if success:\n            # Deliver message\n            target_comm.add_incoming_message(message)\n            sender_comm.sent_messages.append(message)\n\n            # Update social memories\n            if sender_social:\n                sender_social.update_relationship(target_id, \"communication\", \"positive\")\n\n            if target_social:\n                target_social.update_relationship(sender_id, \"communication\", \"positive\")\n\n            # Set cooldown\n            sender_comm.communication_cooldown = 3  # 3 ticks\n\n            print(f\"\ud83d\udcac {sender_id} successfully sent {message_type} to {target_id}: '{content}'\")\n\n            # Publish communication event for other systems\n            if self.event_bus:\n                self.event_bus.publish(\"communication_successful\", {\n                    \"sender_id\": sender_id,\n                    \"target_id\": target_id,\n                    \"message\": message,\n                    \"timestamp\": current_tick\n                })\n        else:\n            # Communication failed\n            if sender_social:\n                sender_social.update_relationship(target_id, \"communication\", \"negative\")\n\n            print(f\"\u274c {sender_id}'s {message_type} to {target_id} was ignored or misunderstood\")\n\n        return success\n\n    def _calculate_success_probability(self, sender_id: str, target_id: str, message_type: str) -&gt; float:\n        \"\"\"Calculate probability of successful communication.\"\"\"\n\n        base_probability = 0.7\n\n        # Factor in sender's language skill\n        sender_comm = self.simulation_state.get_component(sender_id, CommunicationComponent)\n        if sender_comm:\n            base_probability *= sender_comm.language_skill\n\n        # Factor in relationship strength\n        sender_social = self.simulation_state.get_component(sender_id, SocialMemoryComponent)\n        if sender_social:\n            relationship_strength = sender_social.get_relationship_strength(target_id)\n            base_probability *= (0.5 + relationship_strength * 0.5)\n\n        # Message type modifiers\n        type_modifiers = {\n            \"greeting\": 1.2,\n            \"compliment\": 1.1,\n            \"trade_offer\": 0.9,\n            \"warning\": 0.8,\n            \"insult\": 0.3\n        }\n\n        modifier = type_modifiers.get(message_type, 1.0)\n        base_probability *= modifier\n\n        return min(1.0, max(0.1, base_probability))\n\n    async def process_message_queue(self, event_data: Dict[str, Any]) -&gt; None:\n        \"\"\"Process incoming messages for all agents each tick.\"\"\"\n\n        current_tick = event_data.get(\"current_tick\", 0)\n\n        # Get all agents with communication components\n        entities = self.simulation_state.get_entities_with_components([\n            CommunicationComponent\n        ])\n\n        for entity_id, components in entities.items():\n            comm_comp = components[CommunicationComponent]\n\n            # Reduce cooldown\n            if comm_comp.communication_cooldown &gt; 0:\n                comm_comp.communication_cooldown -= 1\n\n            # Process incoming messages\n            unread_messages = comm_comp.get_unread_messages()\n\n            for message in unread_messages:\n                await self._process_incoming_message(entity_id, message, current_tick)\n\n    async def _process_incoming_message(self, recipient_id: str, message: Message, current_tick: int):\n        \"\"\"Process a message received by an agent.\"\"\"\n\n        # Update social memory about the sender\n        social_comp = self.simulation_state.get_component(recipient_id, SocialMemoryComponent)\n        if social_comp:\n            social_comp.update_relationship(\n                message.sender_id, \n                f\"received_{message.message_type}\", \n                \"positive\"\n            )\n\n        # Generate response if required and conditions are met\n        if message.requires_response and self._should_respond(recipient_id, message):\n            await self._generate_automatic_response(recipient_id, message, current_tick)\n\n        print(f\"\ud83d\udce8 {recipient_id} received {message.message_type} from {message.sender_id}\")\n\n    def _should_respond(self, recipient_id: str, message: Message) -&gt; bool:\n        \"\"\"Determine if agent should automatically respond to message.\"\"\"\n\n        # Check if agent is busy (has cooldown)\n        comm_comp = self.simulation_state.get_component(recipient_id, CommunicationComponent)\n        if comm_comp and comm_comp.communication_cooldown &gt; 0:\n            return False\n\n        # Check relationship with sender\n        social_comp = self.simulation_state.get_component(recipient_id, SocialMemoryComponent)\n        if social_comp:\n            relationship_strength = social_comp.get_relationship_strength(message.sender_id)\n            # More likely to respond to agents they have good relationships with\n            return random.random() &lt; relationship_strength\n\n        return random.random() &lt; 0.3  # Default 30% response rate\n\n    async def _generate_automatic_response(self, responder_id: str, original_message: Message, current_tick: int):\n        \"\"\"Generate an automatic response to a message.\"\"\"\n\n        response_content = self._generate_response_content(original_message)\n        response_type = self._determine_response_type(original_message)\n\n        # Create response message\n        response = Message(\n            sender_id=responder_id,\n            content=response_content,\n            message_type=response_type,\n            timestamp=current_tick,\n            urgency=0.3,  # Responses are usually less urgent\n            requires_response=False\n        )\n\n        # Send response\n        sender_comm = self.simulation_state.get_component(original_message.sender_id, CommunicationComponent)\n        if sender_comm:\n            sender_comm.add_incoming_message(response)\n\n            # Update responder's sent messages\n            responder_comm = self.simulation_state.get_component(responder_id, CommunicationComponent)\n            if responder_comm:\n                responder_comm.sent_messages.append(response)\n                responder_comm.communication_cooldown = 2  # Shorter cooldown for responses\n\n            print(f\"\ud83d\udd04 {responder_id} automatically responded to {original_message.sender_id}\")\n\n    def _generate_response_content(self, original_message: Message) -&gt; str:\n        \"\"\"Generate appropriate response content based on message type.\"\"\"\n\n        response_templates = {\n            \"greeting\": [\"Hello!\", \"Hi there!\", \"Greetings!\"],\n            \"trade_offer\": [\"I'll consider it\", \"What are you offering?\", \"Not interested\"],\n            \"warning\": [\"Thank you for the warning\", \"I'll be careful\", \"Noted\"],\n            \"compliment\": [\"Thank you!\", \"That's kind of you\", \"I appreciate that\"],\n            \"insult\": [\"That's uncalled for\", \"I disagree\", \"...\"]\n        }\n\n        templates = response_templates.get(original_message.message_type, [\"I understand\"])\n        return random.choice(templates)\n\n    def _determine_response_type(self, original_message: Message) -&gt; str:\n        \"\"\"Determine appropriate response type based on original message.\"\"\"\n\n        response_mapping = {\n            \"greeting\": \"greeting\",\n            \"trade_offer\": \"trade_response\",\n            \"warning\": \"acknowledgment\",\n            \"compliment\": \"gratitude\",\n            \"insult\": \"defensive\"\n        }\n\n        return response_mapping.get(original_message.message_type, \"general_response\")\n\n    def update_communication_ranges(self, event_data: Dict[str, Any]) -&gt; None:\n        \"\"\"Update communication possibilities when agents move.\"\"\"\n\n        # This could trigger recalculation of who can communicate with whom\n        # For now, we handle this dynamically in validation\n        pass\n\n    def _publish_success(self, event_data: Dict[str, Any], message: str = None) -&gt; None:\n        \"\"\"Signal successful action completion.\"\"\"\n        if message:\n            print(f\"\u2705 {message}\")\n\n        if self.event_bus:\n            self.event_bus.publish(\"action_outcome_ready\", event_data)\n\n    def _publish_failure(self, event_data: Dict[str, Any], reason: str) -&gt; None:\n        \"\"\"Signal action failure with reason.\"\"\"\n        print(f\"\u274c Communication failed: {reason}\")\n\n        # Update action outcome to reflect failure\n        action_plan = event_data.get(\"action_plan_component\")\n        if action_plan and hasattr(action_plan, \"outcome\"):\n            action_plan.outcome.success = False\n            action_plan.outcome.message = reason\n\n        if self.event_bus:\n            self.event_bus.publish(\"action_outcome_ready\", event_data)\n\n    async def update(self, current_tick: int) -&gt; None:\n        \"\"\"Main system update - most logic is event-driven.\"\"\"\n\n        # Perform periodic maintenance tasks\n        if current_tick % 100 == 0:  # Every 100 ticks\n            await self._cleanup_old_messages(current_tick)\n            await self._update_reputation_decay(current_tick)\n\n    async def _cleanup_old_messages(self, current_tick: int) -&gt; None:\n        \"\"\"Remove old messages to prevent memory bloat.\"\"\"\n\n        entities = self.simulation_state.get_entities_with_components([\n            CommunicationComponent\n        ])\n\n        for entity_id, components in entities.items():\n            comm_comp = components[CommunicationComponent]\n\n            # Keep only last 50 sent messages\n            if len(comm_comp.sent_messages) &gt; 50:\n                comm_comp.sent_messages = comm_comp.sent_messages[-50:]\n\n    async def _update_reputation_decay(self, current_tick: int) -&gt; None:\n        \"\"\"Slowly decay relationship strengths over time without interaction.\"\"\"\n\n        entities = self.simulation_state.get_entities_with_components([\n            SocialMemoryComponent\n        ])\n\n        for entity_id, components in entities.items():\n            social_comp = components[SocialMemoryComponent]\n\n            for other_id, relationship in social_comp.relationships.items():\n                time_since_interaction = current_tick - relationship.get(\"last_interaction\", 0)\n\n                # Decay familiarity if no recent interaction (after 200 ticks)\n                if time_since_interaction &gt; 200:\n                    relationship[\"familiarity\"] *= 0.99  # Slow decay\n                    relationship[\"familiarity\"] = max(0.0, relationship[\"familiarity\"])\n</code></pre> systems/__init__.py<pre><code>from .communication_system import CommunicationSystem\n\n__all__ = [\"CommunicationSystem\"]\n</code></pre>"},{"location":"developer/creating-systems/#step-3-create-the-communication-action","title":"Step 3: Create the Communication Action","text":"<p>Create the action that agents can use to communicate:</p> Communication Action actions/communicate_action.py<pre><code>from typing import Any, Dict, List\nfrom agent_core.agents.actions.action_interface import ActionInterface\nfrom agent_core.agents.actions.action_registry import action_registry\nfrom agent_core.agents.actions.base_action import ActionOutcome\nfrom agent_core.core.ecs.abstractions import SimulationState\nfrom ..components.social_components import CommunicationComponent, SocialMemoryComponent\nfrom ..components.position_component import PositionComponent\n\n@action_registry.register\nclass CommunicateAction(ActionInterface):\n    \"\"\"Enables agents to send messages to nearby agents.\"\"\"\n\n    MESSAGE_COSTS = {\n        \"greeting\": 0.5,\n        \"trade_offer\": 1.0,\n        \"warning\": 0.3,\n        \"insult\": 0.2,\n        \"compliment\": 0.4\n    }\n\n    @property\n    def action_id(self) -&gt; str:\n        return \"communicate\"\n\n    @property\n    def name(self) -&gt; str:\n        return \"Communicate\"\n\n    def get_base_cost(self, simulation_state: SimulationState) -&gt; float:\n        return 1.0\n\n    def generate_possible_params(\n        self, \n        entity_id: str, \n        simulation_state: SimulationState, \n        current_tick: int\n    ) -&gt; List[Dict[str, Any]]:\n        \"\"\"Generate communication possibilities based on context.\"\"\"\n\n        # Check if agent can communicate\n        comm_comp = simulation_state.get_component(entity_id, CommunicationComponent)\n        if not comm_comp or comm_comp.communication_cooldown &gt; 0:\n            return []\n\n        pos_comp = simulation_state.get_component(entity_id, PositionComponent)\n        social_comp = simulation_state.get_component(entity_id, SocialMemoryComponent)\n\n        if not pos_comp:\n            return []\n\n        possible_actions = []\n\n        # Find nearby agents\n        nearby_agents = self._find_nearby_agents(\n            simulation_state, entity_id, pos_comp, comm_comp.max_range\n        )\n\n        for target_id, distance in nearby_agents:\n            if target_id == entity_id:\n                continue\n\n            # Generate context-appropriate messages\n            relationship_context = self._get_relationship_context(social_comp, target_id)\n            message_options = self._generate_message_options(\n                relationship_context, distance, current_tick\n            )\n\n            for msg_type, content, urgency, requires_response in message_options:\n                possible_actions.append({\n                    \"target_agent_id\": target_id,\n                    \"message_type\": msg_type,\n                    \"message_content\": content,\n                    \"urgency\": urgency,\n                    \"requires_response\": requires_response\n                })\n\n        return possible_actions\n\n    def _find_nearby_agents(\n        self, \n        simulation_state: SimulationState, \n        entity_id: str,\n        pos_comp: PositionComponent, \n        max_range: int\n    ) -&gt; List[tuple[str, int]]:\n        \"\"\"Find agents within communication range.\"\"\"\n\n        nearby = []\n        my_pos = pos_comp.position\n\n        # Query all entities with position and communication components\n        entities = simulation_state.get_entities_with_components([\n            PositionComponent, CommunicationComponent\n        ])\n\n        for other_id, components in entities.items():\n            if other_id == entity_id:\n                continue\n\n            other_pos_comp = components[PositionComponent]\n            distance = pos_comp.distance_to(other_pos_comp.position)\n\n            if distance &lt;= max_range:\n                nearby.append((other_id, distance))\n\n        return nearby\n\n    def _get_relationship_context(\n        self, \n        social_comp: SocialMemoryComponent, \n        target_id: str\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Get relationship context with target agent.\"\"\"\n\n        if not social_comp or target_id not in social_comp.relationships:\n            return {\n                \"trust\": 0.5,\n                \"familiarity\": 0.0,\n                \"interaction_count\": 0,\n                \"relationship_strength\": 0.5\n            }\n\n        relationship = social_comp.relationships[target_id]\n        relationship_strength = social_comp.get_relationship_strength(target_id)\n\n        return {\n            \"trust\": relationship.get(\"trust\", 0.5),\n            \"familiarity\": relationship.get(\"familiarity\", 0.0),\n            \"interaction_count\": relationship.get(\"interaction_count\", 0),\n            \"relationship_strength\": relationship_strength\n        }\n\n    def _generate_message_options(\n        self, \n        relationship_context: Dict[str, Any], \n        distance: int, \n        current_tick: int\n    ) -&gt; List[tuple[str, str, float, bool]]:\n        \"\"\"Generate appropriate messages based on context.\"\"\"\n\n        options = []\n        trust = relationship_context[\"trust\"]\n        familiarity = relationship_context[\"familiarity\"]\n\n        # Always available: basic greeting\n        options.append((\"greeting\", \"Hello there!\", 0.3, False))\n\n        # Relationship-based messages\n        if trust &gt; 0.7:\n            options.append((\"compliment\", \"You're doing great work!\", 0.4, False))\n            options.append((\"trade_offer\", \"Want to trade resources?\", 0.7, True))\n\n        if trust &lt; 0.3:\n            options.append((\"warning\", \"Stay back!\", 0.8, False))\n\n        # Familiarity-based messages\n        if familiarity &gt; 0.5:\n            options.append((\"casual_chat\", \"How are things going?\", 0.2, False))\n\n        # Distance-based messages\n        if distance == 1:  # Adjacent\n            options.append((\"whisper\", \"Psst, over here...\", 0.6, False))\n\n        return options\n\n    def execute(\n        self,\n        entity_id: str,\n        simulation_state: SimulationState,\n        params: Dict[str, Any],\n        current_tick: int,\n    ) -&gt; ActionOutcome:\n        \"\"\"Execute communication action - logic handled by CommunicationSystem.\"\"\"\n\n        target_id = params.get(\"target_agent_id\", \"unknown\")\n        message_type = params.get(\"message_type\", \"greeting\")\n        content = params.get(\"message_content\", \"\")\n\n        return ActionOutcome(\n            success=True,  # Actual success determined by system\n            message=f\"Agent {entity_id} attempts to {message_type} to {target_id}: '{content}'\",\n            base_reward=0.1\n        )\n\n    def get_feature_vector(\n        self,\n        entity_id: str,\n        simulation_state: SimulationState,\n        params: Dict[str, Any],\n    ) -&gt; List[float]:\n        \"\"\"Encode action for machine learning.\"\"\"\n\n        # One-hot encode message types\n        message_types = [\"greeting\", \"trade_offer\", \"warning\", \"insult\", \"compliment\", \"casual_chat\"]\n        message_type = params.get(\"message_type\", \"greeting\")\n\n        type_encoding = [1.0 if msg_type == message_type else 0.0 \n                        for msg_type in message_types]\n\n        # Additional features\n        features = type_encoding + [\n            float(params.get(\"urgency\", 0.5)),           # Message urgency\n            1.0 if params.get(\"requires_response\") else 0.0,  # Expects response\n            self._get_relationship_strength_feature(simulation_state, entity_id, \n                                                  params.get(\"target_agent_id\", \"\"))\n        ]\n\n        return features\n\n    def _get_relationship_strength_feature(\n        self, \n        simulation_state: SimulationState, \n        entity_id: str, \n        target_id: str\n    ) -&gt; float:\n        \"\"\"Get normalized relationship strength for ML features.\"\"\"\n\n        social_comp = simulation_state.get_component(entity_id, SocialMemoryComponent)\n        if not social_comp or not target_id:\n            return 0.5  # Neutral\n\n        return social_comp.get_relationship_strength(target_id)\n</code></pre>"},{"location":"developer/creating-systems/#step-4-register-and-test-the-system","title":"Step 4: Register and Test the System","text":"<p>Integrate the system into your simulation:</p> System RegistrationTesting run.py<pre><code>from agent_engine.simulation.engine import SimulationManager\nfrom .systems import CommunicationSystem\nfrom .components.social_components import CommunicationComponent, SocialMemoryComponent\nfrom .components.position_component import PositionComponent\n\nasync def setup_and_run(run_id, task_id, experiment_id, config_overrides):\n    \"\"\"Initialize and run simulation with communication system.\"\"\"\n\n    # Create simulation manager\n    manager = SimulationManager(config_overrides, run_id, task_id, experiment_id)\n\n    # Register the communication system\n    manager.register_system(CommunicationSystem)\n\n    # Add agents with communication capabilities\n    await _initialize_communicating_agents(manager, config_overrides)\n\n    # Run simulation\n    await manager.run()\n\nasync def _initialize_communicating_agents(manager: SimulationManager, config: dict):\n    \"\"\"Create agents with communication and social components.\"\"\"\n\n    agent_count = config.get(\"agent_count\", 10)\n\n    for i in range(agent_count):\n        entity_id = f\"agent_{i:03d}\"\n\n        # Add position component\n        import random\n        pos_comp = PositionComponent(\n            x=random.randint(0, 49),\n            y=random.randint(0, 49)\n        )\n        manager.simulation_state.add_component(entity_id, pos_comp)\n\n        # Add communication component\n        comm_comp = CommunicationComponent(\n            max_range=random.randint(3, 7),\n            language_skill=random.uniform(0.7, 1.0)\n        )\n        manager.simulation_state.add_component(entity_id, comm_comp)\n\n        # Add social memory component\n        social_comp = SocialMemoryComponent()\n        manager.simulation_state.add_component(entity_id, social_comp)\n\n        print(f\"Created communicating agent {entity_id} at position {pos_comp.position}\")\n</code></pre> test_communication_system.py<pre><code>import pytest\nfrom unittest.mock import Mock, AsyncMock\nfrom ..systems.communication_system import CommunicationSystem\nfrom ..components.social_components import CommunicationComponent, SocialMemoryComponent, Message\nfrom ..components.position_component import PositionComponent\n\nclass TestCommunicationSystem:\n\n    @pytest.fixture\n    def communication_system(self):\n        mock_state = Mock()\n        mock_config = Mock()\n        mock_scaffold = Mock()\n\n        system = CommunicationSystem(mock_state, mock_config, mock_scaffold)\n        return system\n\n    def test_validate_communication_success(self, communication_system):\n        \"\"\"Test successful communication validation.\"\"\"\n\n        # Setup mock components\n        sender_comm = CommunicationComponent(max_range=5, language_skill=1.0)\n        target_comm = CommunicationComponent()\n        sender_pos = PositionComponent(x=5, y=5)\n        target_pos = PositionComponent(x=7, y=5)  # Within range\n\n        communication_system.simulation_state.get_component.side_effect = lambda entity_id, comp_type: {\n            (\"sender\", CommunicationComponent): sender_comm,\n            (\"target\", CommunicationComponent): target_comm,\n            (\"sender\", PositionComponent): sender_pos,\n            (\"target\", PositionComponent): target_pos,\n        }.get((entity_id, comp_type))\n\n        params = {\n            \"target_agent_id\": \"target\",\n            \"message_type\": \"greeting\",\n            \"message_content\": \"Hello!\"\n        }\n\n        # Test validation\n        result = communication_system._validate_communication(\"sender\", params)\n        assert result is True\n\n    def test_validate_communication_out_of_range(self, communication_system):\n        \"\"\"Test communication validation fails when out of range.\"\"\"\n\n        sender_comm = CommunicationComponent(max_range=5)\n        target_comm = CommunicationComponent()\n        sender_pos = PositionComponent(x=0, y=0)\n        target_pos = PositionComponent(x=10, y=10)  # Out of range\n\n        communication_system.simulation_state.get_component.side_effect = lambda entity_id, comp_type: {\n            (\"sender\", CommunicationComponent): sender_comm,\n            (\"target\", CommunicationComponent): target_comm,\n            (\"sender\", PositionComponent): sender_pos,\n            (\"target\", PositionComponent): target_pos,\n        }.get((entity_id, comp_type))\n\n        params = {\n            \"target_agent_id\": \"target\",\n            \"message_type\": \"greeting\",\n            \"message_content\": \"Hello!\"\n        }\n\n        result = communication_system._validate_communication(\"sender\", params)\n        assert result is False\n\n    async def test_process_incoming_message(self, communication_system):\n        \"\"\"Test processing of incoming messages.\"\"\"\n\n        # Setup components\n        social_comp = SocialMemoryComponent()\n        communication_system.simulation_state.get_component.return_value = social_comp\n\n        # Create test message\n        message = Message(\n            sender_id=\"sender\",\n            content=\"Hello!\",\n            message_type=\"greeting\",\n            timestamp=100,\n            urgency=0.5,\n            requires_response=False\n        )\n\n        # Process message\n        await communication_system._process_incoming_message(\"recipient\", message, 100)\n\n        # Verify relationship was updated\n        assert \"sender\" in social_comp.relationships\n        assert social_comp.relationships[\"sender\"][\"interaction_count\"] == 1\n</code></pre>"},{"location":"developer/creating-systems/#advanced-system-patterns","title":"Advanced System Patterns","text":""},{"location":"developer/creating-systems/#multi-system-coordination","title":"Multi-System Coordination","text":"<p>Systems can coordinate through events without direct coupling:</p> <pre><code>class EconomySystem(System):\n    \"\"\"Example of system that reacts to communication events.\"\"\"\n\n    def __init__(self, simulation_state, config, cognitive_scaffold):\n        super().__init__(simulation_state, config, cognitive_scaffold)\n\n        if self.event_bus:\n            self.event_bus.subscribe(\"communication_successful\", self.on_communication)\n\n    def on_communication(self, event_data: Dict[str, Any]) -&gt; None:\n        \"\"\"React to successful communications for economic modeling.\"\"\"\n\n        message = event_data[\"message\"]\n\n        # Trade offers create economic opportunities\n        if message.message_type == \"trade_offer\":\n            self._create_trade_opportunity(event_data[\"sender_id\"], event_data[\"target_id\"])\n\n        # Social interactions affect reputation and market access\n        elif message.message_type in [\"compliment\", \"greeting\"]:\n            self._update_market_reputation(event_data[\"sender_id\"], event_data[\"target_id\"])\n</code></pre>"},{"location":"developer/creating-systems/#performance-optimization","title":"Performance Optimization","text":"<p>For large-scale simulations, optimize system performance:</p> <pre><code>class OptimizedCommunicationSystem(CommunicationSystem):\n    \"\"\"Performance-optimized version for large simulations.\"\"\"\n\n    def __init__(self, simulation_state, config, cognitive_scaffold):\n        super().__init__(simulation_state, config, cognitive_scaffold)\n\n        # Cache spatial queries\n        self._spatial_cache = {}\n        self._cache_tick = -1\n\n        # Batch message processing\n        self._message_batch = []\n        self._batch_size = 100\n\n    def _find_nearby_agents_cached(self, simulation_state, entity_id, pos_comp, max_range):\n        \"\"\"Use spatial caching to optimize range queries.\"\"\"\n\n        current_tick = getattr(simulation_state, 'current_tick', 0)\n\n        # Rebuild cache if stale\n        if current_tick != self._cache_tick:\n            self._rebuild_spatial_cache(simulation_state)\n            self._cache_tick = current_tick\n\n        # Use cached spatial index\n        return self._spatial_cache.get(entity_id, [])\n\n    async def process_message_queue(self, event_data: Dict[str, Any]) -&gt; None:\n        \"\"\"Batch process messages for better performance.\"\"\"\n\n        # Collect all messages into batch\n        entities = self.simulation_state.get_entities_with_components([CommunicationComponent])\n\n        for entity_id, components in entities.items():\n            comm_comp = components[CommunicationComponent]\n            unread_messages = comm_comp.get_unread_messages()\n\n            for message in unread_messages:\n                self._message_batch.append((entity_id, message))\n\n        # Process batch\n        if len(self._message_batch) &gt;= self._batch_size:\n            await self._process_message_batch()\n\n    async def _process_message_batch(self):\n        \"\"\"Process messages in batch for efficiency.\"\"\"\n\n        # Group by recipient for better cache locality\n        by_recipient = {}\n        for recipient_id, message in self._message_batch:\n            if recipient_id not in by_recipient:\n                by_recipient[recipient_id] = []\n            by_recipient[recipient_id].append(message)\n\n        # Process grouped messages\n        for recipient_id, messages in by_recipient.items():\n            for message in messages:\n                await self._process_incoming_message(recipient_id, message, self._cache_tick)\n\n        self._message_batch.clear()\n</code></pre>"},{"location":"developer/creating-systems/#error-handling-and-recovery","title":"Error Handling and Recovery","text":"<p>Implement robust error handling:</p> <pre><code>class RobustCommunicationSystem(CommunicationSystem):\n    \"\"\"Communication system with comprehensive error handling.\"\"\"\n\n    async def on_communicate(self, event_data: Dict[str, Any]) -&gt; None:\n        \"\"\"Handle communication with comprehensive error recovery.\"\"\"\n\n        try:\n            entity_id = event_data[\"entity_id\"]\n            action_plan = event_data[\"action_plan_component\"]\n            params = action_plan.params\n\n            # Validate with detailed error reporting\n            validation_result = self._validate_communication_detailed(entity_id, params)\n            if not validation_result.success:\n                self._publish_failure(event_data, validation_result.error_message)\n                return\n\n            # Process with timeout protection\n            success = await asyncio.wait_for(\n                self._process_communication_safe(entity_id, params, event_data.get(\"current_tick\", 0)),\n                timeout=5.0  # 5 second timeout\n            )\n\n            if success:\n                self._publish_success(event_data)\n            else:\n                self._publish_failure(event_data, \"Communication processing failed\")\n\n        except asyncio.TimeoutError:\n            self._publish_failure(event_data, \"Communication timed out\")\n            print(f\"WARNING: Communication system timed out for agent {entity_id}\")\n\n        except Exception as e:\n            self._publish_failure(event_data, f\"System error: {str(e)}\")\n            print(f\"ERROR: Communication system exception: {e}\")\n\n            # Log error for debugging\n            if hasattr(self, 'logger'):\n                self.logger.error(f\"Communication system error: {e}\", exc_info=True)\n\n    def _validate_communication_detailed(self, sender_id: str, params: Dict[str, Any]):\n        \"\"\"Detailed validation with specific error messages.\"\"\"\n\n        from dataclasses import dataclass\n\n        @dataclass\n        class ValidationResult:\n            success: bool\n            error_message: str = \"\"\n\n        # Check sender exists\n        if not self.simulation_state.entity_exists(sender_id):\n            return ValidationResult(False, \"Sender does not exist\")\n\n        # Check sender has communication component\n        comm_comp = self.simulation_state.get_component(sender_id, CommunicationComponent)\n        if not comm_comp:\n            return ValidationResult(False, \"Sender lacks communication capability\")\n\n        # Check cooldown\n        if comm_comp.communication_cooldown &gt; 0:\n            return ValidationResult(False, f\"Sender on cooldown for {comm_comp.communication_cooldown} ticks\")\n\n        # Additional validations...\n\n        return ValidationResult(True)\n</code></pre> <p>This comprehensive communication system demonstrates advanced patterns for building robust, scalable systems in ARLA while maintaining the core principles of modularity and event-driven design.</p>"},{"location":"developer/event-bus/","title":"Developer Guide: The Event Bus","text":"<p>In the ARLA framework, systems are designed to be completely isolated from one another. A MovementSystem has no direct knowledge of a CombatSystem, and neither knows about the ReflectionSystem. This decoupling is achieved through a central communication channel: the Event Bus.</p> <p>Understanding how to use the Event Bus is essential for creating new systems and extending the A-life simulation.</p>"},{"location":"developer/event-bus/#1-what-is-the-event-bus","title":"1. What is the Event Bus?","text":"<p>The Event Bus is a simple but powerful implementation of the publish-subscribe design pattern.</p> <p>Publishing: When something significant happens in a system (e.g., an action is completed, an agent's state changes), that system can \"publish\" an event to the bus. An event is just a string name (e.g., \"action_executed\") and a dictionary of data.</p> <p>Subscribing: Other systems can \"subscribe\" to specific event names. When an event is published, the Event Bus automatically calls the handler methods of all subscribed systems, passing them the event data.</p> <p>This pattern ensures that systems don't need to know about each other, making the entire architecture highly modular and easy to test.</p>"},{"location":"developer/event-bus/#2-how-to-subscribe-to-an-event","title":"2. How to Subscribe to an Event","text":"<p>You subscribe to an event within a system's <code>__init__</code> method. The System base class provides access to the event bus via <code>self.event_bus</code>.</p>"},{"location":"developer/event-bus/#example-a-system-listening-for-agent-deaths","title":"Example: A System Listening for Agent Deaths","text":"<pre><code># simulations/my_sim/systems/graveyard_system.py\n\nfrom agent_engine.simulation.system import System\n\nclass GraveyardSystem(System):\n    \"\"\"A system that listens for agent deactivation and logs it.\"\"\"\n\n    def __init__(self, simulation_state, config, cognitive_scaffold):\n        super().__init__(simulation_state, config, cognitive_scaffold)\n\n        # Subscribe the 'on_agent_deactivated' method to the 'agent_deactivated' event\n        if self.event_bus:\n            self.event_bus.subscribe(\"agent_deactivated\", self.on_agent_deactivated)\n\n    def on_agent_deactivated(self, event_data: dict) -&gt; None:\n        \"\"\"This method is called whenever an 'agent_deactivated' event is published.\"\"\"\n        agent_id = event_data.get(\"entity_id\")\n        final_tick = event_data.get(\"current_tick\")\n        print(f\"GraveyardSystem: Agent {agent_id} was deactivated at tick {final_tick}.\")\n\n    async def update(self, current_tick: int):\n        # This system is purely event-driven\n        pass\n</code></pre>"},{"location":"developer/event-bus/#3-how-to-publish-an-event","title":"3. How to Publish an Event","text":"<p>You can publish an event from any system by calling <code>self.event_bus.publish()</code>.</p>"},{"location":"developer/event-bus/#example-a-system-that-triggers-a-heatwave","title":"Example: A System that Triggers a Heatwave","text":"<pre><code># simulations/my_sim/systems/weather_system.py\n\nfrom agent_engine.simulation.system import System\n\nclass WeatherSystem(System):\n    \"\"\"A system that manages the weather and can trigger heatwaves.\"\"\"\n\n    async def update(self, current_tick: int):\n        # Every 100 ticks, trigger a heatwave\n        if current_tick &gt; 0 and current_tick % 100 == 0:\n            print(\"WeatherSystem: A heatwave has begun!\")\n\n            event_data = {\n                \"temperature_increase\": 20.0,\n                \"duration_ticks\": 50,\n                \"current_tick\": current_tick,\n            }\n\n            # Publish the 'heatwave_started' event for other systems to react to\n            if self.event_bus:\n                self.event_bus.publish(\"heatwave_started\", event_data)\n</code></pre>"},{"location":"developer/event-bus/#4-core-engine-events","title":"4. Core Engine Events","text":"<p>The ARLA agent-engine publishes several core events that your custom systems can subscribe to. These are the primary hooks for integrating your world's logic with the main simulation loop.</p>"},{"location":"developer/event-bus/#action_chosen","title":"<code>action_chosen</code>","text":"<p>Published when an agent's DecisionSelector has chosen an action for the current tick.</p> <p>event_data: <code>{ \"entity_id\": str, \"action_plan_component\": ActionPlanComponent, \"current_tick\": int }</code></p>"},{"location":"developer/event-bus/#execute_action_id_action","title":"<code>execute_{action_id}_action</code>","text":"<p>A dynamic event fired by the ActionSystem. Your world-specific systems should subscribe to these to implement the logic for your custom actions.</p> <p>event_data: Same as <code>action_chosen</code>.</p>"},{"location":"developer/event-bus/#action_outcome_ready","title":"<code>action_outcome_ready</code>","text":"<p>Your world-specific system must publish this event after it has fully handled an <code>execute_*</code> event. This signals that the action is resolved.</p> <p>event_data: Same as <code>action_chosen</code>, but now includes the ActionOutcome.</p>"},{"location":"developer/event-bus/#action_executed","title":"<code>action_executed</code>","text":"<p>Published by the ActionSystem after the final reward has been calculated. This is the main event for cognitive systems to listen to.</p> <p>event_data: <code>{ \"entity_id\": str, \"action_plan\": ActionPlanComponent, \"action_outcome\": ActionOutcome, \"current_tick\": int }</code></p>"},{"location":"developer/event-bus/#reflection_completed","title":"<code>reflection_completed</code>","text":"<p>Published by the ReflectionSystem after an agent has completed a full metacognitive cycle.</p> <p>event_data: <code>{ \"tick\": int, \"entity_id\": str, \"context\": dict }</code></p>"},{"location":"guides/installation/","title":"Installation &amp; Setup","text":"<p>Get ARLA running on your local machine in minutes. Our Docker-based setup ensures consistency across all platforms.</p> <p>What You'll Build</p> <p>By the end of this guide, you'll have a complete ARLA development environment with:</p> <ul> <li>Agent simulation engine with cognitive systems</li> <li>PostgreSQL database for experiment data</li> <li>MLflow tracking server for experiment management</li> <li>Redis message broker for distributed computing</li> </ul>"},{"location":"guides/installation/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have these tools installed:</p> <ul> <li> <p> Git</p> <p>For cloning the repository and version control.</p> <p>Download Git</p> </li> <li> <p> Docker &amp; Docker Compose</p> <p>For running the containerized development environment.</p> <p>Download Docker</p> </li> <li> <p> OpenAI API Key</p> <p>Required for cognitive systems that use Large Language Models.</p> <p>Get API Key</p> </li> </ul>"},{"location":"guides/installation/#step-1-clone-the-repository","title":"Step 1: Clone the Repository","text":"<p>Get the latest version of ARLA from GitHub:</p> HTTPSSSHGitHub CLI <pre><code>git clone https://github.com/renbytes/arla.git\ncd arla\n</code></pre> <pre><code>git clone git@github.com:renbytes/arla.git\ncd arla\n</code></pre> <pre><code>gh repo clone renbytes/arla\ncd arla\n</code></pre>"},{"location":"guides/installation/#step-2-configure-environment","title":"Step 2: Configure Environment","text":"<p>ARLA uses environment variables for sensitive configuration like API keys.</p>"},{"location":"guides/installation/#create-configuration-file","title":"Create Configuration File","text":"<p>The <code>Makefile</code> includes a convenient setup command:</p> <pre><code>make setup\n</code></pre> <p>This copies <code>.env.example</code> to <code>.env</code> with default values.</p>"},{"location":"guides/installation/#add-your-api-key","title":"Add Your API Key","text":"<p>Open the newly created <code>.env</code> file and add your OpenAI API key:</p> .env<pre><code># --- OpenAI API Key (Required) ---\nOPENAI_API_KEY=sk-YourSecretKeyGoesHere\n\n# --- Database Configuration ---\nPOSTGRES_USER=admin\nPOSTGRES_PASSWORD=password\nPOSTGRES_DB=agent_sim_db\n\n# --- MLflow Configuration ---\nMLFLOW_TRACKING_URI=http://mlflow:5000\nMLFLOW_TRACKING_USERNAME=admin\nMLFLOW_TRACKING_PASSWORD=password\n</code></pre> <p>API Key Security</p> <p>Never commit your <code>.env</code> file to version control. It's already included in <code>.gitignore</code>.</p>"},{"location":"guides/installation/#step-3-build-and-start-services","title":"Step 3: Build and Start Services","text":"<p>Launch the complete ARLA environment with a single command:</p> <pre><code>make up\n</code></pre>"},{"location":"guides/installation/#what-happens-during-setup","title":"What Happens During Setup","text":"<ul> <li> <p>1. Image Building</p> <p>Docker builds custom images for the application and worker services, installing Python dependencies with Poetry.</p> </li> <li> <p>2. Service Startup</p> <p>Launches PostgreSQL database, Redis message broker, and MLflow tracking server with health checks.</p> </li> <li> <p>3. Dependency Caching</p> <p>Creates shared volumes to cache Python dependencies, making subsequent builds much faster.</p> </li> </ul> <p>First Run Performance</p> <p>The initial setup may take 5-10 minutes to download images and install dependencies. Subsequent runs are much faster thanks to Docker's caching.</p>"},{"location":"guides/installation/#step-4-verify-installation","title":"Step 4: Verify Installation","text":"<p>Confirm everything is working correctly:</p>"},{"location":"guides/installation/#check-service-status","title":"Check Service Status","text":"<pre><code>docker compose ps\n</code></pre> <p>You should see all services running with <code>healthy</code> status:</p> <pre><code>NAME            STATUS                    PORTS\narla-app-1      Up (healthy)             \narla-worker-1   Up (healthy)             \narla-db-1       Up (healthy)             0.0.0.0:5432-&gt;5432/tcp\narla-redis-1    Up (healthy)             0.0.0.0:6379-&gt;6379/tcp\narla-mlflow-1   Up (healthy)             0.0.0.0:5001-&gt;5000/tcp\n</code></pre>"},{"location":"guides/installation/#run-example-simulation","title":"Run Example Simulation","text":"<p>Test the installation with a pre-configured simulation:</p> <pre><code>make run-example\n</code></pre> <p>Expected Output: <pre><code>\u2705 Database connection successful\n\ud83d\udcca MLflow tracking enabled\n\ud83e\udd16 Spawning 10 agents in 50x50 grid world\n\u26a1 Starting simulation with 1000 ticks...\n</code></pre></p>"},{"location":"guides/installation/#access-mlflow-ui","title":"Access MLflow UI","text":"<p>Open your browser and navigate to http://localhost:5001 to view the experiment tracking interface.</p> <p>Installation Complete!</p> <p>You now have a complete ARLA development environment running locally. You're ready to start building simulations!</p>"},{"location":"guides/installation/#next-steps","title":"Next Steps","text":"<ul> <li> <p> Build Your First Simulation</p> <p>Follow our step-by-step tutorial to create a custom simulation from scratch.</p> <p> Start Tutorial</p> </li> <li> <p> Run Experiments</p> <p>Learn how to design and execute large-scale experiments with multiple configurations.</p> <p> Running Simulations</p> </li> <li> <p> Architecture Deep Dive</p> <p>Understand ARLA's modular design and cognitive architecture components.</p> <p> Architecture Guide</p> </li> </ul>"},{"location":"guides/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/installation/#common-issues","title":"Common Issues","text":"Docker Services Won't Start <p>Problem: Services fail to start or remain unhealthy</p> <p>Solutions: <pre><code># Check if ports are already in use\nnetstat -tlnp | grep ':5432\\|:6379\\|:5001'\n\n# Reset and rebuild\ndocker compose down -v\ndocker compose build --no-cache\ndocker compose up -d\n</code></pre></p> MLflow Authentication Errors <p>Problem: 401 Unauthorized when accessing MLflow UI</p> <p>Solutions: - Verify credentials in <code>.env</code> file match MLflow configuration - Check MLflow logs: <code>docker compose logs mlflow</code> - Restart MLflow service: <code>docker compose restart mlflow</code></p> API Key Not Working <p>Problem: OpenAI API errors during simulation</p> <p>Solutions: - Verify API key is valid and has credits - Check the key starts with <code>sk-</code> - Ensure no extra spaces in <code>.env</code> file</p>"},{"location":"guides/installation/#getting-help","title":"Getting Help","text":"<ul> <li>Documentation: Browse our comprehensive guides</li> <li>GitHub Issues: Report bugs and request features</li> <li>Community: Join discussions in our GitHub repository</li> </ul> <p>Ready to build your first simulation? Follow our tutorial guide to create agents from scratch.</p>"},{"location":"guides/running-simulations/","title":"Running Simulations &amp; Experiments","text":"<p>The ARLA framework provides two distinct workflows for running simulations, each tailored to a specific need: quick, iterative development and large-scale, rigorous experimentation. Understanding when to use each is key to an efficient research process.</p>"},{"location":"guides/running-simulations/#1-local-development-make-run-local","title":"1. Local Development: <code>make run-local</code>","text":"<p>For day-to-day development, debugging, or visualizing a single simulation run, the <code>run-local</code> command is your primary tool. It executes a single simulation directly inside the main <code>app</code> container, bypassing the distributed Celery workers.</p>"},{"location":"guides/running-simulations/#when-to-use-it","title":"When to Use It","text":"<ul> <li>Testing a new feature or system</li> <li>Debugging an agent's behavior</li> <li>Quickly generating a GIF for a specific scenario</li> <li>Running a one-off simulation without the overhead of the experiment queue</li> </ul>"},{"location":"guides/running-simulations/#how-to-use-it","title":"How to Use It","text":"<p>The <code>run-local</code> command requires you to specify the simulation's package, configuration file, and scenario file.</p> <pre><code>make run-local \\\n  PACKAGE=\"simulations.berry_sim\" \\\n  CONFIG=\"simulations/berry_sim/config/config.yml\" \\\n  FILE=\"simulations/berry_sim/scenarios/default.json\"\n</code></pre>"},{"location":"guides/running-simulations/#2-research-ab-tests-make-run","title":"2. Research &amp; A/B Tests: <code>make run</code>","text":"<p>For formal research, A/B tests, or any large-scale data collection, the <code>run</code> command provides a powerful, distributed workflow. It uses Celery to manage a queue of simulation jobs, allowing you to run many simulations in parallel across multiple worker processes.</p>"},{"location":"guides/running-simulations/#when-to-use-it_1","title":"When to Use It","text":"<ul> <li>Running ablation studies with multiple variations</li> <li>Executing a scenario multiple times with different random seeds for statistical significance</li> <li>Long-running simulations that you want to execute in the background</li> </ul>"},{"location":"guides/running-simulations/#how-to-use-it_1","title":"How to Use It","text":"<p>This command requires a single <code>FILE</code> argument pointing to an experiment definition YAML file. This file orchestrates the entire experiment.</p> <pre><code># This will automatically start 4 workers and submit the experiment\nmake run FILE=simulations/berry_sim/experiments/causal_ab_test.yml\n\n# To run with more parallel processes, specify the number of workers\nmake run FILE=simulations/berry_sim/experiments/causal_ab_test.yml WORKERS=8\n</code></pre>"},{"location":"guides/running-simulations/#3-analyzing-your-results","title":"3. Analyzing Your Results","text":"<p>Whether you run a local simulation or a full experiment, ARLA produces a consistent set of outputs designed for comprehensive analysis.</p> <ul> <li>MLflow UI (http://localhost:5001): Your first stop for high-level analysis. Use it to compare metrics between different runs in an experiment, view parameters, and get a quick overview of the results.</li> <li>PostgreSQL Database: For deep, granular analysis. The database contains a complete, tick-by-tick record of every agent's state and every action taken. Use a SQL client to connect to the database on port <code>5432</code> and run custom queries.</li> <li>Run Directory (<code>data/logs/</code>): Each simulation creates a unique directory containing artifacts for reproducibility, including the exact configuration file used and periodic snapshots of the simulation state.</li> </ul>"},{"location":"guides/running-simulations/#4-visualization-creating-a-gif","title":"4. Visualization: Creating a GIF","text":"<p>To create a visual representation of a simulation, you first need to enable rendering in its configuration file.</p> <ol> <li>Enable Rendering: In your simulation's <code>config.yml</code>, set <code>rendering.enabled</code> to <code>true</code>.</li> <li>Run the Simulation: Run either a <code>local-run</code> or a full <code>run</code>. The image frames will be saved to a unique subdirectory named after the <code>Run ID</code>.</li> <li>Find the Run ID: Go to the MLflow UI to find the <code>Run ID</code> of the specific simulation you want to visualize.</li> <li>Generate the GIF: Use the <code>make-gif</code> command, providing the base render directory and the specific <code>RUN_ID</code>.</li> </ol> <pre><code># Example for a berry_sim run\nmake make-gif RENDER_DIR=data/gif_renders/berry_sim RUN_ID=d6e572a855844e21a13e0e85b254fa96\n</code></pre> <p>This will create a uniquely named GIF (e.g., <code>simulation-71bcad3e64a346618715e3b8be195e16.gif</code>) in the project root.</p>"},{"location":"guides/understanding-output/","title":"Understanding the Simulation Output","text":"<p>After running a simulation, the ARLA framework generates a set of files and data designed to make your results transparent, reproducible, and easy to analyze. This guide explains the key outputs and where to find them.</p>"},{"location":"guides/understanding-output/#1-the-run-directory","title":"1. The Run Directory","text":"<p>Every simulation run creates a unique, timestamped directory inside <code>data/logs/</code>. This directory is the central location for all artifacts related to that specific run.</p> <p>A typical run directory looks like this:</p> <pre><code>data/logs/\n\u2514\u2500\u2500 20250818_041805_d5c8f0ec-b0bd-4f0f-91f6-b35941f6ea51/\n    \u251c\u2500\u2500 manifest.json\n    \u251c\u2500\u2500 resolved_config.yml\n    \u2514\u2500\u2500 snapshots/\n        \u2514\u2500\u2500 snapshot_tick_50.json\n</code></pre> <ul> <li><code>manifest.json</code>: A critical file for reproducibility. It contains essential metadata about the run, including the unique run ID, the Git commit hash, and the random seed used.</li> <li><code>resolved_config.yml</code>: An exact copy of the configuration used for the run, including all base settings and any overrides from an experiment file.</li> <li><code>snapshots/</code>: This directory contains full snapshots of the simulation state, saved periodically. These can be used to resume a simulation or to analyze the state at a specific point in time.</li> </ul>"},{"location":"guides/understanding-output/#2-the-database","title":"2. The Database","text":"<p>The most detailed, granular data from your simulation is stored in a PostgreSQL database. This includes:</p> <ul> <li>Agent States: A snapshot of every agent's components at every single tick.</li> <li>Events: A log of every action taken by every agent, including the outcome and reward.</li> <li>LLM Interactions: A complete record of every prompt sent to the LLM and the corresponding response.</li> <li>Metrics: Aggregated, simulation-wide metrics for each tick.</li> </ul> <p>You can connect to this database using any standard SQL client to perform detailed analysis.</p>"},{"location":"guides/understanding-output/#3-mlflow-tracking","title":"3. MLflow Tracking","text":"<p>For high-level analysis and comparison between runs, ARLA is integrated with MLflow. The MLflow UI provides a powerful way to visualize and compare the results of your experiments.</p>"},{"location":"guides/understanding-output/#accessing-the-mlflow-ui","title":"Accessing the MLflow UI","text":"<p>While your Docker services are running, you can access the MLflow UI in your web browser at:</p> <p>http://localhost:5001</p>"},{"location":"guides/understanding-output/#what-to-look-for","title":"What to Look For","text":"<ul> <li>Experiments: Your runs will be grouped by the <code>experiment_name</code> defined in your experiment file.</li> <li>Parameters: MLflow logs all the configuration parameters for each run, making it easy to see what changed between different variations.</li> <li>Metrics: Key performance indicators, like average agent reward or total resources, are plotted over time. This is the best way to visualize the high-level dynamics of your simulation.</li> <li>Tags: Important metadata, like the run ID and status, are stored as tags.</li> </ul> <p>Using these three outputs\u2014the run directory, the database, and the MLflow UI\u2014you have a complete and auditable record of every simulation you run.</p>"},{"location":"papers/architecture/arla_intro/","title":"ARLA: A Modular ECS-Based Platform for Ablative Studies in Multi-Agent Cognitive Architecture","text":"<p>Authors: Brian Deely</p> <p>Affiliation: Independent Researcher</p>"},{"location":"papers/architecture/arla_intro/#abstract","title":"Abstract","text":"<p>Research into complex, believable agent behavior requires simulation platforms that are both powerful and easy to modify. Existing tools are often monolithic, making it difficult to perform targeted experiments, such as ablative studies of cognitive components. In this paper, we introduce the Affective Reinforcement Learning Architecture (ARLA), a novel open-source simulation platform designed specifically for building and experimenting with cognitive agents. ARLA is architected using the Entity-Component-System (ECS) pattern, which enforces a clean separation between an agent's core cognitive logic and the rules of the simulated world. We detail its modular design, including a world-agnostic cognitive engine, a concurrent execution manager, and a robust state persistence layer. By demonstrating its use in an exemplar simulation, we show that ARLA provides a flexible and extensible foundation for conducting reproducible research into emergent social phenomena, agent economics, and the foundations of artificial morality.</p>"},{"location":"papers/architecture/arla_intro/#1-introduction","title":"1. Introduction","text":"<p>Motivation: The recent success of large language models has renewed interest in creating autonomous agents that exhibit believable, human-like behavior (e.g., Park et al., 2023). This pursuit requires sophisticated and transparent simulation environments to serve as digital laboratories.</p> <p>The Problem: A primary challenge is the tight coupling of agent \"minds\" and world \"physics\" in many existing simulators. This makes it difficult to isolate and study the effects of specific cognitive mechanisms (e.g., \"How does an agent's behavior change if we disable its ability to form a stable identity?\"). This process, known as ablative analysis, is critical for cognitive science but is poorly supported by monolithic architectures.</p> <p>Our Contribution: We present ARLA, a platform designed to solve this problem. Its core contribution is its modularity, enforced by:</p> <ul> <li>A decoupled architecture based on the Entity-Component-System (ECS) pattern.</li> <li>A clear separation of concerns between a reusable, world-agnostic cognitive engine and world-specific implementations.</li> <li>A system of provider interfaces that act as a bridge, allowing the engine to operate without depending on concrete world details.</li> </ul> <p>Paper Outline: We will first survey related work, then detail ARLA's architecture, demonstrate its use in a concrete simulation, evaluate its performance, and conclude by discussing the experimental possibilities it enables.</p>"},{"location":"papers/architecture/arla_intro/#2-related-work","title":"2. Related Work","text":"<p>Agent-Based Modeling (ABM) Platforms: We position ARLA relative to established ABM frameworks like NetLogo (Tisue &amp; Wilensky, 2004) and Repast (North et al., 2013), noting that while they are powerful for large-scale population dynamics, ARLA focuses more deeply on the rich internal cognitive and affective states of individual agents. We also compare it to modern Python-based alternatives like Mesa (Masad &amp; Kazil, 2015).</p> <p>AI Simulation Environments: We contrast ARLA with environments designed primarily for reinforcement learning, such as the Unity ML-Agents Toolkit or DeepMind's Melting Pot. While these are excellent for training policies, ARLA is designed as an observable \"digital terrarium\" for studying the emergent behavior of pre-defined cognitive architectures, in the vein of the \"Generative Agents\" simulation (Park et al., 2023).</p> <p>Cognitive Architectures: ARLA is not a cognitive architecture itself, but a testbed for implementing their components. We draw inspiration from classic architectures like SOAR (Laird, 2012) and ACT-R (Anderson, 2007), whose theories on memory, goal-handling, and decision-making inform the design of ARLA's cognitive systems (e.g., MemoryComponent, GoalSystem).</p>"},{"location":"papers/architecture/arla_intro/#table-1-feature-comparison-with-existing-platforms","title":"Table 1: Feature Comparison with Existing Platforms","text":"Feature ARLA NetLogo Unity ML-Agents Mesa Repast Cognitive Architecture Support \u2713 Limited \u2717 Limited Limited Ablative Studies \u2713 \u2717 \u2717 \u2717 \u2717 LLM Integration \u2713 \u2717 \u2717 \u2717 \u2717 Async Execution \u2713 \u2717 \u2713 \u2717 \u2713 State Persistence \u2713 \u2713 Limited \u2713 \u2713 Provider Pattern \u2713 \u2717 \u2717 \u2717 \u2717 Built-in Emotion Model \u2713 \u2717 \u2717 \u2717 \u2717"},{"location":"papers/architecture/arla_intro/#3-the-arla-framework-architecture","title":"3. The ARLA Framework Architecture","text":"<p>This section details the design of the monorepo's core packages.</p> <p>[DIAGRAM PLACEHOLDER: Three-layer architecture diagram showing agent-core, agent-engine, and agent-sim layers with arrows indicating dependencies and data flow]</p>"},{"location":"papers/architecture/arla_intro/#31-design-philosophy-the-ecs-pattern","title":"3.1. Design Philosophy: The ECS Pattern","text":"<ul> <li>Entities: Unique IDs representing agents or environmental objects.</li> <li>Components: Plain data containers holding an agent's state (e.g., IdentityComponent, HealthComponent).</li> <li>Systems: The logic that operates on entities possessing specific components (e.g., AffectSystem, DecaySystem).</li> </ul> <p>This design choice is justified by its proven flexibility and performance in game development, which shares many challenges with agent simulation (Nystrom, 2014).</p>"},{"location":"papers/architecture/arla_intro/#32-agent-core-foundational-interfaces","title":"3.2. agent-core: Foundational Interfaces","text":"<p>Defines the \"contract\" for the entire platform. Details key abstractions like Component, ActionInterface, and the provider interfaces. This section emphasizes that any new simulation built with ARLA must adhere to these contracts.</p> <p>Key interfaces include: - <code>Component</code>: Base class with <code>to_dict()</code> and <code>validate()</code> methods - <code>ActionInterface</code>: Contract for all agent actions - <code>VitalityMetricsProviderInterface</code>: Bridge for health/resource data - <code>NarrativeContextProviderInterface</code>: Bridge for LLM-based reflection - <code>StateEncoderInterface</code>: Bridge for Q-learning state representation</p>"},{"location":"papers/architecture/arla_intro/#33-agent-engine-the-cognitive-engine","title":"3.3. agent-engine: The Cognitive Engine","text":"<p>Details the world-agnostic systems that constitute an agent's \"mind\":</p> <p>[DIAGRAM PLACEHOLDER: System interaction diagram showing event flow between cognitive systems]</p> <ul> <li>ActionSystem &amp; RewardCalculator: Handling action outcomes and subjective rewards based on agent values.</li> <li>AffectSystem &amp; EmotionalDynamics: Modeling emotion via appraisal theory (Scherer, 2001), incorporating goal relevance, controllability, and social context.</li> <li>IdentitySystem: Managing a multi-domain model of an agent's self-concept across social, competence, moral, relational, and agency dimensions.</li> <li>ReflectionSystem &amp; GoalSystem: Processing experiences into narrative memories and generating goals through LLM-based reflection.</li> <li>QLearningSystem: A utility-based decision-making module with neural network function approximation.</li> <li>CausalGraphSystem: Building and maintaining a graph of cause-effect relationships from agent experiences.</li> </ul>"},{"location":"papers/architecture/arla_intro/#34-agent-concurrent-agent-persist-pluggable-infrastructure","title":"3.4. agent-concurrent &amp; agent-persist: Pluggable Infrastructure","text":"<p>agent-concurrent: Provides <code>AsyncSystemRunner</code> and <code>SerialSystemRunner</code> for flexible execution strategies, allowing researchers to choose between performance and deterministic debugging.</p> <p>agent-persist: Implements state serialization using Pydantic models, enabling checkpoint/restore functionality and post-hoc analysis of agent trajectories.</p>"},{"location":"papers/architecture/arla_intro/#35-key-implementation-decisions","title":"3.5. Key Implementation Decisions","text":"<ul> <li>Event-driven Architecture: Systems communicate via an event bus rather than direct calls, enabling loose coupling and easy instrumentation.</li> <li>Async/Await for Concurrency: Python's asyncio enables concurrent system updates without threading complexity.</li> <li>Provider Pattern: Dependency injection allows world-agnostic systems to access world-specific data.</li> <li>LLM Integration: Centralized <code>CognitiveScaffold</code> manages all LLM interactions with caching, cost tracking, and structured prompt management.</li> <li>Deterministic Execution: Careful management of random seeds and execution order ensures reproducible simulations.</li> </ul>"},{"location":"papers/architecture/arla_intro/#4-exemplar-simulation-soul-sim","title":"4. Exemplar Simulation: soul-sim","text":"<p>This section demonstrates how the abstract framework is used to create a runnable simulation.</p>"},{"location":"papers/architecture/arla_intro/#41-world-implementation","title":"4.1. World Implementation","text":"<p>Defining world-specific components: <pre><code>class PositionComponent(Component):\n    \"\"\"Stores an entity's position in a 2D grid world.\"\"\"\n    def __init__(self, position: Tuple[int, int], environment: EnvironmentInterface):\n        self.position = position\n        self.history: deque[Tuple[int, int]] = deque(maxlen=20)\n        self.visited_positions: set[Tuple[int, int]] = {position}\n</code></pre></p> <p>Defining world-specific systems: <pre><code>class CombatSystem(System):\n    \"\"\"Processes combat actions between agents.\"\"\"\n    def on_execute_combat(self, event_data: Dict[str, Any]):\n        # Validate positions, calculate damage, update health\n        # Publish outcome for cognitive systems to process\n</code></pre></p>"},{"location":"papers/architecture/arla_intro/#42-bridging-the-world-and-engine","title":"4.2. Bridging the World and Engine","text":"<p>Showcasing a concrete implementation of a provider:</p> <pre><code>class SoulSimVitalityProvider(VitalityMetricsProviderInterface):\n    def get_normalized_vitality_metrics(\n        self, entity_id: str, components: Dict[Type[Component], Component], config: Dict[str, Any]\n    ) -&gt; Dict[str, float]:\n        health_comp = components.get(HealthComponent)\n        time_comp = components.get(TimeBudgetComponent)\n        inv_comp = components.get(InventoryComponent)\n\n        return {\n            \"health_norm\": health_comp.current_health / health_comp.initial_health,\n            \"time_norm\": time_comp.current_time_budget / time_comp.initial_time_budget,\n            \"resources_norm\": min(1.0, inv_comp.current_resources / 100.0)\n        }\n</code></pre>"},{"location":"papers/architecture/arla_intro/#43-a-simulation-in-action","title":"4.3. A Simulation in Action","text":"<p>Walk through a scenario: Agent A attacks Agent B.</p> <ol> <li>CombatSystem processes the attack, reduces B's health</li> <li>ActionSystem receives the outcome via event bus</li> <li>RewardCalculator applies A's value multipliers (combat_victory_multiplier)</li> <li>AffectSystem updates A's emotion based on prediction error</li> <li>IdentitySystem may strengthen A's \"competence\" domain if victorious</li> <li>SocialMemoryComponent updates B's impression of A as threatening</li> </ol> <p>[DIAGRAM PLACEHOLDER: Sequence diagram showing event flow for the combat scenario]</p>"},{"location":"papers/architecture/arla_intro/#44-cognitive-model-validation","title":"4.4. Cognitive Model Validation","text":"<p>We validate our cognitive models against established psychological baselines:</p> <ul> <li>Emotion Dynamics: Our appraisal-based emotion model produces valence/arousal trajectories consistent with [PLACEHOLDER: specific psychology studies]</li> <li>Identity Coherence: Multi-domain identity stability scores correlate with [PLACEHOLDER: social psychology metrics] at r=[PLACEHOLDER]</li> <li>Goal Emergence: Goal generation patterns match motivated behavior literature, with [PLACEHOLDER]% of goals relating to recent success experiences</li> </ul>"},{"location":"papers/architecture/arla_intro/#45-example-experiments","title":"4.5. Example Experiments","text":""},{"location":"papers/architecture/arla_intro/#451-identity-ablation-study","title":"4.5.1 Identity Ablation Study","text":"<ul> <li>Configuration: 100 agents, 50% with IdentitySystem disabled</li> <li>Metrics: Cooperation frequency, resource accumulation, survival time</li> <li>Preliminary Results: Agents without identity show [PLACEHOLDER]% less consistent behavior patterns and [PLACEHOLDER]% reduced cooperation</li> </ul>"},{"location":"papers/architecture/arla_intro/#452-economic-emergence","title":"4.5.2 Economic Emergence","text":"<ul> <li>Setup: Variable resource scarcity (abundant/scarce/depleting)</li> <li>Observed Behaviors:</li> <li>Trading emerges in [PLACEHOLDER]% of scarce resource conditions</li> <li>Territorial defense correlates with resource respawn time (r=[PLACEHOLDER])</li> <li>Wealth inequality (Gini coefficient) reaches [PLACEHOLDER] after 1000 ticks</li> </ul>"},{"location":"papers/architecture/arla_intro/#5-performance-evaluation","title":"5. Performance Evaluation","text":""},{"location":"papers/architecture/arla_intro/#51-scalability-analysis","title":"5.1 Scalability Analysis","text":"<p>[DIAGRAM PLACEHOLDER: Performance graphs showing scalability metrics]</p> Agent Count Ticks/Second Memory (MB) With AsyncRunner With SerialRunner 100 [PLACEHOLDER] [PLACEHOLDER] [PLACEHOLDER] [PLACEHOLDER] 1,000 [PLACEHOLDER] [PLACEHOLDER] [PLACEHOLDER] [PLACEHOLDER] 10,000 [PLACEHOLDER] [PLACEHOLDER] [PLACEHOLDER] [PLACEHOLDER] <p>Database Performance: - Write throughput: [PLACEHOLDER] events/second with batch size 1000 - Query latency for analysis: [PLACEHOLDER]ms for tick-range queries</p>"},{"location":"papers/architecture/arla_intro/#52-computational-overhead","title":"5.2 Computational Overhead","text":"<ul> <li>Provider Abstraction: [PLACEHOLDER]% overhead vs direct component access</li> <li>Event Bus: [PLACEHOLDER] microseconds per event dispatch</li> <li>LLM Integration:</li> <li>Average [PLACEHOLDER] API calls per agent per 100 ticks</li> <li>Cost: $[PLACEHOLDER] per 1000-agent-tick simulation</li> <li>Cache hit rate: [PLACEHOLDER]% for reflection prompts</li> </ul>"},{"location":"papers/architecture/arla_intro/#53-reproducibility-features","title":"5.3 Reproducibility Features","text":"<ul> <li>Deterministic Execution: Identical seeds produce bit-identical results across runs</li> <li>Configuration Validation: Pydantic schemas catch [PLACEHOLDER]% of configuration errors</li> <li>State Snapshots: Full state serialization in [PLACEHOLDER]ms for 1000 agents</li> <li>MLflow Integration: Automatic experiment tracking with hyperparameters, metrics, and artifacts</li> </ul>"},{"location":"papers/architecture/arla_intro/#6-community-and-ecosystem","title":"6. Community and Ecosystem","text":"<p>The ARLA platform is available at [https://github.com/PLACEHOLDER/arla] under the MIT license.</p> <p>Resources Available: - Comprehensive documentation with tutorials - Example experiments and configurations - Plugin template for custom cognitive systems - Discord community for researchers</p> <p>Standardized Formats: - Experiment configuration schemas - Agent behavior trace format - Cognitive component interchange format</p> <p>Planned Activities: - Annual workshop at [PLACEHOLDER] conference - Online competition for emergent behavior discovery - Model zoo for pre-trained agent configurations</p>"},{"location":"papers/architecture/arla_intro/#7-ethical-considerations","title":"7. Ethical Considerations","text":"<p>While ARLA enables powerful simulations of agent behavior, we acknowledge several ethical considerations:</p> <ul> <li>Potential Misuse: Simulations could model harmful behaviors or social dynamics</li> <li>LLM Reflections: Agent \"thoughts\" may reflect biases in underlying language models</li> <li>Computational Resources: Large simulations have environmental impact</li> <li>Responsible Disclosure: We commit to responsible disclosure of emergent strategies that could be exploited</li> </ul> <p>We encourage researchers to consider the broader implications of their experiments and to use ARLA in ways that advance beneficial AI research.</p>"},{"location":"papers/architecture/arla_intro/#8-discussion-future-work","title":"8. Discussion &amp; Future Work","text":""},{"location":"papers/architecture/arla_intro/#strengths","title":"Strengths","text":"<ul> <li>Modularity for Ablative Studies: Researchers can disable systems (e.g., IdentitySystem) to isolate cognitive contributions</li> <li>Extensibility: New cognitive modules, actions, and worlds can be added via the provider pattern</li> <li>Reproducibility: Comprehensive state management and configuration validation</li> <li>Rich Cognitive Modeling: Integrated emotion, identity, goals, and social memory</li> </ul>"},{"location":"papers/architecture/arla_intro/#limitations","title":"Limitations","text":"<ul> <li>Python Performance: GIL limits true parallelism; C++/Rust extensions planned</li> <li>Memory Scaling: Current architecture requires ~[PLACEHOLDER]MB per agent</li> <li>LLM Costs: Reflection-heavy simulations can incur significant API costs</li> <li>Visualization: Limited real-time capabilities; post-hoc analysis focus</li> </ul>"},{"location":"papers/architecture/arla_intro/#technical-roadmap","title":"Technical Roadmap","text":"<ol> <li>Performance Enhancements:</li> <li>Rust core for performance-critical paths (Q3 2024)</li> <li>GPU acceleration for neural components (Q4 2024)</li> <li> <p>Distributed simulation across nodes (2025)</p> </li> <li> <p>Features:</p> </li> <li>Real-time web visualization dashboard</li> <li>Integration with PyTorch Lightning for advanced ML</li> <li>Standardized cognitive architecture benchmarks</li> <li>Natural language scenario specification</li> </ol>"},{"location":"papers/architecture/arla_intro/#research-agenda","title":"Research Agenda","text":"<ol> <li>Ablative Studies: Systematic analysis of each cognitive system's contribution to:</li> <li>Cooperative success in resource-limited environments</li> <li>Emergent communication protocols</li> <li> <p>Social hierarchy formation</p> </li> <li> <p>Economic Studies: Investigation of:</p> </li> <li>Conditions for currency emergence</li> <li>Impact of value system diversity on market dynamics</li> <li> <p>Commons management strategies</p> </li> <li> <p>Morality Studies: Implementation and comparison of:</p> </li> <li>Deontological vs. utilitarian reward calculators</li> <li>Evolution of moral norms through social feedback</li> <li>Punishment and altruism emergence</li> </ol>"},{"location":"papers/architecture/arla_intro/#9-conclusion","title":"9. Conclusion","text":"<p>The ARLA platform provides a robust, modular, and extensible tool for the computational study of artificial agents. By strictly separating an agent's mind from its environment, it lowers the barrier to entry for conducting complex, reproducible experiments in cognitive architecture. Early experiments demonstrate its utility for studying emergence in multi-agent systems, from economic behaviors to social dynamics. We have made the platform open-source to encourage collaboration and extension, and we look forward to the research community's contributions and discoveries.</p>"},{"location":"papers/architecture/arla_intro/#acknowledgments","title":"Acknowledgments","text":"<p>[PLACEHOLDER: Funding sources, collaborators, and institutional support]</p>"},{"location":"papers/architecture/arla_intro/#references","title":"References","text":"<p>Anderson, J. R. (2007). How can the human mind occur in the physical universe? Oxford University Press.</p> <p>Laird, J. E. (2012). The Soar cognitive architecture. MIT Press.</p> <p>Luke, S., Cioffi-Revilla, C., Panait, L., Sullivan, K., &amp; Balan, G. (2005). MASON: A multiagent simulation environment. Simulation, 81(7), 517-527.</p> <p>Masad, D., &amp; Kazil, J. (2015). MESA: An agent-based modeling framework. Proceedings of the 14th Python in Science Conference.</p> <p>North, M. J., Collier, N. T., Ozik, J., Tatara, E. R., Macal, C. M., Bragen, M., &amp; Sydelko, P. (2013). Complex adaptive systems modeling with Repast Simphony. Complex adaptive systems modeling, 1(1), 1-26.</p> <p>Nystrom, R. (2014). Game Programming Patterns. Genever Benning.</p> <p>Park, J. S., O'Brien, J. C., Cai, C. J., Morris, M. R., Liang, P., &amp; Bernstein, M. S. (2023). Generative Agents: Interactive Simulacra of Human Behavior. arXiv preprint arXiv:2304.03442.</p> <p>Scherer, K. R. (2001). Appraisal considered as a process of multilevel sequential checking. Appraisal processes in emotion: Theory, methods, research, 92(120), 57.</p> <p>Tisue, S., &amp; Wilensky, U. (2004). NetLogo: A simple environment for modeling complexity. Proceedings of the International Conference on Complex Systems.</p>"},{"location":"papers/architecture/arla_intro/#appendix-a-getting-started","title":"Appendix A: Getting Started","text":"<pre><code># Quick example of creating a custom cognitive system\nfrom agent_engine.simulation.system import System\nfrom agent_core.core.ecs.component import Component\n\nclass TrustComponent(Component):\n    def __init__(self):\n        self.trust_scores: Dict[str, float] = {}\n\n    def to_dict(self) -&gt; Dict[str, Any]:\n        return {\"trust_scores\": self.trust_scores}\n\n    def validate(self, entity_id: str) -&gt; Tuple[bool, List[str]]:\n        return True, []\n\nclass TrustSystem(System):\n    REQUIRED_COMPONENTS = [TrustComponent, SocialMemoryComponent]\n\n    async def update(self, current_tick: int):\n        # Update trust based on recent interactions\n        for entity_id, components in self.simulation_state.get_entities_with_components(\n            self.REQUIRED_COMPONENTS\n        ).items():\n            trust_comp = components[TrustComponent]\n            social_comp = components[SocialMemoryComponent]\n\n            # Custom trust dynamics based on interaction history\n            for other_id, schema in social_comp.schemas.items():\n                if schema.interaction_count &gt; 0:\n                    # Trust grows with positive interactions\n                    trust_comp.trust_scores[other_id] = min(1.0,\n                        trust_comp.trust_scores.get(other_id, 0.5) +\n                        0.1 * schema.impression_valence\n                    )\n</code></pre>"},{"location":"papers/architecture/arla_intro/#appendix-b-configuration-example","title":"Appendix B: Configuration Example","text":"<pre><code># Example configuration for an economic emergence experiment\nsimulation:\n  steps: 10000\n  random_seed: 42\n\nagent:\n  count: 50\n  start_health: 100\n  start_time_budget: 1000\n\nlearning:\n  memory:\n    reflection_interval: 100\n    emotion_cluster_min_data: 50\n  q_learning:\n    alpha: 0.001\n    gamma: 0.95\n    epsilon_start: 1.0\n    epsilon_end: 0.1\n\nworld:\n  grid_size: [50, 50]\n  resources:\n    spawn_probability: 0.02\n    types:\n      - name: \"food\"\n        respawn_time: 100\n        yield: 20\n      - name: \"materials\"\n        respawn_time: 500\n        yield: 50\n</code></pre> <p>[DIAGRAM PLACEHOLDER: Screenshot montage showing visualization output, MLflow dashboard, and analysis plots]</p>"},{"location":"simulations/checkpointing/","title":"Simulation Management Guide","text":"<p>This guide covers how to run, stop, and restore simulations in the ARLA framework.</p>"},{"location":"simulations/checkpointing/#1-how-to-run-a-new-simulation","title":"1. How to Run a New Simulation","text":"<p>This process involves starting the necessary background services (the message broker and Celery workers) and then submitting the experiment definition file.</p>"},{"location":"simulations/checkpointing/#prerequisites","title":"Prerequisites","text":"<p>You must have a message broker, like Redis, running. If you're using Docker, you can start one with:</p> <pre><code>docker run -d -p 6379:6379 redis\n</code></pre>"},{"location":"simulations/checkpointing/#steps","title":"Steps","text":"<ol> <li>Open a new terminal and start a Celery worker dedicated to running the actual simulations. This worker consumes from the <code>simulations</code> queue.</li> </ol> <pre><code>agentsim start-worker --queue simulations\n</code></pre> <ol> <li>Open a second terminal and start a Celery worker that orchestrates the experiments. This worker consumes from the <code>experiments</code> queue.</li> </ol> <pre><code>agentsim start-worker --queue experiments\n</code></pre> <ol> <li>Open a third terminal to submit your experiment. Point the command to your experiment definition file from the project root (<code>arla/</code>).</li> </ol> <pre><code>agentsim run-experiment agent-sim/experiments/test_ablation.yml\n</code></pre> <p>The orchestrator will read the file, create all the variations, and queue them for the simulation workers.</p>"},{"location":"simulations/checkpointing/#2-how-to-gracefully-stop-a-simulation","title":"2. How to Gracefully Stop a Simulation","text":"<p>To stop the simulation environment, you must shut down the Celery workers.</p> <ol> <li>Navigate to the terminals where your two Celery workers are running.</li> <li>Press <code>Ctrl+C</code> in each terminal.</li> </ol> <p>Celery will perform a \"warm shutdown.\" It will finish any simulation runs that are currently in progress but will not start any new ones from the queue.</p>"},{"location":"simulations/checkpointing/#3-how-to-restore-a-simulation-from-a-checkpoint","title":"3. How to Restore a Simulation from a Checkpoint","text":"<p>The CLI is designed to run new experiments. To restore a specific run from a checkpoint, you'll need to use a dedicated script.</p>"},{"location":"simulations/checkpointing/#steps_1","title":"Steps","text":"<ol> <li>Locate Your Checkpoint File. Checkpoints are saved automatically in the logs directory, with a path similar to this:</li> </ol> <pre><code>data/logs/snapshots/sim_1721334681_a4c1b3f2/snapshot_tick_150.json\n</code></pre> <ol> <li> <p>Create a Restore Script. Create a new Python file in your project, for example, <code>scripts/restore_run.py</code>.</p> </li> <li> <p>Add the Following Code. This script manually calls the <code>setup_and_run</code> function, passing in the path to your checkpoint.</p> </li> </ol> <pre><code># scripts/restore_run.py\nimport asyncio\nfrom omegaconf import OmegaConf\nfrom simulations.soul_sim.run import setup_and_run\n\n# CONFIGURATION\n# 1. Paste the path to your saved checkpoint file here\nCHECKPOINT_PATH = \"data/logs/snapshots/sim_1721334681_a4c1b3f2/snapshot_tick_150.json\"\n\n# 2. Provide IDs for the new, restored run\nRUN_ID = \"restored_run_01\"\nTASK_ID = \"manual_restore_01\"\nEXPERIMENT_ID = \"restored_experiment\"\n\n\nasync def main():\n    \"\"\"\n    Loads a base configuration, then runs the simulation starting\n    from the specified checkpoint.\n    \"\"\"\n    print(f\"--- Restoring simulation from: {CHECKPOINT_PATH}\")\n\n    # Load the base configuration file.\n    base_config = OmegaConf.load(\"simulations/soul_sim/config/base_config.yml\")\n\n    # The setup_and_run function handles the entire lifecycle\n    await setup_and_run(\n        run_id=RUN_ID,\n        task_id=TASK_ID,\n        experiment_id=EXPERIMENT_ID,\n        config_overrides=base_config,\n        checkpoint_path=CHECKPOINT_PATH,\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <ol> <li>Run the Script. Execute your new script from the terminal to start the simulation from the specified file.</li> </ol> <pre><code>python scripts/restore_run.py\n</code></pre>"},{"location":"simulations/checkpointing/#additional-notes","title":"Additional Notes","text":""},{"location":"simulations/checkpointing/#terminal-management","title":"Terminal Management","text":"<p>For better organization, consider using terminal multiplexers like <code>tmux</code> or <code>screen</code> to manage multiple workers:</p> <pre><code># Using tmux\ntmux new-session -d -s arla-workers\ntmux new-window -t arla-workers -n simulations 'agentsim start-worker --queue simulations'\ntmux new-window -t arla-workers -n experiments 'agentsim start-worker --queue experiments'\ntmux attach -t arla-workers\n</code></pre>"},{"location":"simulations/checkpointing/#monitoring","title":"Monitoring","text":"<p>You can monitor your Celery workers and queues using:</p> <pre><code># Check worker status\ncelery -A agent_sim.infrastructure.tasks.celery_app inspect active\n\n# Monitor in real-time (if Flower is installed)\ncelery -A agent_sim.infrastructure.tasks.celery_app flower\n</code></pre>"},{"location":"simulations/checkpointing/#troubleshooting","title":"Troubleshooting","text":"<p>Common Issues:</p> <ul> <li>Redis not running: Ensure Redis is started before launching workers</li> <li>Import errors: Make sure all packages are installed with <code>python install.py</code></li> <li>Permission errors: Check that the data/logs directory is writable</li> <li>Worker hangs: Use <code>Ctrl+C</code> followed by <code>kill -9 &lt;pid&gt;</code> if needed</li> </ul> <p>For more detailed logs, add <code>--loglevel=debug</code> to your worker commands.</p>"},{"location":"simulations/configuration/","title":"ARLA Project: New Simulation Configuration Guide","text":""},{"location":"simulations/configuration/#1-overview","title":"1. Overview","text":"<p>This guide outlines the standardized configuration system for all simulations within the ARLA project. The framework uses Pydantic for configuration management to ensure that all simulations are robust, type-safe, and easier to maintain. By following this pattern, you can catch configuration errors at startup, long before they cause problems deep within a simulation run.</p>"},{"location":"simulations/configuration/#2-creating-your-configuration-schema","title":"2. Creating Your Configuration Schema","text":"<p>For any new simulation (e.g., <code>your_new_sim</code>), you must define its complete configuration structure in a single, hierarchical Pydantic model.</p> <ul> <li>Action: Create a <code>schemas.py</code> file within your simulation's config directory (e.g., <code>simulations/your_new_sim/config/schemas.py</code>).</li> <li>Implementation: Inside this file, define a main Pydantic <code>BaseModel</code> (e.g., <code>YourNewSimAppConfig</code>) that contains all possible configuration parameters, nested into logical sub-models (like <code>AgentConfig</code>, <code>EnvironmentConfig</code>, etc.).</li> </ul> <p>This schema file becomes the single source of truth for your simulation's configuration. It serves as explicit, enforceable documentation, defining every parameter, its data type, and any validation rules (e.g., <code>Field(gt=0)</code>).</p>"},{"location":"simulations/configuration/#example-schema-structure","title":"Example Schema Structure","text":"<pre><code># simulations/your_new_sim/config/schemas.py\nfrom pydantic import BaseModel, Field\nfrom typing import Optional\n\nclass AgentConfig(BaseModel):\n    \"\"\"Configuration for agent behavior and properties.\"\"\"\n    max_health: int = Field(default=100, gt=0, description=\"Maximum health points\")\n    learning_rate: float = Field(default=0.01, gt=0, le=1, description=\"Learning rate for Q-learning\")\n    memory_size: int = Field(default=1000, gt=0, description=\"Size of agent memory buffer\")\n\nclass EnvironmentConfig(BaseModel):\n    \"\"\"Configuration for environment settings.\"\"\"\n    grid_size: int = Field(default=20, gt=0, description=\"Size of the grid world\")\n    resource_density: float = Field(default=0.1, ge=0, le=1, description=\"Density of resources\")\n    max_ticks: int = Field(default=1000, gt=0, description=\"Maximum simulation ticks\")\n\nclass YourNewSimAppConfig(BaseModel):\n    \"\"\"Complete configuration schema for YourNewSim simulation.\"\"\"\n    agent: AgentConfig = Field(default_factory=AgentConfig)\n    environment: EnvironmentConfig = Field(default_factory=EnvironmentConfig)\n    experiment_name: str = Field(default=\"default_experiment\", description=\"Name of the experiment\")\n    debug_mode: bool = Field(default=False, description=\"Enable debug logging\")\n</code></pre>"},{"location":"simulations/configuration/#3-the-validation-workflow","title":"3. The Validation Workflow","text":"<p>Your simulation's entry point (e.g., <code>simulations/your_new_sim/run.py</code>) is responsible for loading and validating the configuration. The standard workflow is:</p> <ol> <li>Load a base YAML configuration file (e.g., <code>simulations/your_new_sim/config/base_config.yml</code>).</li> <li>Use <code>OmegaConf</code> to merge any experiment-specific overrides on top of the base config.</li> <li>Pass the resulting dictionary into your Pydantic model (e.g., <code>config = YourNewSimAppConfig(**config_dict)</code>).</li> </ol> <p>This step will immediately parse and validate the entire configuration structure. If any required fields are missing, if a value has the wrong type, or if any validation rule fails, Pydantic will raise a detailed <code>ValidationError</code> and stop the application.</p>"},{"location":"simulations/configuration/#example-validation-code","title":"Example Validation Code","text":"<pre><code># simulations/your_new_sim/run.py\nimport asyncio\nfrom omegaconf import OmegaConf\nfrom pathlib import Path\nfrom .config.schemas import YourNewSimAppConfig\n\nasync def setup_and_run(\n    run_id: str,\n    task_id: str, \n    experiment_id: str,\n    config_overrides: dict,\n    checkpoint_path: str = None\n):\n    \"\"\"Main entry point for running the simulation.\"\"\"\n\n    # 1. Load base configuration\n    base_config_path = Path(__file__).parent / \"config\" / \"base_config.yml\"\n    base_config = OmegaConf.load(base_config_path)\n\n    # 2. Merge with any experiment overrides\n    final_config_dict = OmegaConf.merge(base_config, config_overrides)\n\n    # 3. Validate using Pydantic schema\n    try:\n        config = YourNewSimAppConfig(**final_config_dict)\n        print(\"\u2705 Configuration validation successful\")\n    except ValidationError as e:\n        print(f\"\u274c Configuration validation failed: {e}\")\n        raise\n\n    # 4. Run simulation with validated config\n    await run_simulation(config, run_id, task_id, experiment_id, checkpoint_path)\n</code></pre>"},{"location":"simulations/configuration/#4-how-to-use-the-configuration-in-code","title":"4. How to Use the Configuration in Code","text":"<p>Once validated, the <code>config</code> object\u2014an instance of your Pydantic model, not a dictionary\u2014should be passed down through your application, starting with the <code>SimulationManager</code>.</p> <p>To access configuration values, you must use direct attribute access. This provides full type safety and IDE autocompletion.</p>"},{"location":"simulations/configuration/#old-way-incorrect","title":"\u274c Old Way (Incorrect):","text":"<pre><code>time_decay = self.config.get(\"agent\", {}).get(\"dynamics\", {}).get(\"decay\", {}).get(\"time_budget_per_step\")\n</code></pre>"},{"location":"simulations/configuration/#new-way-correct","title":"\u2705 New Way (Correct):","text":"<pre><code>time_decay = self.config.agent.dynamics.decay.time_budget_per_step\n</code></pre>"},{"location":"simulations/configuration/#example-usage-in-classes","title":"Example Usage in Classes","text":"<pre><code># Example: Using config in a system class\nclass YourNewSimSystem(System):\n    def __init__(self, simulation_state: SimulationState, config: YourNewSimAppConfig):\n        super().__init__(simulation_state, config)\n\n        # Type-safe access with IDE autocompletion\n        self.max_health = config.agent.max_health\n        self.learning_rate = config.agent.learning_rate\n        self.grid_size = config.environment.grid_size\n\n        if config.debug_mode:\n            print(f\"Initialized with grid size: {self.grid_size}\")\n</code></pre>"},{"location":"simulations/configuration/#5-how-to-add-a-new-configuration-parameter","title":"5. How to Add a New Configuration Parameter","text":""},{"location":"simulations/configuration/#step-1-update-the-schema","title":"Step 1: Update the Schema","text":"<p>Open your simulation's <code>schemas.py</code> file and add the new field to the appropriate Pydantic model, defining its type and any constraints.</p> <pre><code># Add to existing AgentConfig class\nclass AgentConfig(BaseModel):\n    max_health: int = Field(default=100, gt=0)\n    learning_rate: float = Field(default=0.01, gt=0, le=1)\n    memory_size: int = Field(default=1000, gt=0)\n\n    # NEW: Add your new parameter\n    aggression_level: float = Field(\n        default=0.5, \n        ge=0, \n        le=1, \n        description=\"Agent aggression level in combat\"\n    )\n</code></pre>"},{"location":"simulations/configuration/#step-2-update-the-base-config","title":"Step 2: Update the Base Config","text":"<p>Add the new parameter and a default value to your simulation's <code>base_config.yml</code> file, ensuring its location matches the structure in your schema.</p> <pre><code># simulations/your_new_sim/config/base_config.yml\nagent:\n  max_health: 100\n  learning_rate: 0.01\n  memory_size: 1000\n  aggression_level: 0.5  # NEW: Add here\n\nenvironment:\n  grid_size: 20\n  resource_density: 0.1\n  max_ticks: 1000\n\nexperiment_name: \"base_experiment\"\ndebug_mode: false\n</code></pre>"},{"location":"simulations/configuration/#step-3-use-in-code","title":"Step 3: Use in Code","text":"<p>Access your new parameter in any class that receives the <code>config</code> object using direct attribute access.</p> <pre><code># Example usage in a combat system\nclass CombatSystem(System):\n    def __init__(self, simulation_state: SimulationState, config: YourNewSimAppConfig):\n        super().__init__(simulation_state, config)\n        self.aggression_level = config.agent.aggression_level\n\n    def calculate_damage(self, base_damage: int) -&gt; int:\n        # Use the new configuration parameter\n        return int(base_damage * (1 + self.aggression_level))\n</code></pre>"},{"location":"simulations/configuration/#6-configuration-best-practices","title":"6. Configuration Best Practices","text":""},{"location":"simulations/configuration/#dos","title":"\u2705 Do's","text":"<ul> <li>Use descriptive field names that clearly indicate purpose</li> <li>Add docstrings to your Pydantic models for documentation</li> <li>Set appropriate validation constraints (e.g., <code>gt=0</code> for positive values)</li> <li>Provide sensible default values for all optional fields</li> <li>Group related parameters into logical sub-models</li> <li>Use type hints for all fields</li> </ul>"},{"location":"simulations/configuration/#donts","title":"\u274c Don'ts","text":"<ul> <li>Don't use dictionary access (<code>.get()</code>) on validated config objects</li> <li>Don't bypass validation by directly creating dictionaries</li> <li>Don't mix validated and unvalidated configuration objects</li> <li>Don't hardcode values that should be configurable</li> <li>Don't create deeply nested structures (limit to 3-4 levels)</li> </ul>"},{"location":"simulations/configuration/#example-of-good-configuration-structure","title":"Example of Good Configuration Structure","text":"<pre><code>class DynamicsConfig(BaseModel):\n    \"\"\"Agent dynamics and learning parameters.\"\"\"\n    learning_rate: float = Field(default=0.01, gt=0, le=1)\n    discount_factor: float = Field(default=0.95, gt=0, le=1)\n    exploration_rate: float = Field(default=0.1, ge=0, le=1)\n\nclass PhysicalConfig(BaseModel):\n    \"\"\"Agent physical properties.\"\"\"\n    max_health: int = Field(default=100, gt=0)\n    movement_speed: float = Field(default=1.0, gt=0)\n    vision_range: int = Field(default=5, gt=0)\n\nclass AgentConfig(BaseModel):\n    \"\"\"Complete agent configuration.\"\"\"\n    dynamics: DynamicsConfig = Field(default_factory=DynamicsConfig)\n    physical: PhysicalConfig = Field(default_factory=PhysicalConfig)\n    name_prefix: str = Field(default=\"Agent\", min_length=1)\n</code></pre>"},{"location":"simulations/configuration/#7-troubleshooting-common-issues","title":"7. Troubleshooting Common Issues","text":""},{"location":"simulations/configuration/#validation-errors","title":"Validation Errors","text":"<p>When you see validation errors, they typically fall into these categories:</p> <ol> <li>Missing required fields: Add the field to your YAML config</li> <li>Type mismatches: Ensure YAML values match schema types (int vs float vs str)</li> <li>Constraint violations: Check Field constraints like <code>gt=0</code>, <code>le=1</code></li> <li>Nested structure issues: Verify YAML nesting matches Pydantic model structure</li> </ol>"},{"location":"simulations/configuration/#example-error-and-fix","title":"Example Error and Fix","text":"<pre><code># Error message\nValidationError: 1 validation error for YourNewSimAppConfig\nagent.learning_rate\n  ensure this value is greater than 0 (type=value_error.number.not_gt; limit_value=0)\n</code></pre> <pre><code># Fix: Update base_config.yml\nagent:\n  learning_rate: 0.01  # Was 0 or negative, now positive\n</code></pre> <p>This configuration system ensures that your simulations are robust, well-documented, and maintainable while providing excellent developer experience through type safety and IDE support.</p>"},{"location":"tutorials/first-simulation/","title":"Building Your First Simulation","text":"<p>Learn ARLA fundamentals by creating a simple yet complete simulation from scratch. You'll build agents that move in a 2D world while mastering the core concepts of Components, Actions, and Systems.</p> <p>What You'll Learn</p> <ul> <li>Entity-Component-System (ECS) architecture patterns</li> <li>Component design for pure data storage</li> <li>Action implementation for agent behaviors</li> <li>System development for world logic</li> <li>Event-driven communication between systems</li> </ul>"},{"location":"tutorials/first-simulation/#overview-the-simple-movement-simulation","title":"Overview: The Simple Movement Simulation","text":"<p>We'll create a basic simulation where agents move randomly in a 2D grid world. This covers all essential ARLA concepts in a digestible example.</p> <ul> <li> <p>\ud83d\uddc2\ufe0f Components</p> <p>Store agent position data</p> </li> <li> <p>\u26a1 Actions</p> <p>Define movement possibilities</p> </li> <li> <p>\u2699\ufe0f Systems</p> <p>Handle movement logic</p> </li> <li> <p>\ud83d\udce1 Events</p> <p>Coordinate between systems</p> </li> </ul>"},{"location":"tutorials/first-simulation/#step-1-create-project-structure","title":"Step 1: Create Project Structure","text":"<p>Set up the directory structure for your new simulation:</p> <pre><code>mkdir -p simulations/simple_sim/actions\nmkdir -p simulations/simple_sim/config\n</code></pre> <p>Your structure should look like:</p> <pre><code>simulations/\n\u2514\u2500\u2500 simple_sim/\n    \u251c\u2500\u2500 actions/\n    \u2514\u2500\u2500 config/\n</code></pre>"},{"location":"tutorials/first-simulation/#step-2-define-a-position-component","title":"Step 2: Define a Position Component","text":"<p>Components are pure data containers with no logic. Create your first component to track agent positions.</p> components.pyKey Features simulations/simple_sim/components.py<pre><code>from agent_core.core.ecs.component import Component\nfrom typing import Tuple, Dict, Any\n\nclass PositionComponent(Component):\n    \"\"\"Stores an entity's x, y coordinates in the grid world.\"\"\"\n\n    def __init__(self, x: int = 0, y: int = 0):\n        self.x = x\n        self.y = y\n        self.previous_x = x\n        self.previous_y = y\n\n    def move_to(self, new_x: int, new_y: int) -&gt; None:\n        \"\"\"Update position and track previous location.\"\"\"\n        self.previous_x, self.previous_y = self.x, self.y\n        self.x, self.y = new_x, new_y\n\n    @property\n    def position(self) -&gt; Tuple[int, int]:\n        \"\"\"Current position as tuple.\"\"\"\n        return (self.x, self.y)\n\n    @property\n    def previous_position(self) -&gt; Tuple[int, int]:\n        \"\"\"Previous position as tuple.\"\"\"\n        return (self.previous_x, self.previous_y)\n\n    def to_dict(self) -&gt; Dict[str, Any]:\n        \"\"\"Serialize component for persistence.\"\"\"\n        return {\n            \"x\": self.x,\n            \"y\": self.y,\n            \"previous_x\": self.previous_x,\n            \"previous_y\": self.previous_y\n        }\n\n    def validate(self, entity_id: str) -&gt; Tuple[bool, List[str]]:\n        \"\"\"Validate component state.\"\"\"\n        errors = []\n\n        if not isinstance(self.x, int) or not isinstance(self.y, int):\n            errors.append(\"Position coordinates must be integers\")\n\n        return len(errors) == 0, errors\n</code></pre> <ul> <li>Pure Data: No business logic, only state storage</li> <li>Validation: Built-in error checking for data integrity  </li> <li>Serialization: <code>to_dict()</code> enables saving/loading state</li> <li>Convenience Methods: Helper properties for cleaner code</li> </ul>"},{"location":"tutorials/first-simulation/#step-3-create-a-movement-action","title":"Step 3: Create a Movement Action","text":"<p>Actions define what agents can do. They generate possible parameters and delegate execution to Systems via events.</p> move_action.pyKey Features simulations/simple_sim/actions/move_action.py<pre><code>from typing import Any, Dict, List\nfrom agent_core.agents.actions.action_interface import ActionInterface\nfrom agent_core.agents.actions.action_registry import action_registry\nfrom agent_core.agents.actions.base_action import ActionOutcome\nfrom agent_core.core.ecs.abstractions import SimulationState\nfrom ..components import PositionComponent\n\n@action_registry.register\nclass MoveAction(ActionInterface):\n    \"\"\"Allows an agent to move to an adjacent grid cell.\"\"\"\n\n    @property\n    def action_id(self) -&gt; str:\n        return \"move\"\n\n    @property\n    def name(self) -&gt; str:\n        return \"Move\"\n\n    def get_base_cost(self, simulation_state: SimulationState) -&gt; float:\n        \"\"\"Energy cost for movement.\"\"\"\n        return 1.0\n\n    def generate_possible_params(\n        self, \n        entity_id: str, \n        simulation_state: SimulationState, \n        current_tick: int\n    ) -&gt; List[Dict[str, Any]]:\n        \"\"\"Generate all valid movement options.\"\"\"\n\n        pos_comp = simulation_state.get_component(entity_id, PositionComponent)\n        if not pos_comp:\n            return []\n\n        # Define possible movement directions\n        directions = [\n            {\"dx\": 0, \"dy\": 1, \"direction\": \"north\"},\n            {\"dx\": 1, \"dy\": 0, \"direction\": \"east\"}, \n            {\"dx\": 0, \"dy\": -1, \"direction\": \"south\"},\n            {\"dx\": -1, \"dy\": 0, \"direction\": \"west\"}\n        ]\n\n        valid_moves = []\n        for direction in directions:\n            new_x = pos_comp.x + direction[\"dx\"]\n            new_y = pos_comp.y + direction[\"dy\"]\n\n            # Simple bounds checking (extend as needed)\n            if 0 &lt;= new_x &lt; 50 and 0 &lt;= new_y &lt; 50:\n                valid_moves.append({\n                    \"dx\": direction[\"dx\"],\n                    \"dy\": direction[\"dy\"],\n                    \"target_x\": new_x,\n                    \"target_y\": new_y,\n                    \"direction\": direction[\"direction\"]\n                })\n\n        return valid_moves\n\n    def execute(\n        self,\n        entity_id: str,\n        simulation_state: SimulationState,\n        params: Dict[str, Any],\n        current_tick: int,\n    ) -&gt; ActionOutcome:\n        \"\"\"Return action outcome. Actual logic handled by MovementSystem.\"\"\"\n        direction = params.get(\"direction\", \"unknown\")\n        target = (params.get(\"target_x\"), params.get(\"target_y\"))\n\n        return ActionOutcome(\n            success=True,\n            message=f\"Agent {entity_id} moves {direction} to {target}\",\n            base_reward=0.1\n        )\n\n    def get_feature_vector(\n        self,\n        entity_id: str,\n        simulation_state: SimulationState,\n        params: Dict[str, Any],\n    ) -&gt; List[float]:\n        \"\"\"Encode action for machine learning.\"\"\"\n        # Simple encoding: [is_move_action, dx, dy]\n        return [\n            1.0,  # Move action identifier\n            float(params.get(\"dx\", 0)),\n            float(params.get(\"dy\", 0))\n        ]\n</code></pre> <ul> <li>@action_registry.register: Auto-discovery by the simulation engine</li> <li>Parameter Generation: Creates all valid movement options</li> <li>Bounds Checking: Prevents agents from moving off the grid</li> <li>ML Integration: Feature vectors for learning algorithms</li> </ul>"},{"location":"tutorials/first-simulation/#step-4-implement-movement-system","title":"Step 4: Implement Movement System","text":"<p>Systems contain the business logic. They subscribe to events and update the simulation state.</p> systems.pyKey Features simulations/simple_sim/systems.py<pre><code>from typing import Any, Dict\nfrom agent_engine.simulation.system import System\nfrom .components import PositionComponent\n\nclass MovementSystem(System):\n    \"\"\"Handles agent movement in the grid world.\"\"\"\n\n    def __init__(self, simulation_state, config, cognitive_scaffold):\n        super().__init__(simulation_state, config, cognitive_scaffold)\n\n        # Subscribe to movement action events\n        if self.event_bus:\n            self.event_bus.subscribe(\"execute_move_action\", self.on_move_execute)\n\n    def on_move_execute(self, event_data: Dict[str, Any]) -&gt; None:\n        \"\"\"Process movement action execution.\"\"\"\n        entity_id = event_data[\"entity_id\"]\n        action_plan = event_data[\"action_plan_component\"]\n        params = action_plan.params\n\n        # Get agent's position component\n        pos_comp = self.simulation_state.get_component(entity_id, PositionComponent)\n        if not pos_comp:\n            self._publish_failure(event_data, \"Agent has no position component\")\n            return\n\n        # Extract movement parameters\n        target_x = params.get(\"target_x\")\n        target_y = params.get(\"target_y\")\n\n        if target_x is None or target_y is None:\n            self._publish_failure(event_data, \"Invalid movement parameters\")\n            return\n\n        # Validate movement is within bounds\n        if not self._is_valid_position(target_x, target_y):\n            self._publish_failure(event_data, f\"Position ({target_x}, {target_y}) out of bounds\")\n            return\n\n        # Update position\n        old_pos = pos_comp.position\n        pos_comp.move_to(target_x, target_y)\n\n        print(f\"\ud83d\udeb6 Agent {entity_id} moved from {old_pos} to {pos_comp.position}\")\n\n        # Signal action completion\n        self._publish_success(event_data)\n\n    def _is_valid_position(self, x: int, y: int) -&gt; bool:\n        \"\"\"Check if position is within world bounds.\"\"\"\n        return 0 &lt;= x &lt; 50 and 0 &lt;= y &lt; 50\n\n    def _publish_success(self, event_data: Dict[str, Any]) -&gt; None:\n        \"\"\"Notify that action completed successfully.\"\"\"\n        if self.event_bus:\n            self.event_bus.publish(\"action_outcome_ready\", event_data)\n\n    def _publish_failure(self, event_data: Dict[str, Any], reason: str) -&gt; None:\n        \"\"\"Notify that action failed.\"\"\"\n        print(f\"\u274c Movement failed: {reason}\")\n        # Update action outcome to reflect failure\n        if hasattr(event_data.get(\"action_plan_component\"), \"outcome\"):\n            event_data[\"action_plan_component\"].outcome.success = False\n            event_data[\"action_plan_component\"].outcome.message = reason\n\n        if self.event_bus:\n            self.event_bus.publish(\"action_outcome_ready\", event_data)\n\n    async def update(self, current_tick: int) -&gt; None:\n        \"\"\"Main system update loop. Movement is event-driven, so nothing needed here.\"\"\"\n        pass\n</code></pre> <ul> <li>Event Subscription: Listens for <code>execute_move_action</code> events</li> <li>State Validation: Checks components exist and parameters are valid</li> <li>Bounds Checking: Prevents invalid movements</li> <li>Error Handling: Graceful failure with informative messages</li> <li>Event Publishing: Signals action completion to other systems</li> </ul>"},{"location":"tutorials/first-simulation/#step-5-create-simulation-entry-point","title":"Step 5: Create Simulation Entry Point","text":"<p>Tie everything together with a main runner that registers your systems and starts the simulation.</p> run.pyConfiguration simulations/simple_sim/run.py<pre><code>import asyncio\nfrom pathlib import Path\nfrom typing import Optional\nfrom omegaconf import OmegaConf\n\nfrom agent_engine.simulation.engine import SimulationManager\nfrom .systems import MovementSystem\nfrom .components import PositionComponent\n\nasync def setup_and_run(\n    run_id: str,\n    task_id: str, \n    experiment_id: str,\n    config_overrides: dict,\n    checkpoint_path: Optional[str] = None\n):\n    \"\"\"Initialize and run the simple movement simulation.\"\"\"\n\n    print(f\"\ud83d\ude80 Starting Simple Simulation - Run: {run_id}\")\n\n    # Load base configuration\n    config_path = Path(__file__).parent / \"config\" / \"base_config.yml\"\n    if config_path.exists():\n        base_config = OmegaConf.load(config_path)\n        final_config = OmegaConf.merge(base_config, config_overrides)\n    else:\n        final_config = OmegaConf.create(config_overrides)\n\n    # Create simulation manager with required dependencies\n    # Note: In a real implementation, you'd inject proper dependencies\n    manager = SimulationManager(\n        config=final_config,\n        run_id=run_id,\n        task_id=task_id,\n        experiment_id=experiment_id,\n        checkpoint_path=checkpoint_path\n    )\n\n    # Register custom systems\n    manager.register_system(MovementSystem)\n\n    # Add startup entities (agents with position components)\n    await _initialize_agents(manager, final_config)\n\n    print(f\"\ud83c\udfaf Simulation configured with {final_config.get('agent_count', 10)} agents\")\n\n    # Run the simulation\n    await manager.run()\n\n    print(f\"\u2705 Simulation {run_id} completed\")\n\nasync def _initialize_agents(manager: SimulationManager, config: dict):\n    \"\"\"Create initial agents with position components.\"\"\"\n    agent_count = config.get(\"agent_count\", 10)\n\n    for i in range(agent_count):\n        entity_id = f\"agent_{i:03d}\"\n\n        # Create agent at random position\n        import random\n        x = random.randint(0, 49)\n        y = random.randint(0, 49)\n\n        # Add position component\n        position_comp = PositionComponent(x=x, y=y)\n        manager.simulation_state.add_component(entity_id, position_comp)\n\n        print(f\"\ud83e\udd16 Created {entity_id} at position ({x}, {y})\")\n\ndef start_simulation(run_id: str, task_id: str, experiment_id: str, config_overrides: dict):\n    \"\"\"Entry point for external callers.\"\"\"\n    asyncio.run(setup_and_run(run_id, task_id, experiment_id, config_overrides))\n</code></pre> simulations/simple_sim/config/base_config.yml<pre><code># Basic configuration for simple movement simulation\n\nsimulation:\n  max_ticks: 1000\n  random_seed: 42\n\nworld:\n  grid_size: 50\n\nagents:\n  count: 10\n  start_energy: 100.0\n\nlogging:\n  level: \"INFO\"\n  log_movements: true\n</code></pre>"},{"location":"tutorials/first-simulation/#step-6-test-your-simulation","title":"Step 6: Test Your Simulation","text":"<p>Now run your simulation and see agents moving around the grid world:</p> <pre><code>cd simulations/simple_sim\npython -c \"\nfrom run import start_simulation\nstart_simulation('test_run_001', 'tutorial_task', 'simple_sim_experiment', {\n    'agent_count': 5,\n    'simulation': {'max_ticks': 100}\n})\n\"\n</code></pre> <p>Expected Output: <pre><code>\ud83d\ude80 Starting Simple Simulation - Run: test_run_001\n\ud83e\udd16 Created agent_000 at position (23, 15)\n\ud83e\udd16 Created agent_001 at position (8, 42)\n\ud83e\udd16 Created agent_002 at position (35, 7)\n\ud83d\udeb6 Agent agent_000 moved from (23, 15) to (24, 15)\n\ud83d\udeb6 Agent agent_001 moved from (8, 42) to (8, 43)\n...\n\u2705 Simulation test_run_001 completed\n</code></pre></p>"},{"location":"tutorials/first-simulation/#understanding-the-architecture","title":"Understanding the Architecture","text":""},{"location":"tutorials/first-simulation/#event-flow-diagram","title":"Event Flow Diagram","text":"<pre><code>graph TD\n    A[Agent Decision] --&gt; B[MoveAction.generate_possible_params]\n    B --&gt; C[Action Selection]\n    C --&gt; D[execute_move_action Event]\n    D --&gt; E[MovementSystem.on_move_execute]\n    E --&gt; F[Update PositionComponent]\n    F --&gt; G[action_outcome_ready Event]\n    G --&gt; H[Reward Calculation]</code></pre>"},{"location":"tutorials/first-simulation/#key-concepts-learned","title":"Key Concepts Learned","text":"<p>ECS Architecture</p> <ul> <li>Entities: Unique IDs for agents</li> <li>Components: Pure data (PositionComponent)</li> <li>Systems: Logic (MovementSystem)</li> </ul> <p>Event-Driven Design</p> <ul> <li>Systems communicate via events, not direct calls</li> <li>Loose coupling enables easy testing and modification</li> <li>Clear separation of concerns</li> </ul> <p>Action Pattern</p> <ul> <li>Actions define possibilities, not implementation</li> <li>Parameters generated dynamically based on world state</li> <li>Systems handle the actual world changes</li> </ul>"},{"location":"tutorials/first-simulation/#next-steps","title":"Next Steps","text":"<p>Congratulations! You've built a complete ARLA simulation. Here's how to expand it:</p> <ul> <li> <p>\ud83c\udfaf Add More Actions</p> <p>Create actions for resource gathering, agent communication, or combat interactions.</p> <p> Creating Actions Guide</p> </li> <li> <p>\ud83e\udde0 Add Cognitive Systems</p> <p>Integrate memory, goals, and decision-making systems from the agent-engine.</p> <p> Cognitive Architecture</p> </li> <li> <p>\ud83c\udf0d Expand the World</p> <p>Add terrain, resources, obstacles, and environmental dynamics.</p> <p> Advanced Systems</p> </li> <li> <p>\ud83d\udcca Run Experiments</p> <p>Design experiments with multiple configurations and analyze results.</p> <p> Running Experiments</p> </li> </ul>"},{"location":"blog/archive/2025/","title":"2025","text":""},{"location":"blog/category/technical-deep-dive/","title":"Technical Deep Dive","text":""},{"location":"blog/category/research/","title":"Research","text":""},{"location":"blog/category/announcement/","title":"Announcement","text":""},{"location":"blog/category/community/","title":"Community","text":""}]}